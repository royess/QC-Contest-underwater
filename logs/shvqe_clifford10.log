Train hybrid.
----------epoch 0-----------
batched average loss:  -43.826393 minimum candidate loss:  -43.915466
probability converged
strcuture parameter: 
 [[0.40000832 1.5999917 ]
 [0.40003943 1.5999606 ]
 [0.40000898 1.5999911 ]
 [1.5999873  0.40001267]
 [1.599992   0.4000079 ]
 [1.596467   0.40353304]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-49.667492, shape=(), dtype=float32)
----------epoch 50-----------
batched average loss:  -77.91145 minimum candidate loss:  -77.91146
probability converged
strcuture parameter: 
 [[-8.092605   6.2917337]
 [-7.87057    5.633067 ]
 [-8.044177   6.270408 ]
 [ 5.9517493 -7.970865 ]
 [ 6.2771907 -8.100312 ]
 [ 5.40637   -7.8321924]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.18047, shape=(), dtype=float32)
----------epoch 100-----------
batched average loss:  -78.70636 minimum candidate loss:  -78.70636
probability converged
strcuture parameter: 
 [[-8.95393    6.323475 ]
 [-8.734128   5.6615067]
 [-8.904048   6.302096 ]
 [ 5.981581  -8.830485 ]
 [ 6.3087564 -8.960236 ]
 [ 5.433551  -8.695287 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.706535, shape=(), dtype=float32)
----------epoch 150-----------
batched average loss:  -78.71721 minimum candidate loss:  -78.7172
probability converged
strcuture parameter: 
 [[-8.957054   6.323674 ]
 [-8.737258   5.661686 ]
 [-8.907165   6.302295 ]
 [ 5.9817686 -8.833605 ]
 [ 6.3089547 -8.963359 ]
 [ 5.4337215 -8.698417 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.70594, shape=(), dtype=float32)
----------epoch 200-----------
batched average loss:  -78.71546 minimum candidate loss:  -78.71547
probability converged
strcuture parameter: 
 [[-8.970077   6.323674 ]
 [-8.750338   5.661686 ]
 [-8.920169   6.302295 ]
 [ 5.9817686 -8.846605 ]
 [ 6.3089547 -8.976359 ]
 [ 5.4337215 -8.711478 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71317, shape=(), dtype=float32)
----------epoch 250-----------
batched average loss:  -78.72807 minimum candidate loss:  -78.728065
probability converged
strcuture parameter: 
 [[-8.972495   6.323674 ]
 [-8.752763   5.661686 ]
 [-8.922577   6.302295 ]
 [ 5.9817686 -8.849017 ]
 [ 6.3089547 -8.978772 ]
 [ 5.4337215 -8.7139015]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72854, shape=(), dtype=float32)
----------epoch 300-----------
batched average loss:  -78.733055 minimum candidate loss:  -78.73306
probability converged
strcuture parameter: 
 [[-8.975037   6.323674 ]
 [-8.755315   5.661686 ]
 [-8.925115   6.302295 ]
 [ 5.9817686 -8.851554 ]
 [ 6.3089547 -8.981309 ]
 [ 5.4337215 -8.716454 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73312, shape=(), dtype=float32)
----------epoch 350-----------
batched average loss:  -78.73753 minimum candidate loss:  -78.737526
probability converged
strcuture parameter: 
 [[-8.976601   6.323674 ]
 [-8.756888   5.661686 ]
 [-8.926677   6.302295 ]
 [ 5.9817686 -8.853116 ]
 [ 6.3089547 -8.982871 ]
 [ 5.4337215 -8.718023 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73786, shape=(), dtype=float32)
----------epoch 400-----------
batched average loss:  -78.74261 minimum candidate loss:  -78.7426
probability converged
strcuture parameter: 
 [[-8.978417   6.323674 ]
 [-8.758713   5.661686 ]
 [-8.92849    6.302295 ]
 [ 5.9817686 -8.854929 ]
 [ 6.3089547 -8.984684 ]
 [ 5.4337215 -8.719848 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74273, shape=(), dtype=float32)
----------epoch 450-----------
batched average loss:  -78.74513 minimum candidate loss:  -78.74514
probability converged
strcuture parameter: 
 [[-8.979437   6.323674 ]
 [-8.759735   5.661686 ]
 [-8.929508   6.302295 ]
 [ 5.9817686 -8.855947 ]
 [ 6.3089547 -8.985702 ]
 [ 5.4337215 -8.720868 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74513, shape=(), dtype=float32)
----------epoch 500-----------
batched average loss:  -78.74659 minimum candidate loss:  -78.74659
probability converged
strcuture parameter: 
 [[-8.97991    6.323674 ]
 [-8.760208   5.661686 ]
 [-8.929978   6.302295 ]
 [ 5.9817686 -8.856417 ]
 [ 6.3089547 -8.986172 ]
 [ 5.4337215 -8.721341 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74645, shape=(), dtype=float32)
----------epoch 550-----------
batched average loss:  -78.7472 minimum candidate loss:  -78.74721
probability converged
strcuture parameter: 
 [[-8.980182   6.323674 ]
 [-8.760481   5.661686 ]
 [-8.930249   6.302295 ]
 [ 5.9817686 -8.856688 ]
 [ 6.3089547 -8.986443 ]
 [ 5.4337215 -8.721614 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74741, shape=(), dtype=float32)
----------epoch 600-----------
batched average loss:  -78.74774 minimum candidate loss:  -78.74775
probability converged
strcuture parameter: 
 [[-8.980356   6.323674 ]
 [-8.760656   5.661686 ]
 [-8.930424   6.302295 ]
 [ 5.9817686 -8.856862 ]
 [ 6.3089547 -8.986617 ]
 [ 5.4337215 -8.721789 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74776, shape=(), dtype=float32)
----------epoch 650-----------
batched average loss:  -78.748245 minimum candidate loss:  -78.74825
probability converged
strcuture parameter: 
 [[-8.980441   6.323674 ]
 [-8.760742   5.661686 ]
 [-8.930508   6.302295 ]
 [ 5.9817686 -8.856946 ]
 [ 6.3089547 -8.986701 ]
 [ 5.4337215 -8.721875 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74823, shape=(), dtype=float32)
----------epoch 700-----------
batched average loss:  -78.74843 minimum candidate loss:  -78.748436
probability converged
strcuture parameter: 
 [[-8.980502   6.323674 ]
 [-8.760803   5.661686 ]
 [-8.930569   6.302295 ]
 [ 5.9817686 -8.857007 ]
 [ 6.3089547 -8.986762 ]
 [ 5.4337215 -8.721936 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74839, shape=(), dtype=float32)
----------epoch 750-----------
batched average loss:  -78.74872 minimum candidate loss:  -78.748726
probability converged
strcuture parameter: 
 [[-8.980571   6.323674 ]
 [-8.760873   5.661686 ]
 [-8.930636   6.302295 ]
 [ 5.9817686 -8.857075 ]
 [ 6.3089547 -8.98683  ]
 [ 5.4337215 -8.722005 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74865, shape=(), dtype=float32)
----------epoch 800-----------
batched average loss:  -78.74861 minimum candidate loss:  -78.74862
probability converged
strcuture parameter: 
 [[-8.980616   6.323674 ]
 [-8.760918   5.661686 ]
 [-8.930681   6.302295 ]
 [ 5.9817686 -8.85712  ]
 [ 6.3089547 -8.986875 ]
 [ 5.4337215 -8.72205  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.748886, shape=(), dtype=float32)
----------epoch 850-----------
batched average loss:  -78.748955 minimum candidate loss:  -78.74895
probability converged
strcuture parameter: 
 [[-8.980623   6.323674 ]
 [-8.760925   5.661686 ]
 [-8.930688   6.302295 ]
 [ 5.9817686 -8.857126 ]
 [ 6.3089547 -8.986881 ]
 [ 5.4337215 -8.722057 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74894, shape=(), dtype=float32)
----------epoch 900-----------
batched average loss:  -78.74912 minimum candidate loss:  -78.749115
probability converged
strcuture parameter: 
 [[-8.980684   6.323674 ]
 [-8.760988   5.661686 ]
 [-8.930749   6.302295 ]
 [ 5.9817686 -8.857187 ]
 [ 6.3089547 -8.986942 ]
 [ 5.4337215 -8.72212  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74889, shape=(), dtype=float32)
----------epoch 950-----------
batched average loss:  -78.74903 minimum candidate loss:  -78.74904
probability converged
strcuture parameter: 
 [[-8.980723   6.323674 ]
 [-8.761027   5.661686 ]
 [-8.930788   6.302295 ]
 [ 5.9817686 -8.857226 ]
 [ 6.3089547 -8.986981 ]
 [ 5.4337215 -8.722159 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74912, shape=(), dtype=float32)
----------epoch 1000-----------
batched average loss:  -78.74903 minimum candidate loss:  -78.74903
probability converged
strcuture parameter: 
 [[-8.980779   6.323674 ]
 [-8.761083   5.661686 ]
 [-8.930843   6.302295 ]
 [ 5.9817686 -8.857282 ]
 [ 6.3089547 -8.987037 ]
 [ 5.4337215 -8.722215 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74909, shape=(), dtype=float32)
----------epoch 1050-----------
batched average loss:  -78.74917 minimum candidate loss:  -78.749176
probability converged
strcuture parameter: 
 [[-8.9808035  6.323674 ]
 [-8.761107   5.661686 ]
 [-8.930868   6.302295 ]
 [ 5.9817686 -8.8573065]
 [ 6.3089547 -8.9870615]
 [ 5.4337215 -8.7222395]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74914, shape=(), dtype=float32)
----------epoch 1100-----------
batched average loss:  -78.74909 minimum candidate loss:  -78.7491
probability converged
strcuture parameter: 
 [[-8.980793   6.323674 ]
 [-8.761097   5.661686 ]
 [-8.930858   6.302295 ]
 [ 5.9817686 -8.857296 ]
 [ 6.3089547 -8.987051 ]
 [ 5.4337215 -8.722229 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74917, shape=(), dtype=float32)
----------epoch 1150-----------
batched average loss:  -78.74903 minimum candidate loss:  -78.74904
probability converged
strcuture parameter: 
 [[-8.980787   6.323674 ]
 [-8.761091   5.661686 ]
 [-8.930852   6.302295 ]
 [ 5.9817686 -8.85729  ]
 [ 6.3089547 -8.987045 ]
 [ 5.4337215 -8.722223 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74935, shape=(), dtype=float32)
----------epoch 1200-----------
batched average loss:  -78.74919 minimum candidate loss:  -78.74918
probability converged
strcuture parameter: 
 [[-8.980813   6.323674 ]
 [-8.761117   5.661686 ]
 [-8.930878   6.302295 ]
 [ 5.9817686 -8.857316 ]
 [ 6.3089547 -8.987071 ]
 [ 5.4337215 -8.722249 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74914, shape=(), dtype=float32)
----------epoch 1250-----------
batched average loss:  -78.74927 minimum candidate loss:  -78.74927
probability converged
strcuture parameter: 
 [[-8.980821   6.323674 ]
 [-8.761125   5.661686 ]
 [-8.930885   6.302295 ]
 [ 5.9817686 -8.857324 ]
 [ 6.3089547 -8.987079 ]
 [ 5.4337215 -8.722257 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74912, shape=(), dtype=float32)
----------epoch 1300-----------
batched average loss:  -78.74904 minimum candidate loss:  -78.74905
probability converged
strcuture parameter: 
 [[-8.980811   6.323674 ]
 [-8.761115   5.661686 ]
 [-8.930876   6.302295 ]
 [ 5.9817686 -8.857314 ]
 [ 6.3089547 -8.987069 ]
 [ 5.4337215 -8.722247 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74927, shape=(), dtype=float32)
----------epoch 1350-----------
batched average loss:  -78.74922 minimum candidate loss:  -78.74923
probability converged
strcuture parameter: 
 [[-8.980806   6.323674 ]
 [-8.76111    5.661686 ]
 [-8.930871   6.302295 ]
 [ 5.9817686 -8.857309 ]
 [ 6.3089547 -8.987064 ]
 [ 5.4337215 -8.722242 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.749275, shape=(), dtype=float32)
----------epoch 1400-----------
batched average loss:  -78.74914 minimum candidate loss:  -78.74914
probability converged
strcuture parameter: 
 [[-8.980804   6.323674 ]
 [-8.761108   5.661686 ]
 [-8.930869   6.302295 ]
 [ 5.9817686 -8.857307 ]
 [ 6.3089547 -8.987062 ]
 [ 5.4337215 -8.72224  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74913, shape=(), dtype=float32)
----------epoch 1450-----------
batched average loss:  -78.74933 minimum candidate loss:  -78.74931
probability converged
strcuture parameter: 
 [[-8.980818   6.323674 ]
 [-8.761122   5.661686 ]
 [-8.930882   6.302295 ]
 [ 5.9817686 -8.857321 ]
 [ 6.3089547 -8.987076 ]
 [ 5.4337215 -8.722254 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.749146, shape=(), dtype=float32)
----------epoch 1500-----------
batched average loss:  -78.74922 minimum candidate loss:  -78.74923
probability converged
strcuture parameter: 
 [[-8.980814   6.323674 ]
 [-8.761118   5.661686 ]
 [-8.930879   6.302295 ]
 [ 5.9817686 -8.857317 ]
 [ 6.3089547 -8.987072 ]
 [ 5.4337215 -8.72225  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74897, shape=(), dtype=float32)
----------epoch 1550-----------
batched average loss:  -78.74913 minimum candidate loss:  -78.74912
probability converged
strcuture parameter: 
 [[-8.980799   6.323674 ]
 [-8.761103   5.661686 ]
 [-8.930863   6.302295 ]
 [ 5.9817686 -8.857302 ]
 [ 6.3089547 -8.987057 ]
 [ 5.4337215 -8.722235 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7492, shape=(), dtype=float32)
----------epoch 1600-----------
batched average loss:  -78.74933 minimum candidate loss:  -78.74931
probability converged
strcuture parameter: 
 [[-8.980794   6.323674 ]
 [-8.761098   5.661686 ]
 [-8.930859   6.302295 ]
 [ 5.9817686 -8.857297 ]
 [ 6.3089547 -8.987052 ]
 [ 5.4337215 -8.72223  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74919, shape=(), dtype=float32)
----------epoch 1650-----------
batched average loss:  -78.74944 minimum candidate loss:  -78.74944
probability converged
strcuture parameter: 
 [[-8.980805   6.323674 ]
 [-8.761134   5.661686 ]
 [-8.93087    6.302295 ]
 [ 5.9817686 -8.857308 ]
 [ 6.3089547 -8.987063 ]
 [ 5.4337215 -8.722241 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.749306, shape=(), dtype=float32)
----------epoch 1700-----------
batched average loss:  -78.74934 minimum candidate loss:  -78.74934
probability converged
strcuture parameter: 
 [[-8.980794   6.323674 ]
 [-8.761123   5.661686 ]
 [-8.930859   6.302295 ]
 [ 5.9817686 -8.857297 ]
 [ 6.3089547 -8.987052 ]
 [ 5.4337215 -8.72223  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.749275, shape=(), dtype=float32)
----------epoch 1750-----------
batched average loss:  -78.74933 minimum candidate loss:  -78.74933
probability converged
strcuture parameter: 
 [[-8.980798   6.323674 ]
 [-8.7611265  5.661686 ]
 [-8.930862   6.302295 ]
 [ 5.9817686 -8.857301 ]
 [ 6.3089547 -8.987056 ]
 [ 5.4337215 -8.722234 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.749306, shape=(), dtype=float32)
----------epoch 1800-----------
batched average loss:  -78.74921 minimum candidate loss:  -78.74921
probability converged
strcuture parameter: 
 [[-8.9808     6.323674 ]
 [-8.761128   5.661686 ]
 [-8.930864   6.302295 ]
 [ 5.9817686 -8.857303 ]
 [ 6.3089547 -8.987058 ]
 [ 5.4337215 -8.722236 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74941, shape=(), dtype=float32)
----------epoch 1850-----------
batched average loss:  -78.749275 minimum candidate loss:  -78.74928
probability converged
strcuture parameter: 
 [[-8.980805   6.323674 ]
 [-8.761134   5.661686 ]
 [-8.930871   6.302295 ]
 [ 5.9817686 -8.857319 ]
 [ 6.3089547 -8.987064 ]
 [ 5.4337215 -8.722241 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74927, shape=(), dtype=float32)
----------epoch 1900-----------
batched average loss:  -78.74927 minimum candidate loss:  -78.74927
probability converged
strcuture parameter: 
 [[-8.980814   6.323674 ]
 [-8.761143   5.661686 ]
 [-8.930879   6.302295 ]
 [ 5.9817686 -8.857328 ]
 [ 6.3089547 -8.987072 ]
 [ 5.4337215 -8.72225  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74928, shape=(), dtype=float32)
----------epoch 1950-----------
batched average loss:  -78.749275 minimum candidate loss:  -78.749275
probability converged
strcuture parameter: 
 [[-8.980819   6.323674 ]
 [-8.7611475  5.661686 ]
 [-8.930883   6.302295 ]
 [ 5.9817686 -8.857333 ]
 [ 6.3089547 -8.987077 ]
 [ 5.4337215 -8.722255 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74912, shape=(), dtype=float32)
----------epoch 1999-----------
batched average loss:  -78.74922 minimum candidate loss:  -78.74923
probability converged
strcuture parameter: 
 [[-8.980826   6.323674 ]
 [-8.761155   5.661686 ]
 [-8.930891   6.302295 ]
 [ 5.9817686 -8.857341 ]
 [ 6.3089547 -8.987084 ]
 [ 5.4337215 -8.722262 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74937, shape=(), dtype=float32)
Energy: tf.Tensor(-78.74937, shape=(), dtype=float32)
Ref energy: -74.38714627
Error rate: tf.Tensor(0.004235866, shape=(), dtype=float32)
        ┌─────────────┐  ┌──────────────┐ ┌────────────┐ ┌─────────────┐»
 q_0: ──┤ Rx(-1.3903) ├──┤ Ry(-0.34578) ├─┤ Rz(1.3367) ├─┤ Rx(0.78751) ├»
        ├─────────────┤  ├─────────────┬┘┌┴────────────┤ └─────────────┘»
 q_1: ──┤ Rx(-3.0605) ├──┤ Ry(-1.2922) ├─┤ Rz(0.27397) ├────────■───────»
        ├─────────────┤  ├─────────────┤ ├─────────────┤        │       »
 q_2: ──┤ Rx(-5.5517) ├──┤ Ry(0.26976) ├─┤ Rz(0.92157) ├────────■───────»
        ├─────────────┴┐ └┬───────────┬┘ ├─────────────┤                »
 q_3: ──┤ Rx(-0.60884) ├──┤ Ry(1.012) ├──┤ Rz(-4.6955) ├────────■───────»
      ┌─┴──────────────┴┐┌┴───────────┴┐ ├─────────────┤        │       »
 q_4: ┤ Rx(-0.00063367) ├┤ Ry(-3.1415) ├─┤ Rz(-5.1404) ├────────■───────»
      └──┬────────────┬─┘├─────────────┴┐├─────────────┤                »
 q_5: ───┤ Rx(1.1461) ├──┤ Ry(-0.95476) ├┤ Rz(-1.5522) ├────────■───────»
         ├────────────┤  ├─────────────┬┘└┬───────────┬┘        │       »
 q_6: ───┤ Rx(-5.455) ├──┤ Ry(-6.0515) ├──┤ Rz(1.472) ├─────────■───────»
        ┌┴────────────┤  ├─────────────┤  ├───────────┴┐                »
 q_7: ──┤ Rx(-4.2359) ├──┤ Ry(-1.9186) ├──┤ Rz(1.5211) ├────────■───────»
        ├─────────────┤  ├─────────────┤ ┌┴────────────┤        │       »
 q_8: ──┤ Rx(-1.5267) ├──┤ Ry(-5.2608) ├─┤ Rz(-5.0116) ├────────■───────»
       ┌┴─────────────┴┐ ├─────────────┤ ├─────────────┴┐               »
 q_9: ─┤ Rx(-0.029259) ├─┤ Ry(-3.1339) ├─┤ Rz(-0.66203) ├───────■───────»
       └┬─────────────┬┘ ├─────────────┴┐├─────────────┬┘       │       »
q_10: ──┤ Rx(-4.2957) ├──┤ Ry(-0.80056) ├┤ Rz(-2.1514) ├────────■───────»
        └┬───────────┬┘  └┬────────────┬┘└┬────────────┤  ┌───────────┐ »
q_11: ───┤ Rx(2.268) ├────┤ Ry(2.9918) ├──┤ Rz(1.6405) ├──┤ Rx(3.075) ├─»
         └───────────┘    └────────────┘  └────────────┘  └───────────┘ »
«       ┌────────────┐ ┌─────────────┐                      ┌─────────────┐  »
« q_0: ─┤ Ry(1.3292) ├─┤ Rz(0.13171) ├──────────────────■───┤ Rx(-2.8206) ├──»
«      ┌┴────────────┤ └┬────────────┤  ┌────────────┐  │   ├─────────────┤  »
« q_1: ┤ Rx(-2.1031) ├──┤ Ry(-1.369) ├──┤ Rz(1.9232) ├──■───┤ Rx(-3.1985) ├──»
«      ├─────────────┤  ├────────────┤  ├────────────┤    ┌─┴─────────────┴─┐»
« q_2: ┤ Rx(-2.2754) ├──┤ Ry(3.0026) ├──┤ Rz(2.9731) ├──■─┤ Rx(-0.00037173) ├»
«      ├─────────────┤  ├────────────┤ ┌┴────────────┤  │ └─┬─────────────┬─┘»
« q_3: ┤ Rx(-4.8692) ├──┤ Ry(1.5493) ├─┤ Rz(-0.7979) ├──■───┤ Rx(-1.7687) ├──»
«      └┬────────────┤ ┌┴────────────┤ ├─────────────┤      └┬────────────┤  »
« q_4: ─┤ Rx(1.5546) ├─┤ Ry(-2.8841) ├─┤ Rz(-1.5682) ├──■────┤ Rx(3.1237) ├──»
«      ┌┴────────────┤ ├─────────────┴┐├─────────────┴┐ │    ├────────────┤  »
« q_5: ┤ Rx(-2.0853) ├─┤ Ry(-0.71379) ├┤ Rz(-0.24531) ├─■────┤ Rx(3.1438) ├──»
«      ├─────────────┤ ├─────────────┬┘└┬────────────┬┘     ┌┴────────────┤  »
« q_6: ┤ Rx(0.81085) ├─┤ Ry(-2.5738) ├──┤ Rz(3.2967) ├──■───┤ Rx(-3.4682) ├──»
«      ├─────────────┤ ├─────────────┤  ├────────────┤  │ ┌─┴─────────────┴─┐»
« q_7: ┤ Rx(-4.3097) ├─┤ Ry(0.10333) ├──┤ Rz(3.3869) ├──■─┤ Rx(-0.00014934) ├»
«      ├─────────────┤ └┬────────────┤  ├────────────┤    └─┬─────────────┬─┘»
« q_8: ┤ Rx(0.57369) ├──┤ Ry(1.7885) ├──┤ Rz(-1.165) ├──■───┤ Rx(-3.0612) ├──»
«      └┬────────────┤  ├────────────┤  ├────────────┤  │   ├─────────────┤  »
« q_9: ─┤ Rx(5.9479) ├──┤ Ry(-3.423) ├──┤ Rz(0.7427) ├──■───┤ Rx(0.88499) ├──»
«      ┌┴────────────┴┐ └┬──────────┬┘  ├────────────┤      ├─────────────┤  »
«q_10: ┤ Rx(-0.84723) ├──┤ Ry(3.81) ├───┤ Rz(1.4181) ├──■───┤ Rx(-3.8776) ├──»
«      └┬────────────┬┘ ┌┴──────────┴┐  └────────────┘  │   ├─────────────┤  »
«q_11: ─┤ Ry(4.0226) ├──┤ Rz(5.5983) ├──────────────────■───┤ Rx(0.93773) ├──»
«       └────────────┘  └────────────┘                      └─────────────┘  »
«       ┌──────────────┐  ┌────────────┐ ┌─────────────┐ ┌───────────┐  »
« q_0: ─┤ Ry(-0.86987) ├──┤ Rz(5.8641) ├─┤ Rx(-6.2731) ├─┤ Ry(4.054) ├──»
«       ├──────────────┤  ├────────────┤ └─────────────┘ ├───────────┴┐ »
« q_1: ─┤ Ry(0.029829) ├──┤ Rz(3.2851) ├────────■────────┤ Rx(-2.212) ├─»
«       └┬────────────┬┘  ├───────────┬┘        │       ┌┴────────────┤ »
« q_2: ──┤ Ry(3.1438) ├───┤ Rz(1.235) ├─────────■───────┤ Rx(0.22774) ├─»
«        ├────────────┤  ┌┴───────────┴┐                ├─────────────┤ »
« q_3: ──┤ Ry(2.4044) ├──┤ Rz(0.55645) ├────────■───────┤ Rx(-3.7362) ├─»
«       ┌┴────────────┤  ├─────────────┴┐       │       └┬────────────┤ »
« q_4: ─┤ Ry(-1.5655) ├──┤ Rz(-0.83365) ├───────■────────┤ Rx(3.1416) ├─»
«       ├─────────────┤  ├─────────────┬┘                ├────────────┤ »
« q_5: ─┤ Ry(-3.1412) ├──┤ Rz(-1.2419) ├────────■────────┤ Rx(1.5777) ├─»
«       ├─────────────┤  └┬────────────┤        │       ┌┴────────────┤ »
« q_6: ─┤ Ry(-3.2245) ├───┤ Rz(2.8666) ├────────■───────┤ Rx(-0.2075) ├─»
«      ┌┴─────────────┴─┐┌┴────────────┤                └┬────────────┤ »
« q_7: ┤ Ry(0.00048677) ├┤ Rz(-4.0818) ├────────■────────┤ Rx(6.2787) ├─»
«      └─┬────────────┬─┘├─────────────┤        │       ┌┴────────────┴┐»
« q_8: ──┤ Ry(-3.293) ├──┤ Rz(-3.4562) ├────────■───────┤ Rx(-0.36507) ├»
«       ┌┴────────────┴┐ ├─────────────┤                └┬────────────┬┘»
« q_9: ─┤ Ry(-0.33523) ├─┤ Rz(-7.6791) ├────────■────────┤ Rx(3.3316) ├─»
«       ├─────────────┬┘ └┬────────────┤        │       ┌┴────────────┤ »
«q_10: ─┤ Ry(-2.5762) ├───┤ Rz(0.1956) ├────────■───────┤ Rx(-2.0494) ├─»
«       └┬────────────┤  ┌┴────────────┤  ┌────────────┐└┬────────────┤ »
«q_11: ──┤ Ry(1.9242) ├──┤ Rz(0.83344) ├──┤ Rx(3.7108) ├─┤ Ry(1.8163) ├─»
«        └────────────┘  └─────────────┘  └────────────┘ └────────────┘ »
«        ┌────────────┐                    ┌────────────┐┌─────────────┐ »
« q_0: ──┤ Rz(4.4747) ├─────────────────■──┤ Rx(4.0066) ├┤ Ry(0.55185) ├─»
«        ├────────────┤  ┌────────────┐ │ ┌┴────────────┤├─────────────┤ »
« q_1: ──┤ Ry(1.8236) ├──┤ Rz(1.5572) ├─■─┤ Rx(-5.2887) ├┤ Ry(0.69363) ├─»
«       ┌┴────────────┤ ┌┴────────────┤   ├─────────────┤├─────────────┤ »
« q_2: ─┤ Ry(0.63166) ├─┤ Rz(0.67494) ├─■─┤ Rx(-2.4526) ├┤ Ry(0.92733) ├─»
«       ├─────────────┤ └┬────────────┤ │ ├─────────────┤├─────────────┴┐»
« q_3: ─┤ Ry(-2.4387) ├──┤ Rz(1.0119) ├─■─┤ Rx(-1.7811) ├┤ Ry(-0.34247) ├»
«       ├─────────────┤ ┌┴────────────┤   └┬────────────┤└┬────────────┬┘»
« q_4: ─┤ Ry(-3.1423) ├─┤ Rz(0.04598) ├─■──┤ Rx(2.8065) ├─┤ Ry(2.5872) ├─»
«       ├─────────────┤ ├─────────────┤ │  ├────────────┤┌┴────────────┤ »
« q_5: ─┤ Ry(-2.8761) ├─┤ Rz(-4.1579) ├─■──┤ Rx(2.9431) ├┤ Ry(0.12438) ├─»
«       └┬────────────┤ └┬───────────┬┘   ┌┴────────────┤└┬────────────┤ »
« q_6: ──┤ Ry(-3.345) ├──┤ Rz(4.625) ├──■─┤ Rx(-5.2746) ├─┤ Ry(2.1212) ├─»
«        ├────────────┤ ┌┴───────────┴┐ │ ├─────────────┤ ├────────────┤ »
« q_7: ──┤ Ry(3.1429) ├─┤ Rz(-2.3701) ├─■─┤ Rx(-8.6282) ├─┤ Ry(1.7583) ├─»
«       ┌┴────────────┤ └┬────────────┤   └┬────────────┤ ├───────────┬┘ »
« q_8: ─┤ Ry(-3.6137) ├──┤ Rz(5.0018) ├─■──┤ Rx(1.5135) ├─┤ Ry(1.982) ├──»
«      ┌┴─────────────┴┐ ├────────────┤ │ ┌┴────────────┤┌┴───────────┴┐ »
« q_9: ┤ Ry(-0.012745) ├─┤ Rz(0.5678) ├─■─┤ Rx(-2.1633) ├┤ Ry(-1.6547) ├─»
«      └─┬────────────┬┘┌┴────────────┤   └┬────────────┤└┬────────────┤ »
«q_10: ──┤ Ry(1.1315) ├─┤ Rz(-2.8665) ├─■──┤ Rx(1.6146) ├─┤ Ry(1.4761) ├─»
«       ┌┴────────────┴┐└─────────────┘ │ ┌┴────────────┤ ├────────────┤ »
«q_11: ─┤ Rz(-0.75436) ├────────────────■─┤ Rx(-3.2679) ├─┤ Ry(1.3406) ├─»
«       └──────────────┘                  └─────────────┘ └────────────┘ »
«       ┌────────────┐  ┌────────────┐ ┌────────────┐  ┌────────────┐  »
« q_0: ─┤ Rz(4.3034) ├──┤ Rx(-3.158) ├─┤ Ry(2.1567) ├──┤ Rz(1.2552) ├──»
«       ├────────────┤  └────────────┘┌┴────────────┤ ┌┴────────────┴┐ »
« q_1: ─┤ Rz(6.4126) ├────────■───────┤ Rx(-3.8927) ├─┤ Ry(-0.25189) ├─»
«      ┌┴────────────┤        │       ├─────────────┤ └┬────────────┬┘ »
« q_2: ┤ Rz(0.46874) ├────────■───────┤ Rx(-3.1411) ├──┤ Ry(3.1434) ├──»
«      └┬────────────┤                └┬────────────┤  ├────────────┤  »
« q_3: ─┤ Rz(1.9846) ├────────■────────┤ Rx(-1.032) ├──┤ Ry(2.2573) ├──»
«      ┌┴────────────┤        │        ├────────────┤ ┌┴────────────┤  »
« q_4: ┤ Rz(-3.2196) ├────────■────────┤ Rx(2.6249) ├─┤ Ry(-2.7352) ├──»
«      ├─────────────┤                 └┬─────────┬─┘ ├─────────────┤  »
« q_5: ┤ Rz(0.61245) ├────────■─────────┤ Rx(1.8) ├───┤ Ry(-4.6408) ├──»
«      └┬────────────┤        │       ┌─┴─────────┴─┐┌┴─────────────┴─┐»
« q_6: ─┤ Rz(2.7386) ├────────■───────┤ Rx(-3.1422) ├┤ Ry(-0.0017349) ├»
«       ├───────────┬┘                └┬────────────┤└┬─────────────┬─┘»
« q_7: ─┤ Rz(1.681) ├─────────■────────┤ Rx(2.6796) ├─┤ Ry(-3.7001) ├──»
«       ├───────────┴┐        │       ┌┴────────────┤ └┬────────────┤  »
« q_8: ─┤ Rz(5.3659) ├────────■───────┤ Rx(-3.1819) ├──┤ Ry(7.8562) ├──»
«      ┌┴────────────┤                └┬───────────┬┘  ├────────────┤  »
« q_9: ┤ Rz(-1.8818) ├────────■────────┤ Rx(3.472) ├───┤ Ry(3.5234) ├──»
«      ├─────────────┤        │        ├───────────┴┐ ┌┴────────────┤  »
«q_10: ┤ Rz(-2.8972) ├────────■────────┤ Rx(3.8162) ├─┤ Ry(0.14391) ├──»
«      ├─────────────┴┐┌─────────────┐ ├────────────┤ ├─────────────┤  »
«q_11: ┤ Rz(-0.09972) ├┤ Rx(0.12865) ├─┤ Ry(1.8015) ├─┤ Rz(-3.0774) ├──»
«      └──────────────┘└─────────────┘ └────────────┘ └─────────────┘  »
«                          ┌───────────┐     ┌────────────┐  ┌─────────────┐ »
« q_0: ─────────────────■──┤ Rx(2.516) ├─────┤ Ry(2.0132) ├──┤ Rz(0.20247) ├─»
«      ┌──────────────┐ │ ┌┴───────────┴┐  ┌─┴────────────┴┐ ├─────────────┤ »
« q_1: ┤ Rz(0.012523) ├─■─┤ Rx(-3.8804) ├──┤ Ry(-0.078232) ├─┤ Rz(-1.3934) ├─»
«      └┬────────────┬┘   ├─────────────┤  └─┬────────────┬┘ ├─────────────┤ »
« q_2: ─┤ Rz(1.2488) ├──■─┤ Rx(0.84871) ├────┤ Ry(1.5639) ├──┤ Rz(0.42707) ├─»
«       └┬──────────┬┘  │ ├─────────────┤    ├───────────┬┘  └┬────────────┤ »
« q_3: ──┤ Rz(3.87) ├───■─┤ Rx(-3.5875) ├────┤ Ry(3.292) ├────┤ Rz(1.4999) ├─»
«      ┌─┴──────────┴┐    └┬────────────┤   ┌┴───────────┴┐  ┌┴────────────┤ »
« q_4: ┤ Rz(-2.0803) ├──■──┤ Rx(2.6462) ├───┤ Ry(-4.8933) ├──┤ Rz(0.55247) ├─»
«      └┬────────────┤  │  ├────────────┤   ├─────────────┤  ├─────────────┴┐»
« q_5: ─┤ Rz(1.0102) ├──■──┤ Rx(1.6603) ├───┤ Ry(-1.7906) ├──┤ Rz(0.054938) ├»
«       ├────────────┤    ┌┴────────────┤ ┌─┴─────────────┴─┐└┬────────────┬┘»
« q_6: ─┤ Rz(4.6742) ├──■─┤ Rx(-3.1415) ├─┤ Ry(-7.1176e-05) ├─┤ Rz(1.2008) ├─»
«      ┌┴────────────┤  │ └┬────────────┤ └─┬─────────────┬─┘ ├────────────┤ »
« q_7: ┤ Rz(0.32278) ├──■──┤ Rx(4.0458) ├───┤ Ry(-3.9164) ├───┤ Rz(4.6444) ├─»
«      └┬────────────┤    ┌┴────────────┴┐  └┬────────────┤  ┌┴────────────┴┐»
« q_8: ─┤ Rz(2.5532) ├──■─┤ Rx(-0.12259) ├───┤ Ry(5.2213) ├──┤ Rz(-0.85323) ├»
«      ┌┴────────────┤  │ ├─────────────┬┘  ┌┴────────────┤  └┬────────────┬┘»
« q_9: ┤ Rz(-1.4186) ├──■─┤ Rx(-3.5846) ├───┤ Ry(0.32257) ├───┤ Rz(2.2312) ├─»
«      ├─────────────┤    ├─────────────┤   └┬────────────┤  ┌┴────────────┤ »
«q_10: ┤ Rz(-1.1817) ├──■─┤ Rx(-2.7185) ├────┤ Ry(2.5451) ├──┤ Rz(0.35021) ├─»
«      └─────────────┘  │ ├─────────────┴┐   ├────────────┤  └┬────────────┤ »
«q_11: ─────────────────■─┤ Rx(-0.14153) ├───┤ Ry(2.3908) ├───┤ Rz(-4.844) ├─»
«                         └──────────────┘   └────────────┘   └────────────┘ »
«      ┌─────────────┐ ┌────────────┐ ┌─────────────┐                    »
« q_0: ┤ Rx(0.58463) ├─┤ Ry(3.3206) ├─┤ Rz(-1.9819) ├──────────────────■─»
«      └─────────────┘┌┴────────────┤ └┬────────────┤ ┌──────────────┐ │ »
« q_1: ───────■───────┤ Rx(-1.5739) ├──┤ Ry(6.0189) ├─┤ Rz(-0.94181) ├─■─»
«             │       ├─────────────┤ ┌┴────────────┴┐├─────────────┬┘   »
« q_2: ───────■───────┤ Rx(-4.7035) ├─┤ Ry(-0.41075) ├┤ Rz(0.57991) ├──■─»
«                     ├─────────────┤ └┬────────────┬┘└┬────────────┤  │ »
« q_3: ───────■───────┤ Rx(-5.9287) ├──┤ Ry(3.2745) ├──┤ Rz(0.1642) ├──■─»
«             │       └┬────────────┤ ┌┴────────────┤ ┌┴────────────┤    »
« q_4: ───────■────────┤ Rx(1.7609) ├─┤ Ry(-8.9957) ├─┤ Rz(-2.8769) ├──■─»
«                      ├────────────┤ ├─────────────┤ └┬────────────┤  │ »
« q_5: ───────■────────┤ Rx(2.2659) ├─┤ Ry(-4.5277) ├──┤ Rz(1.6254) ├──■─»
«             │       ┌┴────────────┤ ├─────────────┤  ├────────────┤    »
« q_6: ───────■───────┤ Rx(-3.1418) ├─┤ Ry(-3.1415) ├──┤ Rz(3.7819) ├──■─»
«                     └┬────────────┤ └┬────────────┤ ┌┴────────────┤  │ »
« q_7: ───────■────────┤ Rx(1.8478) ├──┤ Ry(-2.657) ├─┤ Rz(0.82383) ├──■─»
«             │       ┌┴────────────┤  ├───────────┬┘ ├─────────────┤    »
« q_8: ───────■───────┤ Rx(-6.5915) ├──┤ Ry(6.416) ├──┤ Rz(-3.9151) ├──■─»
«                     ├─────────────┤ ┌┴───────────┴─┐└┬────────────┤  │ »
« q_9: ───────■───────┤ Rx(-3.6591) ├─┤ Ry(0.033607) ├─┤ Rz(2.7925) ├──■─»
«             │       ├─────────────┤ └┬───────────┬─┘┌┴────────────┴┐   »
«q_10: ───────■───────┤ Rx(-2.1723) ├──┤ Ry(1.321) ├──┤ Rz(-0.61162) ├─■─»
«      ┌─────────────┐├─────────────┴┐┌┴───────────┴┐ └──────────────┘ │ »
«q_11: ┤ Rx(-3.9013) ├┤ Ry(0.051348) ├┤ Rz(-1.8283) ├──────────────────■─»
«      └─────────────┘└──────────────┘└─────────────┘                    »
«        ┌─────────────┐    ┌─────────────┐  ┌─────────────┐┌─────────────┐»
« q_0: ──┤ Rx(-2.7919) ├────┤ Ry(-6.2821) ├──┤ Rz(0.53573) ├┤ Rx(-4.4396) ├»
«        ├─────────────┤    └┬────────────┤  ├─────────────┤└─────────────┘»
« q_1: ──┤ Rx(-3.1416) ├─────┤ Ry(3.1416) ├──┤ Rz(-1.1004) ├───────■───────»
«        ├─────────────┤     ├────────────┤  ├─────────────┤       │       »
« q_2: ──┤ Rx(-4.3592) ├─────┤ Ry(1.5436) ├──┤ Rz(-1.2285) ├───────■───────»
«        ├─────────────┤     ├────────────┤  ├─────────────┤               »
« q_3: ──┤ Rx(-3.5206) ├─────┤ Ry(2.8584) ├──┤ Rz(-2.6882) ├───────■───────»
«        └┬────────────┤   ┌─┴────────────┴─┐├─────────────┤       │       »
« q_4: ───┤ Rx(3.1419) ├───┤ Ry(-0.0012566) ├┤ Rz(-2.7544) ├───────■───────»
«        ┌┴────────────┤   └─┬───────────┬──┘└┬────────────┤               »
« q_5: ──┤ Rx(-1.5681) ├─────┤ Ry(0.631) ├────┤ Rz(4.8402) ├───────■───────»
«      ┌─┴─────────────┴─┐┌──┴───────────┴──┐┌┴────────────┤       │       »
« q_6: ┤ Rx(-0.00071401) ├┤ Ry(-0.00086668) ├┤ Rz(-0.1886) ├───────■───────»
«      └─┬─────────────┬─┘└──┬────────────┬─┘├─────────────┤               »
« q_7: ──┤ Rx(-4.0922) ├─────┤ Ry(-4.617) ├──┤ Rz(-4.4442) ├───────■───────»
«        ├─────────────┤     ├────────────┤  └┬────────────┤       │       »
« q_8: ──┤ Rx(-5.6488) ├─────┤ Ry(-5.808) ├───┤ Rz(5.4293) ├───────■───────»
«        └┬────────────┤    ┌┴────────────┤   ├────────────┤               »
« q_9: ───┤ Rx(3.6123) ├────┤ Ry(-3.1729) ├───┤ Rz(1.8759) ├───────■───────»
«         ├────────────┤    └┬────────────┤   ├────────────┤       │       »
«q_10: ───┤ Rx(4.1028) ├─────┤ Ry(2.0612) ├───┤ Rz(3.2894) ├───────■───────»
«        ┌┴────────────┤     ├────────────┤   ├───────────┬┘ ┌────────────┐»
«q_11: ──┤ Rx(-4.6075) ├─────┤ Ry(2.2446) ├───┤ Rz(1.852) ├──┤ Rx(1.2522) ├»
«        └─────────────┘     └────────────┘   └───────────┘  └────────────┘»
«      ┌─────────────┐ ┌─────────────┐                    ┌────────────┐ »
« q_0: ┤ Ry(-1.2543) ├─┤ Rz(-4.0309) ├─────────────────■──┤ Rx(4.4095) ├─»
«      ├─────────────┤ └┬────────────┤ ┌─────────────┐ │ ┌┴────────────┤ »
« q_1: ┤ Rx(-2.8557) ├──┤ Ry(4.7125) ├─┤ Rz(-1.2417) ├─■─┤ Rx(-4.5281) ├─»
«      └┬────────────┤  ├────────────┤ ├─────────────┤   └┬────────────┤ »
« q_2: ─┤ Rx(5.2838) ├──┤ Ry(1.5859) ├─┤ Rz(-6.1825) ├─■──┤ Rx(2.2441) ├─»
«      ┌┴────────────┤  ├────────────┤ └┬────────────┤ │  ├────────────┤ »
« q_3: ┤ Rx(0.43898) ├──┤ Ry(3.2983) ├──┤ Rz(4.0789) ├─■──┤ Rx(1.6449) ├─»
«      └┬────────────┤ ┌┴────────────┤ ┌┴────────────┤    ├────────────┤ »
« q_4: ─┤ Rx(3.1425) ├─┤ Ry(-3.1405) ├─┤ Rz(-1.9717) ├─■──┤ Rx(2.6354) ├─»
«      ┌┴────────────┤ ├─────────────┤ └┬────────────┤ │ ┌┴────────────┤ »
« q_5: ┤ Rx(-4.7297) ├─┤ Ry(-3.2611) ├──┤ Rz(2.2334) ├─■─┤ Rx(-3.1078) ├─»
«      ├─────────────┤ └┬────────────┤  ├────────────┤   ├─────────────┤ »
« q_6: ┤ Rx(-1.1237) ├──┤ Ry(1.8087) ├──┤ Rz(1.0567) ├─■─┤ Rx(0.86526) ├─»
«      ├─────────────┴┐ ├────────────┤ ┌┴────────────┤ │ ├─────────────┤ »
« q_7: ┤ Rx(-0.70993) ├─┤ Ry(2.1856) ├─┤ Rz(-6.3926) ├─■─┤ Rx(-2.2127) ├─»
«      └┬────────────┬┘ ├────────────┤ └┬────────────┤   ├─────────────┴┐»
« q_8: ─┤ Rx(-5.368) ├──┤ Ry(1.9686) ├──┤ Rz(3.7809) ├─■─┤ Rx(-0.95281) ├»
«       ├────────────┤ ┌┴────────────┤  ├────────────┤ │ └┬────────────┬┘»
« q_9: ─┤ Rx(3.7233) ├─┤ Ry(-1.4376) ├──┤ Rz(2.0843) ├─■──┤ Rx(2.4045) ├─»
«       ├────────────┤ ├─────────────┴┐ ├────────────┤    ├────────────┤ »
«q_10: ─┤ Rx(3.1261) ├─┤ Ry(0.077931) ├─┤ Rz(2.4726) ├─■──┤ Rx(4.7987) ├─»
«       ├────────────┤ ├─────────────┬┘ └────────────┘ │ ┌┴────────────┤ »
«q_11: ─┤ Ry(1.7804) ├─┤ Rz(-3.1171) ├─────────────────■─┤ Rx(-1.5768) ├─»
«       └────────────┘ └─────────────┘                   └─────────────┘ »
«       ┌───────────┐  ┌─────────────┐  ┌────────────┐┌─────────────┐ »
« q_0: ─┤ Ry(1.416) ├──┤ Rz(-2.3477) ├──┤ Rx(1.4522) ├┤ Ry(0.28592) ├─»
«      ┌┴───────────┴─┐├─────────────┤ ┌┴────────────┤├─────────────┤ »
« q_1: ┤ Ry(-0.65208) ├┤ Rz(-3.2634) ├─┤ Rx(-3.0254) ├┤ Ry(-1.8652) ├─»
«      └┬───────────┬─┘├─────────────┤ └┬───────────┬┘└┬────────────┤ »
« q_2: ─┤ Ry(7.952) ├──┤ Rz(-4.0009) ├──┤ Rx(6.984) ├──┤ Ry(-1.495) ├─»
«       ├───────────┴┐ └┬────────────┤ ┌┴───────────┴┐ ├────────────┤ »
« q_3: ─┤ Ry(1.5741) ├──┤ Rz(2.1205) ├─┤ Rx(-5.1111) ├─┤ Ry(1.9166) ├─»
«       ├────────────┤ ┌┴────────────┤ └┬───────────┬┘ ├────────────┤ »
« q_4: ─┤ Ry(3.7148) ├─┤ Rz(-2.0738) ├──┤ Rx(3.171) ├──┤ Ry(5.6416) ├─»
«      ┌┴────────────┤ └┬────────────┤ ┌┴───────────┴┐┌┴────────────┤ »
« q_5: ┤ Ry(-3.9266) ├──┤ Rz(1.6355) ├─┤ Rx(-2.3624) ├┤ Ry(-3.8472) ├─»
«      └┬────────────┤ ┌┴────────────┴┐└┬────────────┤└┬────────────┤ »
« q_6: ─┤ Ry(0.8991) ├─┤ Rz(-0.19752) ├─┤ Rx(6.9111) ├─┤ Ry(2.9532) ├─»
«      ┌┴────────────┤ ├─────────────┬┘┌┴────────────┤ ├────────────┤ »
« q_7: ┤ Ry(-2.4877) ├─┤ Rz(-3.9983) ├─┤ Rx(-3.6305) ├─┤ Ry(-7.287) ├─»
«      ├─────────────┤ └┬────────────┤ └┬────────────┤┌┴────────────┴┐»
« q_8: ┤ Ry(-1.1126) ├──┤ Rz(1.7278) ├──┤ Rx(1.9427) ├┤ Ry(-0.79888) ├»
«      ├─────────────┤ ┌┴────────────┤  ├────────────┤├─────────────┬┘»
« q_9: ┤ Ry(-2.2775) ├─┤ Rz(0.29252) ├──┤ Rx(1.9291) ├┤ Ry(-2.6355) ├─»
«      └┬────────────┤ ├─────────────┤  ├────────────┤└┬────────────┤ »
«q_10: ─┤ Ry(5.1138) ├─┤ Rz(-1.6304) ├──┤ Rx(2.3198) ├─┤ Ry(3.9782) ├─»
«       ├────────────┤ ├─────────────┤  ├────────────┤┌┴────────────┴┐»
«q_11: ─┤ Ry(2.5432) ├─┤ Rz(0.79727) ├──┤ Rx(-1.578) ├┤ Ry(-0.80123) ├»
«       └────────────┘ └─────────────┘  └────────────┘└──────────────┘»
«      ┌─────────────┐                                                         »
« q_0: ┤ Rz(-1.3929) ├─■────────────────────────────────■──■───────────────────»
«      ├─────────────┤ │                                │  │                   »
« q_1: ┤ Rz(-8.3862) ├─■──■────────■────────────────────┼──┼─────■────────■────»
«      └┬───────────┬┘    │        │                    │  │     │        │    »
« q_2: ─┤ Rz(11.73) ├─────■──■─────┼────────────────────┼──■──■──┼─────■──┼────»
«       ├───────────┤        │     │                    │     │  │     │  │    »
« q_3: ─┤ Rz(-1.29) ├────────■──■──■─────■──────────────┼─────┼──┼─────┼──┼────»
«       ├───────────┴┐          │        │              │     │  │     │  │    »
« q_4: ─┤ Rz(1.4972) ├──────────■──■─────┼──────────────┼─────■──┼──■──┼──■──■─»
«      ┌┴────────────┤             │     │              │        │  │  │     │ »
« q_5: ┤ Rz(-1.7582) ├─────────────■──■──■─────■────────┼────────┼──┼──■─────┼─»
«      ├─────────────┤                │        │        │        │  │        │ »
« q_6: ┤ Rz(-8.5069) ├────────────────■──■─────┼────────┼────────┼──■──■─────┼─»
«      └┬────────────┤                   │     │        │        │     │     │ »
« q_7: ─┤ Rz(4.4289) ├───────────────────■──■──■─────■──┼────────┼─────┼─────■─»
«       ├────────────┤                      │        │  │        │     │       »
« q_8: ─┤ Rz(5.6767) ├──────────────────────■──■─────┼──┼────────┼─────■──■────»
«       ├────────────┤                         │     │  │        │        │    »
« q_9: ─┤ Rz(7.2946) ├─────────────────────────■──■──■──┼──■─────┼────────┼────»
«      ┌┴────────────┤                            │     │  │     │        │    »
«q_10: ┤ Rz(-3.2751) ├────────────────────────────■──■──┼──┼─────┼────────■────»
«      └┬────────────┤                               │  │  │     │             »
«q_11: ─┤ Rz(9.6171) ├───────────────────────────────■──■──■─────■─────────────»
«       └────────────┘                                                         »
«                              
« q_0: ─■──■─────────────────■─
«       │  │                 │ 
« q_1: ─┼──┼────────■────────┼─
«       │  │        │        │ 
« q_2: ─┼──┼────────┼──■─────┼─
«       │  │        │  │     │ 
« q_3: ─┼──■──■─────┼──┼─────┼─
«       │     │     │  │     │ 
« q_4: ─┼─────┼─────┼──┼─────┼─
«       │     │     │  │     │ 
« q_5: ─┼──■──┼─────┼──┼─────┼─
«       │  │  │     │  │     │ 
« q_6: ─┼──┼──■─────┼──┼──■──┼─
«       │  │        │  │  │  │ 
« q_7: ─┼──┼──■─────┼──┼──┼──┼─
«       │  │  │     │  │  │  │ 
« q_8: ─┼──■──┼──■──┼──┼──┼──┼─
«       │     │  │  │  │  │  │ 
« q_9: ─┼─────┼──┼──┼──┼──■──■─
«       │     │  │  │  │       
«q_10: ─■─────■──┼──■──┼───────
«                │     │       
«q_11: ──────────■─────■───────
«                              
