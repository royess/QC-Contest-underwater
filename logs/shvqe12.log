Train hybrid.
----------epoch 0-----------
batched average loss:  -38.153282 minimum candidate loss:  -38.91488
probability converged
strcuture parameter: 
 [[0.40000898 1.5999911 ]
 [0.40010864 1.5998914 ]
 [0.4000098  1.5999901 ]
 [1.5999866  0.40001345]
 [1.5999914  0.40000856]
 [0.40013808 1.5998619 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-51.01987, shape=(), dtype=float32)
----------epoch 50-----------
batched average loss:  -76.20067 minimum candidate loss:  -76.20066
probability converged
strcuture parameter: 
 [[-8.881033   5.4455266]
 [-8.787145   4.928609 ]
 [-8.872768   5.383154 ]
 [ 5.1863813 -8.664048 ]
 [ 5.4620514 -8.821946 ]
 [-8.62411    4.9111776]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-76.176056, shape=(), dtype=float32)
----------epoch 100-----------
batched average loss:  -78.5921 minimum candidate loss:  -78.5921
probability converged
strcuture parameter: 
 [[-10.889346    5.4712615]
 [-10.804868    4.951315 ]
 [-10.889895    5.4085274]
 [  5.210525  -10.64092  ]
 [  5.4878645 -10.814123 ]
 [-10.609067    4.933714 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.53282, shape=(), dtype=float32)
----------epoch 150-----------
batched average loss:  -78.70959 minimum candidate loss:  -78.70958
probability converged
strcuture parameter: 
 [[-10.930292    5.471422 ]
 [-10.846012    4.951458 ]
 [-10.931033    5.4086876]
 [  5.2106757 -10.681218 ]
 [  5.4880257 -10.854733 ]
 [-10.649534    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.70515, shape=(), dtype=float32)
----------epoch 200-----------
batched average loss:  -78.72795 minimum candidate loss:  -78.72794
probability converged
strcuture parameter: 
 [[-10.956101    5.471422 ]
 [-10.871953    4.951458 ]
 [-10.956968    5.4086876]
 [  5.2106757 -10.706621 ]
 [  5.4880257 -10.880332 ]
 [-10.675038    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.728035, shape=(), dtype=float32)
----------epoch 250-----------
batched average loss:  -78.727516 minimum candidate loss:  -78.72751
probability converged
strcuture parameter: 
 [[-10.955249    5.471422 ]
 [-10.871095    4.951458 ]
 [-10.95611     5.4086876]
 [  5.2106757 -10.705783 ]
 [  5.4880257 -10.879485 ]
 [-10.674198    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72677, shape=(), dtype=float32)
----------epoch 300-----------
batched average loss:  -78.7301 minimum candidate loss:  -78.7301
probability converged
strcuture parameter: 
 [[-10.957341    5.471422 ]
 [-10.873192    4.951458 ]
 [-10.958206    5.4086876]
 [  5.2106757 -10.707843 ]
 [  5.4880257 -10.88156  ]
 [-10.676265    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73014, shape=(), dtype=float32)
----------epoch 350-----------
batched average loss:  -78.73041 minimum candidate loss:  -78.730415
probability converged
strcuture parameter: 
 [[-10.957587    5.471422 ]
 [-10.873442    4.951458 ]
 [-10.958456    5.4086876]
 [  5.2106757 -10.708084 ]
 [  5.4880257 -10.881805 ]
 [-10.676508    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730385, shape=(), dtype=float32)
----------epoch 400-----------
batched average loss:  -78.73046 minimum candidate loss:  -78.73045
probability converged
strcuture parameter: 
 [[-10.957633    5.471422 ]
 [-10.873487    4.951458 ]
 [-10.958502    5.4086876]
 [  5.2106757 -10.70813  ]
 [  5.4880257 -10.881851 ]
 [-10.676554    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730484, shape=(), dtype=float32)
----------epoch 450-----------
batched average loss:  -78.73048 minimum candidate loss:  -78.73048
probability converged
strcuture parameter: 
 [[-10.957696    5.471422 ]
 [-10.873549    4.951458 ]
 [-10.958564    5.4086876]
 [  5.2106757 -10.708192 ]
 [  5.4880257 -10.881914 ]
 [-10.676617    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730675, shape=(), dtype=float32)
----------epoch 500-----------
batched average loss:  -78.7306 minimum candidate loss:  -78.7306
probability converged
strcuture parameter: 
 [[-10.957668    5.471422 ]
 [-10.873522    4.951458 ]
 [-10.958536    5.4086876]
 [  5.2106757 -10.708166 ]
 [  5.4880257 -10.881887 ]
 [-10.67659     4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73054, shape=(), dtype=float32)
----------epoch 550-----------
batched average loss:  -78.73039 minimum candidate loss:  -78.730385
probability converged
strcuture parameter: 
 [[-10.95765     5.471422 ]
 [-10.873504    4.951458 ]
 [-10.958518    5.4086876]
 [  5.2106757 -10.708148 ]
 [  5.4880257 -10.881868 ]
 [-10.676571    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73058, shape=(), dtype=float32)
----------epoch 600-----------
batched average loss:  -78.73057 minimum candidate loss:  -78.73056
probability converged
strcuture parameter: 
 [[-10.957669    5.471422 ]
 [-10.873524    4.951458 ]
 [-10.958538    5.4086876]
 [  5.2106757 -10.708167 ]
 [  5.4880257 -10.8818865]
 [-10.67659     4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73077, shape=(), dtype=float32)
----------epoch 650-----------
batched average loss:  -78.73067 minimum candidate loss:  -78.730675
probability converged
strcuture parameter: 
 [[-10.957682    5.471422 ]
 [-10.873537    4.951458 ]
 [-10.958551    5.4086876]
 [  5.2106757 -10.708178 ]
 [  5.4880257 -10.881898 ]
 [-10.676601    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7306, shape=(), dtype=float32)
----------epoch 700-----------
batched average loss:  -78.73065 minimum candidate loss:  -78.73066
probability converged
strcuture parameter: 
 [[-10.957584    5.471422 ]
 [-10.873439    4.951458 ]
 [-10.958453    5.4086876]
 [  5.2106757 -10.70808  ]
 [  5.4880257 -10.881801 ]
 [-10.676504    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730545, shape=(), dtype=float32)
----------epoch 750-----------
batched average loss:  -78.73058 minimum candidate loss:  -78.73058
probability converged
strcuture parameter: 
 [[-10.957548    5.471422 ]
 [-10.873402    4.951458 ]
 [-10.958416    5.4086876]
 [  5.2106757 -10.708043 ]
 [  5.4880257 -10.881763 ]
 [-10.676467    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73067, shape=(), dtype=float32)
----------epoch 800-----------
batched average loss:  -78.73064 minimum candidate loss:  -78.73063
probability converged
strcuture parameter: 
 [[-10.957525    5.471422 ]
 [-10.873379    4.951458 ]
 [-10.958393    5.4086876]
 [  5.2106757 -10.708021 ]
 [  5.4880257 -10.881741 ]
 [-10.676444    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73062, shape=(), dtype=float32)
----------epoch 850-----------
batched average loss:  -78.730545 minimum candidate loss:  -78.73055
probability converged
strcuture parameter: 
 [[-10.957481    5.471422 ]
 [-10.873334    4.951458 ]
 [-10.958348    5.4086876]
 [  5.2106757 -10.707978 ]
 [  5.4880257 -10.881697 ]
 [-10.676401    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73057, shape=(), dtype=float32)
----------epoch 900-----------
batched average loss:  -78.730736 minimum candidate loss:  -78.73074
probability converged
strcuture parameter: 
 [[-10.957463    5.471422 ]
 [-10.873315    4.951458 ]
 [-10.958329    5.4086876]
 [  5.2106757 -10.707961 ]
 [  5.4880257 -10.88168  ]
 [-10.676384    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73057, shape=(), dtype=float32)
----------epoch 950-----------
batched average loss:  -78.73065 minimum candidate loss:  -78.73065
probability converged
strcuture parameter: 
 [[-10.957453    5.471422 ]
 [-10.873303    4.951458 ]
 [-10.958318    5.4086876]
 [  5.2106757 -10.707952 ]
 [  5.4880257 -10.88167  ]
 [-10.676374    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730415, shape=(), dtype=float32)
----------epoch 1000-----------
batched average loss:  -78.73064 minimum candidate loss:  -78.73063
probability converged
strcuture parameter: 
 [[-10.957401    5.471422 ]
 [-10.873253    4.951458 ]
 [-10.958267    5.4086876]
 [  5.2106757 -10.7079   ]
 [  5.4880257 -10.8816185]
 [-10.676323    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730545, shape=(), dtype=float32)
----------epoch 1050-----------
batched average loss:  -78.73065 minimum candidate loss:  -78.73066
probability converged
strcuture parameter: 
 [[-10.957414    5.471422 ]
 [-10.873265    4.951458 ]
 [-10.95828     5.4086876]
 [  5.2106757 -10.707912 ]
 [  5.4880257 -10.881631 ]
 [-10.676335    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730515, shape=(), dtype=float32)
----------epoch 1100-----------
batched average loss:  -78.73057 minimum candidate loss:  -78.73056
probability converged
strcuture parameter: 
 [[-10.957401    5.471422 ]
 [-10.873254    4.951458 ]
 [-10.958268    5.4086876]
 [  5.2106757 -10.707903 ]
 [  5.4880257 -10.881619 ]
 [-10.676325    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73062, shape=(), dtype=float32)
----------epoch 1150-----------
batched average loss:  -78.73041 minimum candidate loss:  -78.730415
probability converged
strcuture parameter: 
 [[-10.957374    5.471422 ]
 [-10.873225    4.951458 ]
 [-10.9582405   5.4086876]
 [  5.2106757 -10.707876 ]
 [  5.4880257 -10.881592 ]
 [-10.676298    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730606, shape=(), dtype=float32)
----------epoch 1200-----------
batched average loss:  -78.73053 minimum candidate loss:  -78.730515
probability converged
strcuture parameter: 
 [[-10.957383    5.471422 ]
 [-10.873235    4.951458 ]
 [-10.95825     5.4086876]
 [  5.2106757 -10.707884 ]
 [  5.4880257 -10.881601 ]
 [-10.676307    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7306, shape=(), dtype=float32)
----------epoch 1250-----------
batched average loss:  -78.73047 minimum candidate loss:  -78.73047
probability converged
strcuture parameter: 
 [[-10.957394    5.471422 ]
 [-10.873246    4.951458 ]
 [-10.958261    5.4086876]
 [  5.2106757 -10.707892 ]
 [  5.4880257 -10.88161  ]
 [-10.676315    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73067, shape=(), dtype=float32)
----------epoch 1300-----------
batched average loss:  -78.73083 minimum candidate loss:  -78.73082
probability converged
strcuture parameter: 
 [[-10.9573765   5.471422 ]
 [-10.873229    4.951458 ]
 [-10.958243    5.4086876]
 [  5.2106757 -10.707875 ]
 [  5.4880257 -10.881594 ]
 [-10.676298    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73063, shape=(), dtype=float32)
----------epoch 1350-----------
batched average loss:  -78.73053 minimum candidate loss:  -78.73053
probability converged
strcuture parameter: 
 [[-10.957361    5.471422 ]
 [-10.873214    4.951458 ]
 [-10.958228    5.4086876]
 [  5.2106757 -10.707859 ]
 [  5.4880257 -10.8815775]
 [-10.676282    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73063, shape=(), dtype=float32)
----------epoch 1400-----------
batched average loss:  -78.730484 minimum candidate loss:  -78.73049
probability converged
strcuture parameter: 
 [[-10.957347    5.471422 ]
 [-10.873199    4.951458 ]
 [-10.958214    5.4086876]
 [  5.2106757 -10.707845 ]
 [  5.4880257 -10.881563 ]
 [-10.676268    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73052, shape=(), dtype=float32)
----------epoch 1450-----------
batched average loss:  -78.73061 minimum candidate loss:  -78.73062
probability converged
strcuture parameter: 
 [[-10.957358    5.471422 ]
 [-10.873211    4.951458 ]
 [-10.958225    5.4086876]
 [  5.2106757 -10.707856 ]
 [  5.4880257 -10.881575 ]
 [-10.676279    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73061, shape=(), dtype=float32)
----------epoch 1500-----------
batched average loss:  -78.730736 minimum candidate loss:  -78.73074
probability converged
strcuture parameter: 
 [[-10.957355    5.471422 ]
 [-10.873207    4.951458 ]
 [-10.958221    5.4086876]
 [  5.2106757 -10.707852 ]
 [  5.4880257 -10.881571 ]
 [-10.676275    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73045, shape=(), dtype=float32)
----------epoch 1550-----------
batched average loss:  -78.73054 minimum candidate loss:  -78.73054
probability converged
strcuture parameter: 
 [[-10.9573555   5.471422 ]
 [-10.873209    4.951458 ]
 [-10.958223    5.4086876]
 [  5.2106757 -10.707853 ]
 [  5.4880257 -10.881572 ]
 [-10.676276    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73057, shape=(), dtype=float32)
----------epoch 1600-----------
batched average loss:  -78.730705 minimum candidate loss:  -78.7307
probability converged
strcuture parameter: 
 [[-10.957354    5.471422 ]
 [-10.873207    4.951458 ]
 [-10.958221    5.4086876]
 [  5.2106757 -10.707851 ]
 [  5.4880257 -10.881569 ]
 [-10.676273    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730316, shape=(), dtype=float32)
----------epoch 1650-----------
batched average loss:  -78.73041 minimum candidate loss:  -78.73042
probability converged
strcuture parameter: 
 [[-10.957347    5.471422 ]
 [-10.8732      4.951458 ]
 [-10.958215    5.4086876]
 [  5.2106757 -10.707846 ]
 [  5.4880257 -10.881563 ]
 [-10.676268    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730545, shape=(), dtype=float32)
----------epoch 1700-----------
batched average loss:  -78.7307 minimum candidate loss:  -78.73069
probability converged
strcuture parameter: 
 [[-10.957342    5.471422 ]
 [-10.873196    4.951458 ]
 [-10.95821     5.4086876]
 [  5.2106757 -10.70784  ]
 [  5.4880257 -10.881558 ]
 [-10.676263    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73055, shape=(), dtype=float32)
----------epoch 1750-----------
batched average loss:  -78.73057 minimum candidate loss:  -78.73056
probability converged
strcuture parameter: 
 [[-10.957333    5.471422 ]
 [-10.873186    4.951458 ]
 [-10.9582      5.4086876]
 [  5.2106757 -10.70783  ]
 [  5.4880257 -10.881549 ]
 [-10.676253    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73062, shape=(), dtype=float32)
----------epoch 1800-----------
batched average loss:  -78.73071 minimum candidate loss:  -78.73071
probability converged
strcuture parameter: 
 [[-10.957338    5.471422 ]
 [-10.873192    4.951458 ]
 [-10.958206    5.4086876]
 [  5.2106757 -10.707837 ]
 [  5.4880257 -10.881555 ]
 [-10.67626     4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730515, shape=(), dtype=float32)
----------epoch 1850-----------
batched average loss:  -78.73058 minimum candidate loss:  -78.730576
probability converged
strcuture parameter: 
 [[-10.957328    5.471422 ]
 [-10.873181    4.951458 ]
 [-10.958196    5.4086876]
 [  5.2106757 -10.707828 ]
 [  5.4880257 -10.881544 ]
 [-10.6762495   4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73074, shape=(), dtype=float32)
----------epoch 1900-----------
batched average loss:  -78.730644 minimum candidate loss:  -78.73064
probability converged
strcuture parameter: 
 [[-10.957328    5.471422 ]
 [-10.873181    4.951458 ]
 [-10.958196    5.4086876]
 [  5.2106757 -10.7078285]
 [  5.4880257 -10.881544 ]
 [-10.6762495   4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73066, shape=(), dtype=float32)
----------epoch 1950-----------
batched average loss:  -78.730774 minimum candidate loss:  -78.730774
probability converged
strcuture parameter: 
 [[-10.957321    5.471422 ]
 [-10.873175    4.951458 ]
 [-10.958189    5.4086876]
 [  5.2106757 -10.707823 ]
 [  5.4880257 -10.881537 ]
 [-10.676243    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73078, shape=(), dtype=float32)
----------epoch 1999-----------
batched average loss:  -78.7307 minimum candidate loss:  -78.73069
probability converged
strcuture parameter: 
 [[-10.957325    5.471422 ]
 [-10.8731785   4.951458 ]
 [-10.958193    5.4086876]
 [  5.2106757 -10.707827 ]
 [  5.4880257 -10.881541 ]
 [-10.676247    4.933855 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73086, shape=(), dtype=float32)
Energy: tf.Tensor(-78.73086, shape=(), dtype=float32)
Ref energy: -74.38714627
Error rate: tf.Tensor(0.029117733, shape=(), dtype=float32)
      ┌─────────────┐┌─────────────┐┌──────────────┐┌─────────────┐»
 q_0: ┤ Rx(-3.1034) ├┤ Ry(-2.6379) ├┤ Rz(0.079933) ├┤ Rx(-2.7187) ├»
      └┬────────────┤├─────────────┤└┬────────────┬┘└─────────────┘»
 q_1: ─┤ Rx(-3.151) ├┤ Ry(-3.1476) ├─┤ Rz(3.5851) ├────────■───────»
      ┌┴────────────┤├─────────────┤ ├────────────┤        │       »
 q_2: ┤ Rx(-6.1123) ├┤ Ry(-2.3847) ├─┤ Rz(2.9757) ├────────■───────»
      ├─────────────┤└┬────────────┤ ├────────────┤                »
 q_3: ┤ Rx(-3.1133) ├─┤ Ry(-0.131) ├─┤ Rz(3.1062) ├────────■───────»
      └┬────────────┤┌┴────────────┤┌┴────────────┤        │       »
 q_4: ─┤ Rx(2.0679) ├┤ Ry(-2.9955) ├┤ Rz(0.94509) ├────────■───────»
       ├────────────┤├─────────────┤├─────────────┤                »
 q_5: ─┤ Rx(3.1415) ├┤ Ry(-3.1416) ├┤ Rz(-5.0898) ├────────■───────»
      ┌┴────────────┤├─────────────┤└┬────────────┤        │       »
 q_6: ┤ Rx(-2.1079) ├┤ Ry(-1.2984) ├─┤ Rz(2.7377) ├────────■───────»
      ├─────────────┤├─────────────┤┌┴────────────┤                »
 q_7: ┤ Rx(0.08982) ├┤ Ry(-3.1569) ├┤ Rz(-3.7574) ├────────■───────»
      ├─────────────┤├─────────────┤└┬────────────┤        │       »
 q_8: ┤ Rx(-4.9088) ├┤ Ry(-5.5235) ├─┤ Rz(-3.785) ├────────■───────»
      └┬───────────┬┘├─────────────┤ ├────────────┤                »
 q_9: ─┤ Rx(1.377) ├─┤ Ry(0.28556) ├─┤ Rz(3.2346) ├────────■───────»
      ┌┴───────────┴┐└┬────────────┤┌┴────────────┴┐       │       »
q_10: ┤ Rx(0.28563) ├─┤ Ry(3.2107) ├┤ Rz(-0.36834) ├───────■───────»
      ├─────────────┤ ├────────────┤├─────────────┬┘ ┌────────────┐»
q_11: ┤ Rx(-2.1226) ├─┤ Ry(2.0843) ├┤ Rz(-2.0978) ├──┤ Rx(-3.271) ├»
      └─────────────┘ └────────────┘└─────────────┘  └────────────┘»
«       ┌───────────┐ ┌─────────────┐                  ┌─────────────┐»
« q_0: ─┤ Ry(-2.38) ├─┤ Rz(-2.7861) ├────────────────■─┤ Rx(-4.5185) ├»
«      ┌┴───────────┴┐├─────────────┤ ┌────────────┐ │ ├─────────────┤»
« q_1: ┤ Rx(-6.1334) ├┤ Ry(-3.7606) ├─┤ Rz(1.1208) ├─■─┤ Rx(-4.9519) ├»
«      ├─────────────┤├─────────────┤ ├────────────┤   └┬────────────┤»
« q_2: ┤ Rx(-3.1818) ├┤ Ry(-3.9395) ├─┤ Rz(3.6716) ├─■──┤ Rx(5.0749) ├»
«      ├─────────────┤└┬────────────┤┌┴────────────┤ │ ┌┴────────────┤»
« q_3: ┤ Rx(-5.1868) ├─┤ Ry(6.0919) ├┤ Rz(0.93438) ├─■─┤ Rx(-0.2876) ├»
«      └┬────────────┤┌┴────────────┤└┬────────────┤   └┬────────────┤»
« q_4: ─┤ Rx(1.6384) ├┤ Ry(-2.3937) ├─┤ Rz(1.7189) ├─■──┤ Rx(5.1953) ├»
«      ┌┴────────────┤├─────────────┤┌┴────────────┤ │  ├────────────┤»
« q_5: ┤ Rx(-3.2166) ├┤ Ry(-3.1389) ├┤ Rz(-2.1073) ├─■──┤ Rx(2.6985) ├»
«      └┬────────────┤├─────────────┤└┬───────────┬┘    ├────────────┤»
« q_6: ─┤ Rx(4.4853) ├┤ Ry(-2.2294) ├─┤ Rz(2.518) ├──■──┤ Rx(6.2831) ├»
«       ├────────────┤└┬────────────┤ ├───────────┴┐ │ ┌┴────────────┤»
« q_7: ─┤ Rx(3.0231) ├─┤ Ry(-3.207) ├─┤ Rz(4.8168) ├─■─┤ Rx(0.14634) ├»
«      ┌┴────────────┤┌┴────────────┤┌┴────────────┤   └┬────────────┤»
« q_8: ┤ Rx(-1.3048) ├┤ Ry(-2.7175) ├┤ Rz(0.35194) ├─■──┤ Rx(2.8467) ├»
«      └┬────────────┤├─────────────┤└┬────────────┤ │  ├───────────┬┘»
« q_9: ─┤ Rx(1.2144) ├┤ Ry(0.64806) ├─┤ Rz(1.6545) ├─■──┤ Rx(2.187) ├─»
«      ┌┴────────────┤└┬────────────┤┌┴────────────┤   ┌┴───────────┴┐»
«q_10: ┤ Rx(-3.0846) ├─┤ Ry(3.6276) ├┤ Rz(0.53186) ├─■─┤ Rx(0.22305) ├»
«      └┬────────────┤ ├────────────┤└─────────────┘ │ ├─────────────┤»
«q_11: ─┤ Ry(1.3082) ├─┤ Rz(3.0747) ├────────────────■─┤ Rx(-1.6727) ├»
«       └────────────┘ └────────────┘                  └─────────────┘»
«       ┌─────────────┐   ┌───────────┐   ┌────────────┐  ┌─────────────┐  »
« q_0: ─┤ Ry(-3.4887) ├───┤ Rz(1.373) ├───┤ Rx(-4.747) ├──┤ Ry(-2.0618) ├──»
«       └┬────────────┤   ├───────────┴┐  └────────────┘  ├─────────────┤  »
« q_1: ──┤ Ry(1.7429) ├───┤ Rz(2.3263) ├────────■─────────┤ Rx(-2.6664) ├──»
«        ├────────────┤   ├────────────┤        │         └┬────────────┤  »
« q_2: ──┤ Ry(-2.198) ├───┤ Rz(1.6896) ├────────■──────────┤ Rx(5.0045) ├──»
«        ├────────────┤  ┌┴────────────┴┐                 ┌┴────────────┤  »
« q_3: ──┤ Ry(3.9959) ├──┤ Rz(-0.89262) ├───────■─────────┤ Rx(-3.4206) ├──»
«       ┌┴────────────┤  ├─────────────┬┘       │         └┬────────────┤  »
« q_4: ─┤ Ry(-1.8705) ├──┤ Rz(-1.8221) ├────────■──────────┤ Rx(3.1074) ├──»
«       ├─────────────┤ ┌┴─────────────┴┐                  ├────────────┤  »
« q_5: ─┤ Ry(-3.1529) ├─┤ Rz(-0.026398) ├───────■──────────┤ Rx(1.6939) ├──»
«       ├─────────────┤ └┬─────────────┬┘       │       ┌──┴────────────┴─┐»
« q_6: ─┤ Ry(-6.2833) ├──┤ Rz(0.67478) ├────────■───────┤ Rx(-0.00010289) ├»
«      ┌┴─────────────┴┐ ├─────────────┤                └─┬──────────────┬┘»
« q_7: ┤ Ry(-0.011013) ├─┤ Rz(-1.3285) ├────────■─────────┤ Rx(-0.12479) ├─»
«      └─┬────────────┬┘ └┬────────────┤        │         ├─────────────┬┘ »
« q_8: ──┤ Ry(3.3912) ├───┤ Rz(3.6335) ├────────■─────────┤ Rx(-6.5587) ├──»
«       ┌┴────────────┤   ├────────────┤                  ├─────────────┤  »
« q_9: ─┤ Ry(-2.7237) ├───┤ Rz(2.2809) ├────────■─────────┤ Rx(0.58462) ├──»
«       └┬────────────┤   ├────────────┤        │         ├─────────────┤  »
«q_10: ──┤ Ry(3.2906) ├───┤ Rz(1.8484) ├────────■─────────┤ Rx(-4.6923) ├──»
«        ├────────────┤   ├────────────┤ ┌─────────────┐  └┬────────────┤  »
«q_11: ──┤ Ry(2.0542) ├───┤ Rz(2.6726) ├─┤ Rx(-1.5201) ├───┤ Ry(3.5199) ├──»
«        └────────────┘   └────────────┘ └─────────────┘   └────────────┘  »
«       ┌────────────┐                    ┌─────────────┐   ┌────────────┐ »
« q_0: ─┤ Rz(2.8868) ├────────────────■───┤ Rx(-1.7687) ├───┤ Ry(1.6295) ├─»
«       ├───────────┬┘ ┌───────────┐  │   ├─────────────┴┐ ┌┴────────────┤ »
« q_1: ─┤ Ry(4.377) ├──┤ Rz(1.361) ├──■───┤ Rx(-0.37003) ├─┤ Ry(0.88654) ├─»
«      ┌┴───────────┴┐ ├───────────┴┐     ├──────────────┤ ├─────────────┤ »
« q_2: ┤ Ry(-8.4635) ├─┤ Rz(4.3461) ├─■───┤ Rx(-0.10443) ├─┤ Ry(-6.2687) ├─»
«      ├─────────────┤ ├────────────┤ │   ├─────────────┬┘ ├─────────────┴┐»
« q_3: ┤ Ry(-3.4853) ├─┤ Rz(1.8725) ├─■───┤ Rx(-1.7691) ├──┤ Ry(0.035632) ├»
«      ├─────────────┤┌┴────────────┤     └┬───────────┬┘  └┬───────────┬─┘»
« q_4: ┤ Ry(-6.2519) ├┤ Rz(-0.5094) ├─■────┤ Rx(3.153) ├────┤ Ry(6.272) ├──»
«      ├─────────────┤├─────────────┤ │    ├───────────┴┐   ├───────────┴┐ »
« q_5: ┤ Ry(-5.0249) ├┤ Rz(-4.1085) ├─■────┤ Rx(2.9622) ├───┤ Ry(3.0531) ├─»
«      ├─────────────┤└┬────────────┤   ┌──┴────────────┴─┐┌┴────────────┤ »
« q_6: ┤ Ry(-3.1416) ├─┤ Rz(4.8443) ├─■─┤ Rx(-1.9721e-05) ├┤ Ry(-3.1417) ├─»
«      └┬────────────┤┌┴────────────┤ │ └──┬───────────┬──┘└┬────────────┤ »
« q_7: ─┤ Ry(3.0354) ├┤ Rz(-7.5987) ├─■────┤ Rx(6.161) ├────┤ Ry(-2.405) ├─»
«      ┌┴────────────┤├─────────────┤     ┌┴───────────┴─┐ ┌┴────────────┤ »
« q_8: ┤ Ry(-8.9902) ├┤ Rz(-8.5205) ├─■───┤ Rx(-0.61756) ├─┤ Ry(-8.1366) ├─»
«      ├─────────────┤└┬────────────┤ │   └┬────────────┬┘ ├─────────────┴┐»
« q_9: ┤ Ry(-1.4086) ├─┤ Rz(5.2621) ├─■────┤ Rx(3.0698) ├──┤ Ry(-0.64227) ├»
«      └┬────────────┤┌┴────────────┤      ├────────────┤  └┬────────────┬┘»
«q_10: ─┤ Ry(3.0525) ├┤ Rz(-1.1555) ├─■────┤ Rx(3.2147) ├───┤ Ry(7.4685) ├─»
«       ├────────────┤└─────────────┘ │   ┌┴────────────┤   ├───────────┬┘ »
«q_11: ─┤ Rz(2.6627) ├────────────────■───┤ Rx(-3.6216) ├───┤ Ry(2.212) ├──»
«       └────────────┘                    └─────────────┘   └───────────┘  »
«       ┌────────────┐┌─────────────┐┌─────────────┐    ┌────────────┐  »
« q_0: ─┤ Rz(1.6135) ├┤ Rx(0.25844) ├┤ Ry(0.91462) ├────┤ Rz(1.8212) ├──»
«       ├────────────┤└─────────────┘├─────────────┤    ├────────────┤  »
« q_1: ─┤ Rz(1.1266) ├───────■───────┤ Rx(-3.2773) ├────┤ Ry(4.5579) ├──»
«      ┌┴────────────┤       │       ├─────────────┤    ├────────────┤  »
« q_2: ┤ Rz(-1.1049) ├───────■───────┤ Rx(-5.0917) ├────┤ Ry(2.6867) ├──»
«      └┬────────────┤               ├─────────────┤    ├────────────┤  »
« q_3: ─┤ Rz(3.5883) ├───────■───────┤ Rx(-3.6919) ├────┤ Ry(1.8599) ├──»
«      ┌┴────────────┤       │       └┬───────────┬┘ ┌──┴────────────┴─┐»
« q_4: ┤ Rz(-4.4958) ├───────■────────┤ Rx(3.141) ├──┤ Ry(-0.00040644) ├»
«      └┬────────────┤                ├───────────┴┐ └─┬─────────────┬─┘»
« q_5: ─┤ Rz(3.8786) ├───────■────────┤ Rx(3.8969) ├───┤ Ry(-4.7727) ├──»
«      ┌┴────────────┤       │       ┌┴────────────┤   ├─────────────┤  »
« q_6: ┤ Rz(-1.5968) ├───────■───────┤ Rx(-3.1415) ├───┤ Ry(-3.1416) ├──»
«      ├─────────────┤               └┬────────────┤   ├─────────────┤  »
« q_7: ┤ Rz(-1.9613) ├───────■────────┤ Rx(1.5827) ├───┤ Ry(-5.1355) ├──»
«      ├─────────────┤       │       ┌┴────────────┤   └┬────────────┤  »
« q_8: ┤ Rz(-8.1155) ├───────■───────┤ Rx(-6.0824) ├────┤ Ry(2.7552) ├──»
«      ├─────────────┤               ├─────────────┴┐  ┌┴────────────┤  »
« q_9: ┤ Rz(-2.5346) ├───────■───────┤ Rx(-0.18713) ├──┤ Ry(-3.2698) ├──»
«      └┬────────────┤       │       └─┬──────────┬─┘  └┬────────────┤  »
«q_10: ─┤ Rz(1.4016) ├───────■─────────┤ Rx(3.07) ├─────┤ Ry(2.9576) ├──»
«      ┌┴────────────┤┌─────────────┐ ┌┴──────────┤     ├────────────┤  »
«q_11: ┤ Rz(-3.6885) ├┤ Rx(-3.0948) ├─┤ Ry(1.011) ├─────┤ Rz(2.5204) ├──»
«      └─────────────┘└─────────────┘ └───────────┘     └────────────┘  »
«                        ┌─────────────┐ ┌──────────────┐ ┌────────────┐»
« q_0: ────────────────■─┤ Rx(-3.0371) ├─┤ Ry(-0.66471) ├─┤ Rz(3.8635) ├»
«       ┌────────────┐ │ ├─────────────┤ └┬────────────┬┘┌┴────────────┤»
« q_1: ─┤ Rz(3.5103) ├─■─┤ Rx(-3.6087) ├──┤ Ry(3.2649) ├─┤ Rz(-4.4379) ├»
«       ├────────────┤   ├─────────────┤  ├────────────┤ └┬────────────┤»
« q_2: ─┤ Rz(6.1357) ├─■─┤ Rx(-3.2374) ├──┤ Ry(2.2198) ├──┤ Rz(1.9113) ├»
«       ├────────────┤ │ ├─────────────┤  ├────────────┤  ├────────────┤»
« q_3: ─┤ Rz(1.5469) ├─■─┤ Rx(0.42003) ├──┤ Ry(6.0472) ├──┤ Rz(3.6559) ├»
«      ┌┴────────────┤   ├─────────────┤  ├────────────┤ ┌┴────────────┤»
« q_4: ┤ Rz(-3.6907) ├─■─┤ Rx(-3.5486) ├──┤ Ry(6.9195) ├─┤ Rz(-4.5568) ├»
«      └┬────────────┤ │ └┬────────────┤ ┌┴────────────┤ └┬────────────┤»
« q_5: ─┤ Rz(3.8883) ├─■──┤ Rx(1.6025) ├─┤ Ry(-3.3764) ├──┤ Rz(4.9621) ├»
«      ┌┴────────────┤   ┌┴────────────┤ ├─────────────┤ ┌┴────────────┤»
« q_6: ┤ Rz(-2.2745) ├─■─┤ Rx(-3.1459) ├─┤ Ry(0.92749) ├─┤ Rz(-3.0296) ├»
«      ├─────────────┤ │ └┬────────────┤ ├─────────────┤ ├─────────────┤»
« q_7: ┤ Rz(-2.1208) ├─■──┤ Rx(2.8765) ├─┤ Ry(-2.6332) ├─┤ Rz(-1.0859) ├»
«      ├─────────────┤   ┌┴────────────┤ └┬────────────┤ ├─────────────┤»
« q_8: ┤ Rz(0.29196) ├─■─┤ Rx(-6.6782) ├──┤ Ry(4.4245) ├─┤ Rz(-3.8113) ├»
«      └┬────────────┤ │ ├─────────────┤ ┌┴────────────┤ └┬────────────┤»
« q_9: ─┤ Rz(1.2119) ├─■─┤ Rx(-3.0678) ├─┤ Ry(-6.8466) ├──┤ Rz(3.7398) ├»
«      ┌┴────────────┤   ├─────────────┴┐└┬────────────┤  ├────────────┤»
«q_10: ┤ Rz(-3.2004) ├─■─┤ Rx(-0.43168) ├─┤ Ry(4.5448) ├──┤ Rz(5.5101) ├»
«      └─────────────┘ │ ├─────────────┬┘ ├────────────┤ ┌┴────────────┤»
«q_11: ────────────────■─┤ Rx(-2.5712) ├──┤ Ry(0.1721) ├─┤ Rz(0.95526) ├»
«                        └─────────────┘  └────────────┘ └─────────────┘»
«       ┌────────────┐┌─────────────┐  ┌───────────┐                    »
« q_0: ─┤ Rx(1.9383) ├┤ Ry(-4.4429) ├──┤ Rz(7.004) ├──────────────────■─»
«       └────────────┘├─────────────┤ ┌┴───────────┴┐ ┌─────────────┐ │ »
« q_1: ───────■───────┤ Rx(-2.4924) ├─┤ Ry(-1.5245) ├─┤ Rz(-5.4604) ├─■─»
«             │       ├─────────────┤ └┬────────────┤ ├─────────────┤   »
« q_2: ───────■───────┤ Rx(-2.1173) ├──┤ Ry(-3.245) ├─┤ Rz(-1.9234) ├─■─»
«                     ├─────────────┤ ┌┴────────────┤ └┬────────────┤ │ »
« q_3: ───────■───────┤ Rx(-3.4558) ├─┤ Ry(0.61366) ├──┤ Rz(3.8344) ├─■─»
«             │       ├─────────────┤ ├─────────────┴┐┌┴────────────┤   »
« q_4: ───────■───────┤ Rx(-1.3187) ├─┤ Ry(-0.25087) ├┤ Rz(-3.6273) ├─■─»
«                     └┬────────────┤ ├─────────────┬┘└┬────────────┤ │ »
« q_5: ───────■────────┤ Rx(3.1414) ├─┤ Ry(-3.1415) ├──┤ Rz(2.5695) ├─■─»
«             │       ┌┴────────────┤ ├─────────────┤  ├────────────┤   »
« q_6: ───────■───────┤ Rx(-3.2965) ├─┤ Ry(-4.0599) ├──┤ Rz(6.5951) ├─■─»
«                     └┬────────────┤ ├─────────────┴┐┌┴────────────┤ │ »
« q_7: ───────■────────┤ Rx(2.2293) ├─┤ Ry(-0.13834) ├┤ Rz(0.92539) ├─■─»
«             │       ┌┴────────────┴┐└┬────────────┬┘├─────────────┤   »
« q_8: ───────■───────┤ Rx(-0.37015) ├─┤ Ry(2.8737) ├─┤ Rz(-1.9753) ├─■─»
«                     ├─────────────┬┘┌┴────────────┤ ├─────────────┤ │ »
« q_9: ───────■───────┤ Rx(-3.1177) ├─┤ Ry(-3.3915) ├─┤ Rz(0.92744) ├─■─»
«             │       ├─────────────┤ └┬────────────┤ └┬────────────┤   »
«q_10: ───────■───────┤ Rx(-2.6917) ├──┤ Ry(3.1038) ├──┤ Rz(5.3406) ├─■─»
«      ┌─────────────┐├─────────────┤  ├────────────┤  └────────────┘ │ »
«q_11: ┤ Rx(-3.3713) ├┤ Ry(0.55146) ├──┤ Rz(3.5932) ├─────────────────■─»
«      └─────────────┘└─────────────┘  └────────────┘                   »
«      ┌─────────────┐ ┌─────────────┐  ┌────────────┐ ┌─────────────┐»
« q_0: ┤ Rx(0.66014) ├─┤ Ry(-3.8805) ├──┤ Rz(0.1399) ├─┤ Rx(-3.8832) ├»
«      ├─────────────┴┐├─────────────┴┐┌┴────────────┤ └─────────────┘»
« q_1: ┤ Rx(-0.12243) ├┤ Ry(-0.87229) ├┤ Rz(-5.8942) ├────────■───────»
«      ├─────────────┬┘├──────────────┤├─────────────┴┐       │       »
« q_2: ┤ Rx(-1.2065) ├─┤ Ry(-0.88152) ├┤ Rz(-0.32284) ├───────■───────»
«      ├─────────────┤ └┬────────────┬┘└┬────────────┬┘               »
« q_3: ┤ Rx(0.13662) ├──┤ Ry(3.0974) ├──┤ Rz(3.9662) ├────────■───────»
«      ├─────────────┴┐ ├────────────┤ ┌┴────────────┤        │       »
« q_4: ┤ Rx(-0.91281) ├─┤ Ry(2.0376) ├─┤ Rz(-4.7565) ├────────■───────»
«      └┬────────────┬┘ ├────────────┤ └┬────────────┤                »
« q_5: ─┤ Rx(4.9615) ├──┤ Ry(4.1955) ├──┤ Rz(3.1205) ├────────■───────»
«       ├────────────┤ ┌┴────────────┤  ├────────────┤        │       »
« q_6: ─┤ Rx(3.1416) ├─┤ Ry(-6.2831) ├──┤ Rz(3.7545) ├────────■───────»
«       ├────────────┤ ├─────────────┤  ├────────────┤                »
« q_7: ─┤ Rx(6.0883) ├─┤ Ry(-2.9122) ├──┤ Rz(3.3127) ├────────■───────»
«      ┌┴────────────┤ ├─────────────┤ ┌┴────────────┤        │       »
« q_8: ┤ Rx(-2.6942) ├─┤ Ry(0.28894) ├─┤ Rz(-1.8273) ├────────■───────»
«      └┬────────────┤ └┬────────────┤ └┬────────────┤                »
« q_9: ─┤ Rx(2.7501) ├──┤ Ry(-1.982) ├──┤ Rz(5.8489) ├────────■───────»
«       ├────────────┤ ┌┴────────────┴┐ └┬──────────┬┘        │       »
«q_10: ─┤ Rx(1.5019) ├─┤ Ry(-0.38317) ├──┤ Rz(3.47) ├─────────■───────»
«      ┌┴────────────┤ ├──────────────┤ ┌┴──────────┴┐  ┌────────────┐»
«q_11: ┤ Rx(-1.4947) ├─┤ Ry(-0.69424) ├─┤ Rz(1.5072) ├──┤ Rx(-6.035) ├»
«      └─────────────┘ └──────────────┘ └────────────┘  └────────────┘»
«      ┌─────────────┐ ┌─────────────┐                     ┌─────────────┐  »
« q_0: ┤ Ry(0.25957) ├─┤ Rz(-4.6705) ├─────────────────■───┤ Rx(-5.1527) ├──»
«      ├─────────────┤ ├─────────────┴┐┌─────────────┐ │   ├─────────────┤  »
« q_1: ┤ Rx(-7.8463) ├─┤ Ry(0.027832) ├┤ Rz(0.76426) ├─■───┤ Rx(-4.3171) ├──»
«      ├─────────────┤┌┴──────────────┤└┬────────────┤     ├─────────────┤  »
« q_2: ┤ Rx(-6.1648) ├┤ Ry(-0.023471) ├─┤ Rz(2.3018) ├─■───┤ Rx(0.51197) ├──»
«      ├─────────────┤└─┬────────────┬┘ ├────────────┤ │   ├─────────────┤  »
« q_3: ┤ Rx(-6.3731) ├──┤ Ry(5.8417) ├──┤ Rz(2.3979) ├─■───┤ Rx(0.12829) ├──»
«      └┬────────────┤ ┌┴────────────┤ ┌┴────────────┤     └┬────────────┤  »
« q_4: ─┤ Rx(1.0668) ├─┤ Ry(-3.9119) ├─┤ Rz(-3.5552) ├─■────┤ Rx(5.9585) ├──»
«      ┌┴────────────┤ ├─────────────┴┐└┬────────────┤ │   ┌┴────────────┤  »
« q_5: ┤ Rx(-1.4463) ├─┤ Ry(-0.19413) ├─┤ Rz(4.4805) ├─■───┤ Rx(-3.1413) ├──»
«      └┬────────────┤ ├─────────────┬┘┌┴────────────┤     ├─────────────┤  »
« q_6: ─┤ Rx(1.5763) ├─┤ Ry(-1.3621) ├─┤ Rz(-1.2908) ├─■───┤ Rx(-0.9731) ├──»
«       ├────────────┤ └┬────────────┤ ├─────────────┤ │ ┌─┴─────────────┴─┐»
« q_7: ─┤ Rx(2.9981) ├──┤ Ry(2.2989) ├─┤ Rz(-2.3388) ├─■─┤ Rx(-6.1762e-05) ├»
«      ┌┴────────────┤ ┌┴────────────┤ └┬────────────┤   └──┬────────────┬─┘»
« q_8: ┤ Rx(-4.0874) ├─┤ Ry(-1.0186) ├──┤ Rz(-2.402) ├─■────┤ Rx(3.9997) ├──»
«      ├─────────────┤ └┬────────────┤ ┌┴────────────┤ │    ├────────────┤  »
« q_9: ┤ Rx(-6.9972) ├──┤ Ry(-4.081) ├─┤ Rz(0.63137) ├─■────┤ Rx(3.1382) ├──»
«      └┬────────────┤  ├────────────┤ └┬────────────┤      └┬──────────┬┘  »
«q_10: ─┤ Rx(6.0848) ├──┤ Ry(3.9398) ├──┤ Rz(3.0301) ├─■─────┤ Rx(2.91) ├───»
«       ├────────────┤  ├────────────┤  └────────────┘ │   ┌─┴──────────┴┐  »
«q_11: ─┤ Ry(1.5104) ├──┤ Rz(5.2976) ├─────────────────■───┤ Rx(-1.5682) ├──»
«       └────────────┘  └────────────┘                     └─────────────┘  »
«       ┌────────────┐ ┌─────────────┐┌──────────────┐ ┌────────────┐»
« q_0: ─┤ Ry(2.3849) ├─┤ Rz(-3.1705) ├┤ Rx(-0.83145) ├─┤ Ry(1.2812) ├»
«       ├────────────┤ └┬────────────┤└──────────────┘┌┴────────────┤»
« q_1: ─┤ Ry(5.4925) ├──┤ Rz(1.1837) ├───────■────────┤ Rx(-4.7413) ├»
«       ├────────────┤  ├────────────┤       │        ├─────────────┤»
« q_2: ─┤ Ry(3.8265) ├──┤ Rz(1.6937) ├───────■────────┤ Rx(-2.3337) ├»
«       ├────────────┤  ├────────────┤                └┬────────────┤»
« q_3: ─┤ Ry(0.2758) ├──┤ Rz(3.3975) ├───────■─────────┤ Rx(2.0076) ├»
«       ├────────────┤ ┌┴────────────┤       │         ├────────────┤»
« q_4: ─┤ Ry(3.1576) ├─┤ Rz(-4.6458) ├───────■─────────┤ Rx(2.7282) ├»
«      ┌┴────────────┤ └┬────────────┤                ┌┴────────────┤»
« q_5: ┤ Ry(-3.1415) ├──┤ Rz(4.1831) ├───────■────────┤ Rx(-3.1415) ├»
«      ├─────────────┤  ├────────────┤       │        └┬────────────┤»
« q_6: ┤ Ry(-5.9139) ├──┤ Rz(3.7017) ├───────■─────────┤ Rx(8.6414) ├»
«      ├─────────────┤  ├───────────┬┘                ┌┴────────────┤»
« q_7: ┤ Ry(-3.1447) ├──┤ Rz(2.171) ├────────■────────┤ Rx(-2.6333) ├»
«      ├─────────────┴┐┌┴───────────┴┐       │        ├─────────────┤»
« q_8: ┤ Ry(-0.90605) ├┤ Rz(-4.1039) ├───────■────────┤ Rx(-3.7727) ├»
«      ├──────────────┤└┬────────────┤                └┬───────────┬┘»
« q_9: ┤ Ry(-0.32586) ├─┤ Rz(1.3664) ├───────■─────────┤ Rx(3.148) ├─»
«      ├─────────────┬┘┌┴────────────┤       │         ├───────────┴┐»
«q_10: ┤ Ry(-2.2002) ├─┤ Rz(0.62043) ├───────■─────────┤ Rx(2.4442) ├»
«      └┬────────────┤ └┬────────────┤ ┌────────────┐  ├────────────┤»
«q_11: ─┤ Ry(1.7813) ├──┤ Rz(1.5158) ├─┤ Rx(1.5825) ├──┤ Ry(1.5132) ├»
«       └────────────┘  └────────────┘ └────────────┘  └────────────┘»
«      ┌─────────────┐                   ┌─────────────┐┌─────────────┐»
« q_0: ┤ Rz(-3.0962) ├─────────────────■─┤ Rx(-1.8475) ├┤ Ry(-3.9034) ├»
«      ├─────────────┴┐ ┌────────────┐ │ ├─────────────┤└┬───────────┬┘»
« q_1: ┤ Ry(-0.85359) ├─┤ Rz(3.1598) ├─■─┤ Rx(-4.3423) ├─┤ Ry(6.597) ├─»
«      └┬────────────┬┘ ├────────────┤   ├─────────────┤ ├───────────┴┐»
« q_2: ─┤ Ry(-6.368) ├──┤ Rz(2.8845) ├─■─┤ Rx(-2.0382) ├─┤ Ry(4.1222) ├»
«       ├────────────┤ ┌┴────────────┤ │ ├─────────────┤┌┴────────────┤»
« q_3: ─┤ Ry(3.1985) ├─┤ Rz(0.48385) ├─■─┤ Rx(-5.9483) ├┤ Ry(-3.0025) ├»
«       ├────────────┤ ├─────────────┤   ├─────────────┤├─────────────┤»
« q_4: ─┤ Ry(3.1136) ├─┤ Rz(-4.4399) ├─■─┤ Rx(0.70795) ├┤ Ry(-0.4028) ├»
«       ├────────────┤ ├─────────────┤ │ ├─────────────┤└┬────────────┤»
« q_5: ─┤ Ry(3.1416) ├─┤ Rz(-5.0913) ├─■─┤ Rx(-2.7552) ├─┤ Ry(1.8468) ├»
«      ┌┴────────────┴┐└┬────────────┤   └┬────────────┤┌┴────────────┤»
« q_6: ┤ Ry(-0.64702) ├─┤ Rz(3.1063) ├─■──┤ Rx(1.8512) ├┤ Ry(-6.9188) ├»
«      └┬────────────┬┘ ├────────────┤ │ ┌┴────────────┤├─────────────┤»
« q_7: ─┤ Ry(-7.855) ├──┤ Rz(2.9154) ├─■─┤ Rx(-2.9764) ├┤ Ry(-2.6188) ├»
«      ┌┴────────────┤ ┌┴────────────┤   ├─────────────┤├─────────────┤»
« q_8: ┤ Ry(-1.5573) ├─┤ Rz(0.47458) ├─■─┤ Rx(-1.8278) ├┤ Ry(-1.4942) ├»
«      ├─────────────┤ └┬────────────┤ │ └┬────────────┤├─────────────┤»
« q_9: ┤ Ry(-3.0996) ├──┤ Rz(2.2098) ├─■──┤ Rx(1.7151) ├┤ Ry(-1.0856) ├»
«      ├─────────────┴┐ ├────────────┤   ┌┴────────────┤└┬────────────┤»
«q_10: ┤ Ry(-0.63911) ├─┤ Rz(5.0464) ├─■─┤ Rx(0.46259) ├─┤ Ry(2.9001) ├»
«      └┬────────────┬┘ └────────────┘ │ ├─────────────┤ ├────────────┤»
«q_11: ─┤ Rz(1.6687) ├─────────────────■─┤ Rx(-2.4007) ├─┤ Ry(2.6056) ├»
«       └────────────┘                   └─────────────┘ └────────────┘»
«       ┌────────────┐ ┌───────────┐ ┌─────────────┐ ┌─────────────┐          »
« q_0: ─┤ Rz(-4.092) ├─┤ Rx(1.651) ├─┤ Ry(-1.2682) ├─┤ Rz(0.45597) ├──■───────»
«       ├────────────┤┌┴───────────┴┐└┬────────────┤ ├─────────────┴┐ │       »
« q_1: ─┤ Rz(2.8289) ├┤ Rx(-5.7958) ├─┤ Ry(3.3149) ├─┤ Rz(-0.68532) ├─■──■────»
«       ├────────────┤└┬────────────┤ ├────────────┤ └┬────────────┬┘    │    »
« q_2: ─┤ Rz(4.7338) ├─┤ Rx(-2.283) ├─┤ Ry(4.1314) ├──┤ Rz(2.5629) ├─────■──■─»
«       ├───────────┬┘┌┴────────────┤ ├────────────┤ ┌┴────────────┴┐       │ »
« q_3: ─┤ Rz(4.967) ├─┤ Rx(0.23388) ├─┤ Ry(2.6139) ├─┤ Rz(-0.21155) ├───────■─»
«       ├───────────┴┐├─────────────┤┌┴────────────┤ └┬────────────┬┘         »
« q_4: ─┤ Rz(1.5557) ├┤ Rx(-2.2464) ├┤ Ry(-5.5522) ├──┤ Rz(3.7087) ├──────────»
«      ┌┴────────────┤├─────────────┤└┬────────────┤  ├───────────┬┘          »
« q_5: ┤ Rz(-3.1002) ├┤ Rx(-4.0732) ├─┤ Ry(4.2754) ├──┤ Rz(1.781) ├───────────»
«      ├─────────────┤└┬────────────┤┌┴────────────┤  ├───────────┴┐          »
« q_6: ┤ Rz(-2.2243) ├─┤ Rx(5.5294) ├┤ Ry(-2.2837) ├──┤ Rz(6.4714) ├──────────»
«      └┬────────────┤┌┴────────────┤├─────────────┴┐┌┴────────────┤          »
« q_7: ─┤ Rz(7.8068) ├┤ Rx(-1.0077) ├┤ Ry(-0.23869) ├┤ Rz(-1.0868) ├──────────»
«      ┌┴────────────┤├─────────────┤├──────────────┤└┬────────────┤          »
« q_8: ┤ Rz(-2.3226) ├┤ Rx(-3.1119) ├┤ Ry(0.074268) ├─┤ Rz(1.5174) ├──────────»
«      ├─────────────┤└┬────────────┤└┬────────────┬┘┌┴────────────┤          »
« q_9: ┤ Rz(-4.7839) ├─┤ Rx(4.4102) ├─┤ Ry(1.4937) ├─┤ Rz(-10.155) ├──────────»
«      └┬────────────┤ ├────────────┤ ├────────────┤ ├─────────────┤          »
«q_10: ─┤ Rz(3.9407) ├─┤ Rx(4.2026) ├─┤ Ry(1.7288) ├─┤ Rz(-2.6903) ├──────────»
«      ┌┴────────────┤┌┴────────────┤ ├───────────┬┘ ├─────────────┴┐         »
«q_11: ┤ Rz(0.89803) ├┤ Rx(-2.9458) ├─┤ Ry(2.274) ├──┤ Rz(-0.94493) ├─────────»
«      └─────────────┘└─────────────┘ └───────────┘  └──────────────┘         »
«                                                                       »
« q_0: ─────────────────────────■──■────────────────────■───────■───────»
«                               │  │                    │       │       »
« q_1: ────■────────────────────┼──┼─────■────────■─────┼───────┼───────»
«          │                    │  │     │        │     │       │       »
« q_2: ────┼────────────────────┼──■──■──┼─────■──┼─────┼───────┼───────»
«          │                    │     │  │     │  │     │       │       »
« q_3: ─■──■─────■──────────────┼─────┼──┼─────┼──┼─────┼───────■───────»
«       │        │              │     │  │     │  │     │ ┌────────────┐»
« q_4: ─■──■─────┼──────────────┼─────■──┼──■──┼──■──■──┼─┤ Rx(3.1435) ├»
«          │     │              │        │  │  │     │  │ └────────────┘»
« q_5: ────■──■──■─────■────────┼────────┼──┼──■─────┼──┼───────■───────»
«             │        │        │        │  │        │  │       │       »
« q_6: ───────■──■─────┼────────┼────────┼──■──■─────┼──┼───────┼───────»
«                │     │        │        │     │     │  │       │       »
« q_7: ──────────■──■──■─────■──┼────────┼─────┼─────■──┼───────┼───────»
«                   │        │  │        │     │        │       │       »
« q_8: ─────────────■──■─────┼──┼────────┼─────■──■─────┼───────■───────»
«                      │     │  │        │        │     │               »
« q_9: ────────────────■──■──■──┼──■─────┼────────┼─────┼───────────────»
«                         │     │  │     │        │     │               »
«q_10: ───────────────────■──■──┼──┼─────┼────────■─────■───────────────»
«                            │  │  │     │                              »
«q_11: ──────────────────────■──■──■─────■──────────────────────────────»
«                                                                       »
«                                                                             »
« q_0: ───────────────────────────────────────────────────────────────────────»
«                                           ┌─────────────┐ ┌───────────────┐ »
« q_1: ───────────────────────────────────■─┤ Rx(-3.1407) ├─┤ Ry(-0.016634) ├─»
«                                         │ └─────────────┘ └─┬────────────┬┘ »
« q_2: ───────────────────────────────────┼────────■──────────┤ Rx(3.7335) ├──»
«                                         │        │          ├────────────┤  »
« q_3: ──────────────────────────■────────┼────────┼──────────┤ Rx(3.1441) ├──»
«          ┌──────────┐          │        │        │         ┌┴────────────┤  »
« q_4: ────┤ Ry(3.14) ├──────────┼────────┼────────┼─────────┤ Rz(-1.8568) ├──»
«      ┌───┴──────────┴──┐       │        │        │       ┌─┴─────────────┴─┐»
« q_5: ┤ Rx(-6.6469e-06) ├───────┼────────┼────────┼───────┤ Ry(-4.8147e-05) ├»
«      └─────────────────┘       │        │        │       └─────────────────┘»
« q_6: ──────────────────────────■────────┼────────┼──────────────────────────»
«                         ┌─────────────┐ │        │        ┌────────────────┐»
« q_7: ─────────■─────────┤ Rx(-3.1417) ├─┼────────┼────────┤ Ry(9.9601e-05) ├»
«               │         └─────────────┘ │        │        ├────────────────┤»
« q_8: ─────────┼────────────────■────────┼────────┼────────┤ Rx(7.4859e-06) ├»
«               │                │        │        │        └────────────────┘»
« q_9: ─────────┼────────────────┼────────┼────────┼──────────────────────────»
«               │                │        │        │       ┌─────────────────┐»
«q_10: ─────────■────────────────┼────────■────────┼───────┤ Rx(-1.5835e-05) ├»
«                                │                 │       └──┬────────────┬─┘»
«q_11: ──────────────────────────■─────────────────■──────────┤ Rx(3.1416) ├──»
«                                                             └────────────┘  »
«                                          ┌────────────┐┌─────────────┐»
« q_0: ─────────────────────────────────■──┤ Rx(3.0814) ├┤ Ry(0.18616) ├»
«       ┌────────────┐                  │  └────────────┘└─────────────┘»
« q_1: ─┤ Rz(4.7967) ├──────────────────┼───────────────────────────────»
«      ┌┴────────────┤ ┌─────────────┐  │                               »
« q_2: ┤ Ry(-4.6495) ├─┤ Rz(-4.6721) ├──┼───────────────────────────────»
«      ├─────────────┤ └┬───────────┬┘  │                               »
« q_3: ┤ Ry(-3.1413) ├──┤ Rz(5.554) ├───┼───────────────────────────────»
«      └─────────────┘  └───────────┘   │                               »
« q_4: ─────────────────────────────────┼───────────────────────────────»
«      ┌─────────────┐                  │                               »
« q_5: ┤ Rz(-1.6548) ├──────────────────┼───────────────────────────────»
«      └─────────────┘┌───────────────┐ │ ┌─────────────┐ ┌────────────┐»
« q_6: ───────■───────┤ Rx(0.0001424) ├─┼─┤ Ry(-6.2831) ├─┤ Rz(2.4482) ├»
«             │       └─┬────────────┬┘ │ └─────────────┘ └────────────┘»
« q_7: ───────┼─────────┤ Rz(3.6354) ├──┼───────────────────────────────»
«             │        ┌┴────────────┤  │  ┌────────────┐               »
« q_8: ───────┼────────┤ Ry(-3.1416) ├──┼──┤ Rz(2.7536) ├───────────────»
«             │        └─────────────┘  │  ├───────────┬┘┌─────────────┐»
« q_9: ───────■─────────────────────────■──┤ Rx(3.141) ├─┤ Ry(-3.1417) ├»
«       ┌────────────┐  ┌───────────┐      └───────────┘ └─────────────┘»
«q_10: ─┤ Ry(3.1416) ├──┤ Rz(3.355) ├───────────────────────────────────»
«      ┌┴────────────┤ ┌┴───────────┴┐                                  »
«q_11: ┤ Ry(-3.1416) ├─┤ Rz(-4.5085) ├──────────────────────────────────»
«      └─────────────┘ └─────────────┘                                  »
«       ┌────────────┐
« q_0: ─┤ Rz(0.2862) ├
«       └────────────┘
« q_1: ───────────────
«                     
« q_2: ───────────────
«                     
« q_3: ───────────────
«                     
« q_4: ───────────────
«                     
« q_5: ───────────────
«                     
« q_6: ───────────────
«                     
« q_7: ───────────────
«                     
« q_8: ───────────────
«      ┌─────────────┐
« q_9: ┤ Rz(-6.8228) ├
«      └─────────────┘
«q_10: ───────────────
«                     
«q_11: ───────────────
«                     
