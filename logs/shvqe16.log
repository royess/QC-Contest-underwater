Train hybrid.
----------epoch 0-----------
batched average loss:  -42.45841 minimum candidate loss:  -42.91959
probability converged
strcuture parameter: 
 [[0.40000826 1.5999918 ]
 [0.40002978 1.5999702 ]
 [0.40000874 1.5999913 ]
 [1.5999851  0.40001488]
 [1.5999918  0.40000826]
 [0.4000495  1.5999506 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-51.365734, shape=(), dtype=float32)
----------epoch 50-----------
batched average loss:  -75.183044 minimum candidate loss:  -75.183044
probability converged
strcuture parameter: 
 [[-9.222325   5.6360765]
 [-9.053136   4.9963193]
 [-9.187724   5.5792084]
 [ 5.1812143 -9.010888 ]
 [ 5.6061425 -9.147599 ]
 [-8.948985   4.912632 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-75.67682, shape=(), dtype=float32)
----------epoch 100-----------
batched average loss:  -78.65272 minimum candidate loss:  -78.652725
probability converged
strcuture parameter: 
 [[-12.506596    5.6631994]
 [-12.35547     5.0202518]
 [-12.47405     5.606027 ]
 [  5.205842  -12.264494 ]
 [  5.633054  -12.403593 ]
 [-12.212525    4.9360104]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.64678, shape=(), dtype=float32)
----------epoch 150-----------
batched average loss:  -78.72882 minimum candidate loss:  -78.72882
probability converged
strcuture parameter: 
 [[-12.651634    5.66337  ]
 [-12.501298    5.020402 ]
 [-12.619163    5.6061945]
 [  5.2059965 -12.408248 ]
 [  5.633222  -12.547421 ]
 [-12.356704    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.70847, shape=(), dtype=float32)
----------epoch 200-----------
batched average loss:  -78.72345 minimum candidate loss:  -78.72344
probability converged
strcuture parameter: 
 [[-12.672119    5.66337  ]
 [-12.521893    5.020402 ]
 [-12.63966     5.6061945]
 [  5.2059965 -12.428549 ]
 [  5.633222  -12.567732 ]
 [-12.377063    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73775, shape=(), dtype=float32)
----------epoch 250-----------
batched average loss:  -78.74678 minimum candidate loss:  -78.74679
probability converged
strcuture parameter: 
 [[-12.683983    5.66337  ]
 [-12.533822    5.020402 ]
 [-12.651533    5.6061945]
 [  5.2059965 -12.440307 ]
 [  5.633222  -12.5794935]
 [-12.388857    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74688, shape=(), dtype=float32)
----------epoch 300-----------
batched average loss:  -78.74743 minimum candidate loss:  -78.74742
probability converged
strcuture parameter: 
 [[-12.684565    5.66337  ]
 [-12.534406    5.020402 ]
 [-12.652115    5.6061945]
 [  5.2059965 -12.440881 ]
 [  5.633222  -12.580068 ]
 [-12.389433    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74734, shape=(), dtype=float32)
----------epoch 350-----------
batched average loss:  -78.74769 minimum candidate loss:  -78.74769
probability converged
strcuture parameter: 
 [[-12.6847105   5.66337  ]
 [-12.534553    5.020402 ]
 [-12.652262    5.6061945]
 [  5.2059965 -12.441024 ]
 [  5.633222  -12.580211 ]
 [-12.389576    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.747635, shape=(), dtype=float32)
----------epoch 400-----------
batched average loss:  -78.74758 minimum candidate loss:  -78.74759
probability converged
strcuture parameter: 
 [[-12.684745    5.66337  ]
 [-12.534588    5.020402 ]
 [-12.652297    5.6061945]
 [  5.2059965 -12.441057 ]
 [  5.633222  -12.580244 ]
 [-12.38961     4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74767, shape=(), dtype=float32)
----------epoch 450-----------
batched average loss:  -78.7477 minimum candidate loss:  -78.74771
probability converged
strcuture parameter: 
 [[-12.684736    5.66337  ]
 [-12.534579    5.020402 ]
 [-12.652288    5.6061945]
 [  5.2059965 -12.441049 ]
 [  5.633222  -12.5802355]
 [-12.389602    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7478, shape=(), dtype=float32)
----------epoch 500-----------
batched average loss:  -78.747795 minimum candidate loss:  -78.747795
probability converged
strcuture parameter: 
 [[-12.684759    5.66337  ]
 [-12.534602    5.020402 ]
 [-12.652311    5.6061945]
 [  5.2059965 -12.4410715]
 [  5.633222  -12.580258 ]
 [-12.389625    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.747696, shape=(), dtype=float32)
----------epoch 550-----------
batched average loss:  -78.747734 minimum candidate loss:  -78.747734
probability converged
strcuture parameter: 
 [[-12.6848135   5.66337  ]
 [-12.534657    5.020402 ]
 [-12.652366    5.6061945]
 [  5.2059965 -12.441126 ]
 [  5.633222  -12.580313 ]
 [-12.38968     4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74771, shape=(), dtype=float32)
----------epoch 600-----------
batched average loss:  -78.74774 minimum candidate loss:  -78.74776
probability converged
strcuture parameter: 
 [[-12.684952    5.66337  ]
 [-12.534797    5.020402 ]
 [-12.652504    5.6061945]
 [  5.2059965 -12.441262 ]
 [  5.633222  -12.580449 ]
 [-12.389818    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74782, shape=(), dtype=float32)
----------epoch 650-----------
batched average loss:  -78.747826 minimum candidate loss:  -78.74783
probability converged
strcuture parameter: 
 [[-12.684955    5.66337  ]
 [-12.534801    5.020402 ]
 [-12.652507    5.6061945]
 [  5.2059965 -12.441265 ]
 [  5.633222  -12.580452 ]
 [-12.389821    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7478, shape=(), dtype=float32)
----------epoch 700-----------
batched average loss:  -78.74776 minimum candidate loss:  -78.747765
probability converged
strcuture parameter: 
 [[-12.684988    5.66337  ]
 [-12.534835    5.020402 ]
 [-12.65254     5.6061945]
 [  5.2059965 -12.441297 ]
 [  5.633222  -12.580483 ]
 [-12.389853    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74798, shape=(), dtype=float32)
----------epoch 750-----------
batched average loss:  -78.74786 minimum candidate loss:  -78.747856
probability converged
strcuture parameter: 
 [[-12.684979    5.66337  ]
 [-12.534825    5.020402 ]
 [-12.652531    5.6061945]
 [  5.2059965 -12.441289 ]
 [  5.633222  -12.580476 ]
 [-12.389845    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74785, shape=(), dtype=float32)
----------epoch 800-----------
batched average loss:  -78.74797 minimum candidate loss:  -78.74796
probability converged
strcuture parameter: 
 [[-12.685087    5.66337  ]
 [-12.534934    5.020402 ]
 [-12.652638    5.6061945]
 [  5.2059965 -12.441393 ]
 [  5.633222  -12.58058  ]
 [-12.389952    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74774, shape=(), dtype=float32)
----------epoch 850-----------
batched average loss:  -78.74791 minimum candidate loss:  -78.7479
probability converged
strcuture parameter: 
 [[-12.685067    5.66337  ]
 [-12.534915    5.020402 ]
 [-12.652618    5.6061945]
 [  5.2059965 -12.441375 ]
 [  5.633222  -12.580562 ]
 [-12.389933    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74792, shape=(), dtype=float32)
----------epoch 900-----------
batched average loss:  -78.74769 minimum candidate loss:  -78.747696
probability converged
strcuture parameter: 
 [[-12.68506     5.66337  ]
 [-12.534909    5.020402 ]
 [-12.652612    5.6061945]
 [  5.2059965 -12.441367 ]
 [  5.633222  -12.580554 ]
 [-12.389925    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74787, shape=(), dtype=float32)
----------epoch 950-----------
batched average loss:  -78.74793 minimum candidate loss:  -78.74794
probability converged
strcuture parameter: 
 [[-12.685034    5.66337  ]
 [-12.5348835   5.020402 ]
 [-12.652586    5.6061945]
 [  5.2059965 -12.441342 ]
 [  5.633222  -12.580528 ]
 [-12.389899    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74792, shape=(), dtype=float32)
----------epoch 1000-----------
batched average loss:  -78.74794 minimum candidate loss:  -78.74795
probability converged
strcuture parameter: 
 [[-12.685035    5.66337  ]
 [-12.534883    5.020402 ]
 [-12.652587    5.6061945]
 [  5.2059965 -12.441343 ]
 [  5.633222  -12.580529 ]
 [-12.3899      4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.747955, shape=(), dtype=float32)
----------epoch 1050-----------
batched average loss:  -78.74776 minimum candidate loss:  -78.747765
probability converged
strcuture parameter: 
 [[-12.68506     5.66337  ]
 [-12.534907    5.020402 ]
 [-12.652612    5.6061945]
 [  5.2059965 -12.441367 ]
 [  5.633222  -12.580553 ]
 [-12.389925    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7478, shape=(), dtype=float32)
----------epoch 1100-----------
batched average loss:  -78.747696 minimum candidate loss:  -78.7477
probability converged
strcuture parameter: 
 [[-12.685092    5.66337  ]
 [-12.53494     5.020402 ]
 [-12.652644    5.6061945]
 [  5.2059965 -12.4414   ]
 [  5.633222  -12.5805855]
 [-12.389957    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7478, shape=(), dtype=float32)
----------epoch 1150-----------
batched average loss:  -78.747795 minimum candidate loss:  -78.747795
probability converged
strcuture parameter: 
 [[-12.685099    5.66337  ]
 [-12.534946    5.020402 ]
 [-12.652651    5.6061945]
 [  5.2059965 -12.441407 ]
 [  5.633222  -12.580593 ]
 [-12.389965    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74793, shape=(), dtype=float32)
----------epoch 1200-----------
batched average loss:  -78.74781 minimum candidate loss:  -78.74782
probability converged
strcuture parameter: 
 [[-12.685106    5.66337  ]
 [-12.534954    5.020402 ]
 [-12.652658    5.6061945]
 [  5.2059965 -12.441416 ]
 [  5.633222  -12.580602 ]
 [-12.389974    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.747795, shape=(), dtype=float32)
----------epoch 1250-----------
batched average loss:  -78.74798 minimum candidate loss:  -78.74798
probability converged
strcuture parameter: 
 [[-12.685078    5.66337  ]
 [-12.534925    5.020402 ]
 [-12.65263     5.6061945]
 [  5.2059965 -12.441386 ]
 [  5.633222  -12.580572 ]
 [-12.389944    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.747795, shape=(), dtype=float32)
----------epoch 1300-----------
batched average loss:  -78.748024 minimum candidate loss:  -78.74802
probability converged
strcuture parameter: 
 [[-12.685072    5.66337  ]
 [-12.53492     5.020402 ]
 [-12.652624    5.6061945]
 [  5.2059965 -12.4413805]
 [  5.633222  -12.580566 ]
 [-12.389938    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74793, shape=(), dtype=float32)
----------epoch 1350-----------
batched average loss:  -78.74787 minimum candidate loss:  -78.74788
probability converged
strcuture parameter: 
 [[-12.68508     5.66337  ]
 [-12.534927    5.020402 ]
 [-12.652632    5.6061945]
 [  5.2059965 -12.441388 ]
 [  5.633222  -12.580574 ]
 [-12.389946    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74778, shape=(), dtype=float32)
----------epoch 1400-----------
batched average loss:  -78.74804 minimum candidate loss:  -78.74804
probability converged
strcuture parameter: 
 [[-12.68507     5.66337  ]
 [-12.534917    5.020402 ]
 [-12.652622    5.6061945]
 [  5.2059965 -12.441379 ]
 [  5.633222  -12.5805645]
 [-12.389936    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74781, shape=(), dtype=float32)
----------epoch 1450-----------
batched average loss:  -78.748024 minimum candidate loss:  -78.74802
probability converged
strcuture parameter: 
 [[-12.685083    5.66337  ]
 [-12.53493     5.020402 ]
 [-12.652636    5.6061945]
 [  5.2059965 -12.441392 ]
 [  5.633222  -12.580578 ]
 [-12.38995     4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74807, shape=(), dtype=float32)
----------epoch 1500-----------
batched average loss:  -78.747826 minimum candidate loss:  -78.74783
probability converged
strcuture parameter: 
 [[-12.685073    5.66337  ]
 [-12.53492     5.020402 ]
 [-12.652625    5.6061945]
 [  5.2059965 -12.4413805]
 [  5.633222  -12.580566 ]
 [-12.389938    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.747795, shape=(), dtype=float32)
----------epoch 1550-----------
batched average loss:  -78.74787 minimum candidate loss:  -78.74787
probability converged
strcuture parameter: 
 [[-12.685077    5.66337  ]
 [-12.534924    5.020402 ]
 [-12.652629    5.6061945]
 [  5.2059965 -12.441383 ]
 [  5.633222  -12.580569 ]
 [-12.389941    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74787, shape=(), dtype=float32)
----------epoch 1600-----------
batched average loss:  -78.747826 minimum candidate loss:  -78.74783
probability converged
strcuture parameter: 
 [[-12.685061    5.66337  ]
 [-12.534908    5.020402 ]
 [-12.652614    5.6061945]
 [  5.2059965 -12.441368 ]
 [  5.633222  -12.580554 ]
 [-12.389926    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74787, shape=(), dtype=float32)
----------epoch 1650-----------
batched average loss:  -78.747986 minimum candidate loss:  -78.74799
probability converged
strcuture parameter: 
 [[-12.685079    5.66337  ]
 [-12.534926    5.020402 ]
 [-12.652631    5.6061945]
 [  5.2059965 -12.441385 ]
 [  5.633222  -12.580571 ]
 [-12.389943    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74797, shape=(), dtype=float32)
----------epoch 1700-----------
batched average loss:  -78.74788 minimum candidate loss:  -78.74789
probability converged
strcuture parameter: 
 [[-12.68507     5.66337  ]
 [-12.534919    5.020402 ]
 [-12.652622    5.6061945]
 [  5.2059965 -12.441377 ]
 [  5.633222  -12.580563 ]
 [-12.389935    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7478, shape=(), dtype=float32)
----------epoch 1750-----------
batched average loss:  -78.7477 minimum candidate loss:  -78.74771
probability converged
strcuture parameter: 
 [[-12.685053    5.66337  ]
 [-12.534902    5.020402 ]
 [-12.652605    5.6061945]
 [  5.2059965 -12.4413595]
 [  5.633222  -12.580545 ]
 [-12.389917    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.747955, shape=(), dtype=float32)
----------epoch 1800-----------
batched average loss:  -78.7478 minimum candidate loss:  -78.7478
probability converged
strcuture parameter: 
 [[-12.68507     5.66337  ]
 [-12.534919    5.020402 ]
 [-12.652622    5.6061945]
 [  5.2059965 -12.441376 ]
 [  5.633222  -12.580563 ]
 [-12.389935    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74789, shape=(), dtype=float32)
----------epoch 1850-----------
batched average loss:  -78.747826 minimum candidate loss:  -78.74783
probability converged
strcuture parameter: 
 [[-12.685068    5.66337  ]
 [-12.534917    5.020402 ]
 [-12.65262     5.6061945]
 [  5.2059965 -12.441374 ]
 [  5.633222  -12.580561 ]
 [-12.389933    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74805, shape=(), dtype=float32)
----------epoch 1900-----------
batched average loss:  -78.74768 minimum candidate loss:  -78.74768
probability converged
strcuture parameter: 
 [[-12.685064    5.66337  ]
 [-12.534913    5.020402 ]
 [-12.6526165   5.6061945]
 [  5.2059965 -12.441372 ]
 [  5.633222  -12.580559 ]
 [-12.389931    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.747856, shape=(), dtype=float32)
----------epoch 1950-----------
batched average loss:  -78.74786 minimum candidate loss:  -78.74785
probability converged
strcuture parameter: 
 [[-12.685067    5.66337  ]
 [-12.534916    5.020402 ]
 [-12.652619    5.6061945]
 [  5.2059965 -12.441376 ]
 [  5.633222  -12.580563 ]
 [-12.389935    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74783, shape=(), dtype=float32)
----------epoch 1999-----------
batched average loss:  -78.7479 minimum candidate loss:  -78.747894
probability converged
strcuture parameter: 
 [[-12.685063    5.66337  ]
 [-12.534912    5.020402 ]
 [-12.652616    5.6061945]
 [  5.2059965 -12.441371 ]
 [  5.633222  -12.580558 ]
 [-12.389931    4.9361567]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.74805, shape=(), dtype=float32)
Energy: tf.Tensor(-78.74805, shape=(), dtype=float32)
Ref energy: -74.38714627
Error rate: tf.Tensor(0.006010212, shape=(), dtype=float32)
       ┌─────────────┐  ┌────────────┐ ┌────────────┐ ┌────────────┐»
 q_0: ─┤ Rx(-3.9725) ├──┤ Ry(1.2696) ├─┤ Rz(4.7246) ├─┤ Rx(-5.409) ├»
       ├─────────────┤ ┌┴────────────┤ ├────────────┤ └────────────┘»
 q_1: ─┤ Rx(-1.9199) ├─┤ Ry(-4.5631) ├─┤ Rz(1.1274) ├───────■───────»
       ├─────────────┴┐├─────────────┤ ├────────────┤       │       »
 q_2: ─┤ Rx(0.019718) ├┤ Ry(-3.3363) ├─┤ Rz(-3.051) ├───────■───────»
       └┬────────────┬┘└┬────────────┤ ├────────────┤               »
 q_3: ──┤ Rx(-4.291) ├──┤ Ry(5.2934) ├─┤ Rz(-2.854) ├───────■───────»
      ┌─┴────────────┴┐┌┴────────────┤ ├───────────┬┘       │       »
 q_4: ┤ Rx(-0.081668) ├┤ Ry(-2.9478) ├─┤ Rz(6.855) ├────────■───────»
      └─┬────────────┬┘├─────────────┤┌┴───────────┴┐               »
 q_5: ──┤ Rx(4.7384) ├─┤ Ry(-1.0437) ├┤ Rz(-1.5618) ├───────■───────»
       ┌┴────────────┤ └┬───────────┬┘└┬────────────┤       │       »
 q_6: ─┤ Rx(-3.1423) ├──┤ Ry(-3.14) ├──┤ Rz(3.9897) ├───────■───────»
       └┬────────────┤  ├───────────┴┐┌┴────────────┤               »
 q_7: ──┤ Rx(3.2104) ├──┤ Ry(3.1766) ├┤ Rz(0.99137) ├───────■───────»
       ┌┴────────────┤ ┌┴────────────┤└┬────────────┤       │       »
 q_8: ─┤ Rx(-2.1937) ├─┤ Ry(-3.5357) ├─┤ Rz(2.3568) ├───────■───────»
       ├─────────────┤ └┬───────────┬┘┌┴────────────┴┐              »
 q_9: ─┤ Rx(-3.4292) ├──┤ Ry(6.065) ├─┤ Rz(-0.40052) ├──────■───────»
       ├─────────────┤  ├───────────┴┐├─────────────┬┘      │       »
q_10: ─┤ Rx(-1.5023) ├──┤ Ry(5.5913) ├┤ Rz(-2.0976) ├───────■───────»
       └┬────────────┤  ├────────────┤└┬────────────┤ ┌────────────┐»
q_11: ──┤ Rx(4.4734) ├──┤ Ry(3.5487) ├─┤ Rz(1.8808) ├─┤ Rx(2.3799) ├»
        └────────────┘  └────────────┘ └────────────┘ └────────────┘»
«       ┌────────────┐┌─────────────┐                    ┌─────────────┐ »
« q_0: ─┤ Ry(-1.521) ├┤ Rz(-7.0204) ├──────────────────■─┤ Rx(-1.0563) ├─»
«      ┌┴────────────┤├─────────────┤  ┌────────────┐  │ ├─────────────┤ »
« q_1: ┤ Rx(-1.8587) ├┤ Ry(-1.4252) ├──┤ Rz(1.9591) ├──■─┤ Rx(-3.1954) ├─»
«      └┬────────────┤├─────────────┤ ┌┴────────────┤    ├─────────────┴┐»
« q_2: ─┤ Rx(-6.289) ├┤ Ry(0.20625) ├─┤ Rz(-2.4414) ├──■─┤ Rx(-0.97368) ├»
«      ┌┴────────────┤├─────────────┤ ├─────────────┤  │ ├─────────────┬┘»
« q_3: ┤ Rx(-4.9478) ├┤ Ry(0.58438) ├─┤ Rz(-2.2987) ├──■─┤ Rx(-3.1416) ├─»
«      ├─────────────┤├─────────────┤ └┬───────────┬┘    └┬────────────┤ »
« q_4: ┤ Rx(-3.1506) ├┤ Ry(-3.1947) ├──┤ Rz(3.681) ├───■──┤ Rx(1.2816) ├─»
«      └┬────────────┤├─────────────┤ ┌┴───────────┴─┐ │  ├────────────┤ »
« q_5: ─┤ Rx(4.2257) ├┤ Ry(-4.7512) ├─┤ Rz(-0.59852) ├─■──┤ Rx(3.2558) ├─»
«       ├────────────┤├─────────────┤ ├─────────────┬┘    ├────────────┤ »
« q_6: ─┤ Rx(1.4225) ├┤ Ry(-4.5953) ├─┤ Rz(0.68761) ├──■──┤ Rx(1.8621) ├─»
«       ├────────────┤├─────────────┤ └┬────────────┤  │ ┌┴────────────┤ »
« q_7: ─┤ Rx(3.4166) ├┤ Ry(0.18582) ├──┤ Rz(2.9658) ├──■─┤ Rx(0.15511) ├─»
«      ┌┴────────────┤├─────────────┴┐ ├────────────┤    ├─────────────┴┐»
« q_8: ┤ Rx(-5.4926) ├┤ Ry(-0.21804) ├─┤ Rz(-4.711) ├──■─┤ Rx(0.095651) ├»
«      ├─────────────┤└┬────────────┬┘┌┴────────────┤  │ ├─────────────┬┘»
« q_9: ┤ Rx(0.23598) ├─┤ Ry(6.4704) ├─┤ Rz(-4.6201) ├──■─┤ Rx(-3.3777) ├─»
«      ├─────────────┤┌┴────────────┴┐└┬────────────┤    ├─────────────┤ »
«q_10: ┤ Rx(-2.1238) ├┤ Ry(-0.11235) ├─┤ Rz(6.7613) ├──■─┤ Rx(-2.2778) ├─»
«      └┬────────────┤└┬────────────┬┘ └────────────┘  │ └┬────────────┤ »
«q_11: ─┤ Ry(5.0179) ├─┤ Rz(2.8017) ├──────────────────■──┤ Rx(3.6966) ├─»
«       └────────────┘ └────────────┘                     └────────────┘ »
«       ┌────────────┐  ┌───────────┐ ┌─────────────┐ ┌─────────────┐  »
« q_0: ─┤ Ry(-3.279) ├──┤ Rz(1.833) ├─┤ Rx(-4.2827) ├─┤ Ry(0.26603) ├──»
«      ┌┴────────────┤ ┌┴───────────┴┐└─────────────┘ └┬────────────┤  »
« q_1: ┤ Ry(-3.4491) ├─┤ Rz(-1.0932) ├───────■─────────┤ Rx(6.8946) ├──»
«      ├─────────────┤ ├─────────────┤       │         ├────────────┤  »
« q_2: ┤ Ry(-1.1832) ├─┤ Rz(-3.2443) ├───────■─────────┤ Rx(1.9599) ├──»
«      └┬────────────┤ ├─────────────┤                ┌┴────────────┤  »
« q_3: ─┤ Ry(3.1415) ├─┤ Rz(-1.3508) ├───────■────────┤ Rx(-5.4487) ├──»
«      ┌┴────────────┤ └┬────────────┤       │        ├─────────────┤  »
« q_4: ┤ Ry(-3.0695) ├──┤ Rz(2.9555) ├───────■────────┤ Rx(-1.8552) ├──»
«      ├─────────────┤ ┌┴────────────┤                └┬────────────┤  »
« q_5: ┤ Ry(-4.0335) ├─┤ Rz(0.37889) ├───────■─────────┤ Rx(2.3299) ├──»
«      ├─────────────┤ └┬────────────┤       │        ┌┴────────────┤  »
« q_6: ┤ Ry(-6.2665) ├──┤ Rz(4.9075) ├───────■────────┤ Rx(-5.4333) ├──»
«      ├─────────────┤ ┌┴────────────┤                └┬────────────┤  »
« q_7: ┤ Ry(-6.3358) ├─┤ Rz(-8.7738) ├───────■─────────┤ Rx(3.0424) ├──»
«      ├─────────────┤ └┬────────────┤       │         ├────────────┤  »
« q_8: ┤ Ry(-2.0137) ├──┤ Rz(3.5021) ├───────■─────────┤ Rx(2.9899) ├──»
«      ├─────────────┤  ├───────────┬┘                ┌┴────────────┴┐ »
« q_9: ┤ Ry(-1.6146) ├──┤ Rz(3.188) ├────────■────────┤ Rx(-0.75879) ├─»
«      └┬────────────┤  ├───────────┴┐       │        ├──────────────┤ »
«q_10: ─┤ Ry(1.2326) ├──┤ Rz(1.9745) ├───────■────────┤ Rx(-0.31704) ├─»
«      ┌┴────────────┴┐┌┴────────────┤ ┌────────────┐┌┴──────────────┴┐»
«q_11: ┤ Ry(-0.64998) ├┤ Rz(0.77101) ├─┤ Rx(2.3136) ├┤ Ry(-0.0016587) ├»
«      └──────────────┘└─────────────┘ └────────────┘└────────────────┘»
«      ┌──────────────┐                  ┌─────────────┐ ┌─────────────┐ »
« q_0: ┤ Rz(-0.97279) ├────────────────■─┤ Rx(-1.0795) ├─┤ Ry(0.14311) ├─»
«      ├─────────────┬┘┌─────────────┐ │ └┬────────────┤┌┴─────────────┴┐»
« q_1: ┤ Ry(0.14841) ├─┤ Rz(-1.4672) ├─■──┤ Rx(6.3201) ├┤ Ry(-0.078261) ├»
«      ├─────────────┤ └┬────────────┤    ├────────────┤└┬─────────────┬┘»
« q_2: ┤ Ry(0.66588) ├──┤ Rz(-1.381) ├─■──┤ Rx(8.0315) ├─┤ Ry(-2.4772) ├─»
«      └┬────────────┤  ├────────────┤ │ ┌┴────────────┤ └┬────────────┤ »
« q_3: ─┤ Ry(1.5978) ├──┤ Rz(5.2484) ├─■─┤ Rx(-2.4887) ├──┤ Ry(3.2289) ├─»
«      ┌┴────────────┤ ┌┴────────────┤   ├─────────────┤ ┌┴────────────┤ »
« q_4: ┤ Ry(0.19455) ├─┤ Rz(-2.2661) ├─■─┤ Rx(-3.1414) ├─┤ Ry(-3.1417) ├─»
«      ├─────────────┤ └┬────────────┤ │ ├─────────────┤ └┬────────────┤ »
« q_5: ┤ Ry(-5.7268) ├──┤ Rz(5.1469) ├─■─┤ Rx(0.61448) ├──┤ Ry(-1.381) ├─»
«      ├─────────────┤  ├────────────┤   └┬────────────┤ ┌┴────────────┴┐»
« q_6: ┤ Ry(-3.7666) ├──┤ Rz(3.1897) ├─■──┤ Rx(4.9783) ├─┤ Ry(-0.38936) ├»
«      └┬────────────┤ ┌┴────────────┤ │  ├────────────┤ └┬────────────┬┘»
« q_7: ─┤ Ry(5.9283) ├─┤ Rz(-1.3696) ├─■──┤ Rx(1.2921) ├──┤ Ry(1.5942) ├─»
«      ┌┴────────────┤ └┬────────────┤    ├────────────┤ ┌┴────────────┤ »
« q_8: ┤ Ry(-3.0288) ├──┤ Rz(7.4548) ├─■──┤ Rx(3.1691) ├─┤ Ry(-3.1517) ├─»
«      └┬────────────┤  ├────────────┤ │ ┌┴────────────┤ ├─────────────┤ »
« q_9: ─┤ Ry(5.8004) ├──┤ Rz(7.8176) ├─■─┤ Rx(0.14059) ├─┤ Ry(-6.2992) ├─»
«       ├────────────┤ ┌┴────────────┤   └┬────────────┤ └┬────────────┤ »
«q_10: ─┤ Ry(8.0836) ├─┤ Rz(-9.0203) ├─■──┤ Rx(1.3149) ├──┤ Ry(7.2821) ├─»
«      ┌┴────────────┤ └─────────────┘ │  ├────────────┤  ├────────────┤ »
«q_11: ┤ Rz(-6.5985) ├─────────────────■──┤ Rx(4.8582) ├──┤ Ry(4.8321) ├─»
«      └─────────────┘                    └────────────┘  └────────────┘ »
«      ┌─────────────┐┌────────────┐ ┌────────────┐ ┌───────────────┐»
« q_0: ┤ Rz(-4.3731) ├┤ Rx(3.0258) ├─┤ Ry(2.1938) ├─┤ Rz(-0.098915) ├»
«      └┬────────────┤└────────────┘┌┴────────────┤ └─┬────────────┬┘»
« q_1: ─┤ Rz(6.4623) ├──────■───────┤ Rx(0.18187) ├───┤ Ry(3.3281) ├─»
«       ├───────────┬┘      │       ├─────────────┤   ├────────────┤ »
« q_2: ─┤ Rz(8.782) ├───────■───────┤ Rx(-3.3583) ├───┤ Ry(9.3519) ├─»
«       ├───────────┴┐              ├─────────────┤   ├────────────┤ »
« q_3: ─┤ Rz(8.0926) ├──────■───────┤ Rx(-1.9499) ├───┤ Ry(8.2879) ├─»
«       ├───────────┬┘      │       └┬────────────┤  ┌┴────────────┤ »
« q_4: ─┤ Rz(1.433) ├───────■────────┤ Rx(3.1415) ├──┤ Ry(-3.1419) ├─»
«       ├───────────┴┐               ├────────────┤  ├─────────────┤ »
« q_5: ─┤ Rz(2.1939) ├──────■────────┤ Rx(3.4668) ├──┤ Ry(-6.8839) ├─»
«       ├────────────┤      │       ┌┴────────────┤  ├─────────────┤ »
« q_6: ─┤ Rz(3.0853) ├──────■───────┤ Rx(0.36996) ├──┤ Ry(-2.5951) ├─»
«      ┌┴────────────┤              └─┬──────────┬┘  └┬────────────┤ »
« q_7: ┤ Rz(-1.4279) ├──────■─────────┤ Rx(2.07) ├────┤ Ry(4.8065) ├─»
«      ├─────────────┤      │       ┌─┴──────────┴┐   ├────────────┤ »
« q_8: ┤ Rz(0.80002) ├──────■───────┤ Rx(0.00927) ├───┤ Ry(0.0276) ├─»
«      └┬────────────┤              ├─────────────┤  ┌┴────────────┤ »
« q_9: ─┤ Rz(5.9237) ├──────■───────┤ Rx(-6.0245) ├──┤ Ry(-3.4147) ├─»
«      ┌┴────────────┤      │       ├─────────────┴┐ └┬────────────┤ »
«q_10: ┤ Rz(-3.3392) ├──────■───────┤ Rx(-0.29768) ├──┤ Ry(5.4079) ├─»
«      ├─────────────┤┌────────────┐└┬────────────┬┘ ┌┴────────────┤ »
«q_11: ┤ Rz(-5.1376) ├┤ Rx(4.6499) ├─┤ Ry(4.9935) ├──┤ Rz(-3.5719) ├─»
«      └─────────────┘└────────────┘ └────────────┘  └─────────────┘ »
«                           ┌────────────┐ ┌─────────────┐ ┌────────────┐»
« q_0: ──────────────────■──┤ Rx(-6.808) ├─┤ Ry(-4.2874) ├─┤ Rz(2.6343) ├»
«       ┌─────────────┐  │ ┌┴────────────┤ ├─────────────┤ ├────────────┤»
« q_1: ─┤ Rz(0.39329) ├──■─┤ Rx(0.50955) ├─┤ Ry(-1.9707) ├─┤ Rz(8.8714) ├»
«       └┬────────────┤    ├─────────────┤ └┬───────────┬┘┌┴────────────┤»
« q_2: ──┤ Rz(3.3453) ├──■─┤ Rx(-4.0374) ├──┤ Ry(1.644) ├─┤ Rz(-2.6804) ├»
«       ┌┴────────────┤  │ ├─────────────┤  ├───────────┴┐└┬────────────┤»
« q_3: ─┤ Rz(0.45044) ├──■─┤ Rx(-4.5301) ├──┤ Ry(1.8919) ├─┤ Rz(4.1211) ├»
«       ├─────────────┤    └┬────────────┤ ┌┴────────────┤┌┴────────────┤»
« q_4: ─┤ Rz(-3.2213) ├──■──┤ Rx(3.1416) ├─┤ Ry(-3.1415) ├┤ Rz(-1.3153) ├»
«       └┬────────────┤  │  ├────────────┤ ├─────────────┤└┬────────────┤»
« q_5: ──┤ Rz(3.2706) ├──■──┤ Rx(2.7678) ├─┤ Ry(-3.4732) ├─┤ Rz(3.9307) ├»
«      ┌─┴────────────┴┐   ┌┴────────────┤ ├─────────────┤ ├────────────┤»
« q_6: ┤ Rz(-0.094993) ├─■─┤ Rx(-3.1109) ├─┤ Ry(-6.3765) ├─┤ Rz(5.4812) ├»
«      └┬─────────────┬┘ │ └┬────────────┤ ├─────────────┤┌┴────────────┤»
« q_7: ─┤ Rz(0.26153) ├──■──┤ Rx(4.2666) ├─┤ Ry(-0.5844) ├┤ Rz(-1.3491) ├»
«       ├─────────────┤    ┌┴────────────┴┐├─────────────┤├─────────────┤»
« q_8: ─┤ Rz(-3.6819) ├──■─┤ Rx(0.039185) ├┤ Ry(-9.3532) ├┤ Rz(-3.0462) ├»
«       ├─────────────┴┐ │ ├─────────────┬┘├─────────────┤└┬────────────┤»
« q_9: ─┤ Rz(-0.17609) ├─■─┤ Rx(-3.7167) ├─┤ Ry(-2.2598) ├─┤ Rz(1.9007) ├»
«       ├─────────────┬┘   ├─────────────┤ └┬────────────┤┌┴────────────┤»
«q_10: ─┤ Rz(-4.4998) ├──■─┤ Rx(0.87242) ├──┤ Ry(2.2062) ├┤ Rz(-9.5283) ├»
«       └─────────────┘  │ └┬────────────┤  ├────────────┤├─────────────┤»
«q_11: ──────────────────■──┤ Rx(1.2858) ├──┤ Ry(4.9293) ├┤ Rz(-4.4512) ├»
«                           └────────────┘  └────────────┘└─────────────┘»
«      ┌─────────────┐┌─────────────┐ ┌────────────┐                    »
« q_0: ┤ Rx(0.43376) ├┤ Ry(-1.6341) ├─┤ Rz(2.4788) ├──────────────────■─»
«      └─────────────┘├─────────────┤┌┴────────────┤  ┌────────────┐  │ »
« q_1: ───────■───────┤ Rx(-6.5989) ├┤ Ry(-0.8646) ├──┤ Rz(1.2751) ├──■─»
«             │       └┬────────────┤└┬────────────┤ ┌┴────────────┴┐   »
« q_2: ───────■────────┤ Rx(2.1177) ├─┤ Ry(-1.859) ├─┤ Rz(-0.93314) ├─■─»
«                     ┌┴────────────┤ ├────────────┤ ├─────────────┬┘ │ »
« q_3: ───────■───────┤ Rx(-2.0788) ├─┤ Ry(3.8564) ├─┤ Rz(0.63223) ├──■─»
«             │       └┬────────────┤┌┴────────────┴┐├─────────────┤    »
« q_4: ───────■────────┤ Rx(1.5709) ├┤ Ry(-0.90892) ├┤ Rz(-4.5687) ├──■─»
«                      ├────────────┤├─────────────┬┘└┬────────────┤  │ »
« q_5: ───────■────────┤ Rx(6.9894) ├┤ Ry(-2.5833) ├──┤ Rz(3.9841) ├──■─»
«             │       ┌┴────────────┤├─────────────┤  ├────────────┤    »
« q_6: ───────■───────┤ Rx(-2.7771) ├┤ Ry(-3.5168) ├──┤ Rz(2.7356) ├──■─»
«                     └┬────────────┤└┬────────────┤ ┌┴────────────┤  │ »
« q_7: ───────■────────┤ Rx(4.8274) ├─┤ Ry(1.9555) ├─┤ Rz(-3.3222) ├──■─»
«             │       ┌┴────────────┤ ├────────────┤ ├─────────────┤    »
« q_8: ───────■───────┤ Rx(-2.0755) ├─┤ Ry(1.4449) ├─┤ Rz(-1.1957) ├──■─»
«                     ├─────────────┤┌┴────────────┴┐└┬────────────┤  │ »
« q_9: ───────■───────┤ Rx(-1.9261) ├┤ Ry(-0.23519) ├─┤ Rz(2.1541) ├──■─»
«             │       └┬────────────┤└┬────────────┬┘┌┴────────────┤    »
«q_10: ───────■────────┤ Rx(1.3115) ├─┤ Ry(2.0039) ├─┤ Rz(-4.3971) ├──■─»
«       ┌───────────┐  ├────────────┤┌┴────────────┤ └─────────────┘  │ »
«q_11: ─┤ Rx(5.982) ├──┤ Ry(4.7755) ├┤ Rz(-2.7037) ├──────────────────■─»
«       └───────────┘  └────────────┘└─────────────┘                    »
«      ┌──────────────┐ ┌────────────┐ ┌─────────────┐ ┌─────────────┐»
« q_0: ┤ Rx(-0.91875) ├─┤ Ry(1.5653) ├─┤ Rz(-2.5454) ├─┤ Rx(-1.5991) ├»
«      └┬────────────┬┘ ├────────────┤ └┬────────────┤ └─────────────┘»
« q_1: ─┤ Rx(6.5461) ├──┤ Ry(9.6704) ├──┤ Rz(5.9492) ├────────■───────»
«      ┌┴────────────┤  ├────────────┤  ├────────────┤        │       »
« q_2: ┤ Rx(-10.391) ├──┤ Ry(3.8182) ├──┤ Rz(4.5056) ├────────■───────»
«      ├─────────────┤  ├────────────┤  ├────────────┤                »
« q_3: ┤ Rx(-4.9433) ├──┤ Ry(3.4638) ├──┤ Rz(3.0159) ├────────■───────»
«      ├─────────────┤  ├────────────┤ ┌┴────────────┤        │       »
« q_4: ┤ Rx(-7.8554) ├──┤ Ry(1.4271) ├─┤ Rz(-4.8278) ├────────■───────»
«      └┬────────────┤ ┌┴────────────┤ └┬────────────┤                »
« q_5: ─┤ Rx(-3.142) ├─┤ Ry(-3.1418) ├──┤ Rz(5.3918) ├────────■───────»
«      ┌┴────────────┤ ├─────────────┴┐ ├────────────┤        │       »
« q_6: ┤ Rx(-3.1729) ├─┤ Ry(0.048098) ├─┤ Rz(4.1685) ├────────■───────»
«      └┬────────────┤ ├─────────────┬┘┌┴────────────┴┐               »
« q_7: ─┤ Rx(3.4522) ├─┤ Ry(0.81094) ├─┤ Rz(-0.56229) ├───────■───────»
«      ┌┴────────────┤ └┬────────────┤ └┬────────────┬┘       │       »
« q_8: ┤ Rx(-3.9266) ├──┤ Ry(6.9858) ├──┤ Rz(1.8366) ├────────■───────»
«      ├─────────────┴┐┌┴────────────┴┐ ├────────────┤                »
« q_9: ┤ Rx(-0.54819) ├┤ Ry(-0.74566) ├─┤ Rz(3.7698) ├────────■───────»
«      └┬────────────┬┘└┬───────────┬─┘ ├────────────┤        │       »
«q_10: ─┤ Rx(3.7827) ├──┤ Ry(3.989) ├───┤ Rz(3.4945) ├────────■───────»
«       ├────────────┤  ├───────────┴┐ ┌┴────────────┤  ┌────────────┐»
«q_11: ─┤ Rx(4.6229) ├──┤ Ry(3.8516) ├─┤ Rz(-4.5842) ├──┤ Rx(5.4975) ├»
«       └────────────┘  └────────────┘ └─────────────┘  └────────────┘»
«      ┌─────────────┐ ┌─────────────┐                    ┌─────────────┐ »
« q_0: ┤ Ry(-3.0179) ├─┤ Rz(-1.1736) ├──────────────────■─┤ Rx(-2.8719) ├─»
«      ├─────────────┴┐└┬────────────┤ ┌─────────────┐  │ ├─────────────┤ »
« q_1: ┤ Rx(-0.17214) ├─┤ Ry(5.7543) ├─┤ Rz(-3.8753) ├──■─┤ Rx(-1.9099) ├─»
«      └┬────────────┬┘┌┴────────────┤ ├─────────────┤    └┬────────────┤ »
« q_2: ─┤ Rx(10.162) ├─┤ Ry(-1.0293) ├─┤ Rz(-2.5866) ├──■──┤ Rx(4.7154) ├─»
«       ├────────────┤ └┬────────────┤ ├─────────────┴┐ │  ├────────────┤ »
« q_3: ─┤ Rx(2.0209) ├──┤ Ry(4.8454) ├─┤ Rz(-0.30176) ├─■──┤ Rx(6.0677) ├─»
«       ├────────────┤ ┌┴────────────┤ └┬────────────┬┘   ┌┴────────────┤ »
« q_4: ─┤ Rx(3.1416) ├─┤ Ry(-3.1416) ├──┤ Rz(-4.126) ├──■─┤ Rx(-3.1425) ├─»
«      ┌┴────────────┤ └┬────────────┤  ├────────────┤  │ ├─────────────┤ »
« q_5: ┤ Rx(-4.6981) ├──┤ Ry(1.5089) ├──┤ Rz(3.9684) ├──■─┤ Rx(-4.7133) ├─»
«      ├─────────────┴┐┌┴────────────┴┐ ├────────────┤    ├─────────────┤ »
« q_6: ┤ Rx(-0.45689) ├┤ Ry(-0.61574) ├─┤ Rz(6.1281) ├──■─┤ Rx(-3.2316) ├─»
«      └┬────────────┬┘└┬────────────┬┘┌┴────────────┤  │ ├─────────────┤ »
« q_7: ─┤ Rx(10.195) ├──┤ Ry(2.9516) ├─┤ Rz(-7.0147) ├──■─┤ Rx(-3.4536) ├─»
«      ┌┴────────────┴┐┌┴────────────┤ ├─────────────┤    ├─────────────┤ »
« q_8: ┤ Rx(-0.74445) ├┤ Ry(-3.4491) ├─┤ Rz(-1.6649) ├──■─┤ Rx(0.17781) ├─»
«      └┬────────────┬┘└┬────────────┤ └┬────────────┤  │ └┬────────────┤ »
« q_9: ─┤ Rx(1.8269) ├──┤ Ry(-6.577) ├──┤ Rz(3.5434) ├──■──┤ Rx(1.5983) ├─»
«       ├───────────┬┘  ├───────────┬┘  ├────────────┤     ├────────────┤ »
«q_10: ─┤ Rx(4.097) ├───┤ Ry(4.854) ├───┤ Rz(6.3807) ├──■──┤ Rx(4.2892) ├─»
«       ├───────────┴┐ ┌┴───────────┴┐  └────────────┘  │ ┌┴────────────┴┐»
«q_11: ─┤ Ry(1.4738) ├─┤ Rz(-5.3276) ├──────────────────■─┤ Rx(-0.50467) ├»
«       └────────────┘ └─────────────┘                    └──────────────┘»
«      ┌──────────────┐┌─────────────┐ ┌──────────────┐  ┌────────────┐ »
« q_0: ┤ Ry(-0.86364) ├┤ Rz(-1.2805) ├─┤ Rx(-0.34979) ├──┤ Ry(-2.659) ├─»
«      ├─────────────┬┘└┬────────────┤ └──────────────┘ ┌┴────────────┤ »
« q_1: ┤ Ry(-2.1382) ├──┤ Rz(1.2575) ├────────■─────────┤ Rx(-7.9142) ├─»
«      └┬───────────┬┘ ┌┴────────────┤        │         ├─────────────┤ »
« q_2: ─┤ Ry(6.414) ├──┤ Rz(-0.8135) ├────────■─────────┤ Rx(-3.3993) ├─»
«      ┌┴───────────┴┐ ├─────────────┤                  ├─────────────┤ »
« q_3: ┤ Ry(0.23995) ├─┤ Rz(-4.2494) ├────────■─────────┤ Rx(-0.6204) ├─»
«      └┬───────────┬┘ ├─────────────┤        │         └┬────────────┤ »
« q_4: ─┤ Ry(3.143) ├──┤ Rz(-3.8346) ├────────■──────────┤ Rx(4.2821) ├─»
«      ┌┴───────────┴┐ └┬────────────┤                  ┌┴────────────┤ »
« q_5: ┤ Ry(0.81246) ├──┤ Rz(4.9562) ├────────■─────────┤ Rx(-3.1415) ├─»
«      ├─────────────┤  ├────────────┤        │         └┬───────────┬┘ »
« q_6: ┤ Ry(0.12453) ├──┤ Rz(4.7692) ├────────■──────────┤ Rx(2.266) ├──»
«      ├─────────────┤ ┌┴────────────┤                   ├───────────┴┐ »
« q_7: ┤ Ry(-4.0608) ├─┤ Rz(-1.9924) ├────────■──────────┤ Rx(2.9919) ├─»
«      ├─────────────┤ ├─────────────┤        │        ┌─┴────────────┴┐»
« q_8: ┤ Ry(-6.4749) ├─┤ Rz(-4.9046) ├────────■────────┤ Rx(-0.032648) ├»
«      └┬────────────┤ ├─────────────┴┐                └─┬────────────┬┘»
« q_9: ─┤ Ry(-5.082) ├─┤ Rz(-0.47597) ├───────■──────────┤ Rx(5.4997) ├─»
«       ├────────────┤ ├─────────────┬┘       │         ┌┴────────────┤ »
«q_10: ─┤ Ry(1.6411) ├─┤ Rz(0.35533) ├────────■─────────┤ Rx(-3.9571) ├─»
«       ├───────────┬┘ ├─────────────┤ ┌─────────────┐  ├─────────────┤ »
«q_11: ─┤ Ry(-3.02) ├──┤ Rz(-2.8003) ├─┤ Rx(-2.6919) ├──┤ Ry(-3.4075) ├─»
«       └───────────┘  └─────────────┘ └─────────────┘  └─────────────┘ »
«      ┌─────────────┐                   ┌─────────────┐  ┌────────────┐ »
« q_0: ┤ Rz(-0.1388) ├────────────────■──┤ Rx(-5.4299) ├──┤ Ry(1.6464) ├─»
«      ├─────────────┤ ┌────────────┐ │  └┬───────────┬┘  ├────────────┤ »
« q_1: ┤ Ry(-6.3633) ├─┤ Rz(2.5321) ├─■───┤ Rx(1.644) ├───┤ Ry(1.9787) ├─»
«      ├─────────────┤ ├────────────┤     ├───────────┴┐  ├────────────┤ »
« q_2: ┤ Ry(-4.5888) ├─┤ Rz(6.4027) ├─■───┤ Rx(1.8081) ├──┤ Ry(4.8146) ├─»
«      └┬───────────┬┘ ├────────────┤ │   ├────────────┤  ├────────────┤ »
« q_3: ─┤ Ry(4.224) ├──┤ Rz(1.3566) ├─■───┤ Rx(1.5076) ├──┤ Ry(2.1193) ├─»
«      ┌┴───────────┴┐ ├────────────┤     ├────────────┤ ┌┴────────────┤ »
« q_4: ┤ Ry(-7.9715) ├─┤ Rz(5.1078) ├─■───┤ Rx(3.3575) ├─┤ Ry(-3.0866) ├─»
«      ├─────────────┤ ├────────────┤ │  ┌┴────────────┤ ├─────────────┤ »
« q_5: ┤ Ry(-6.2834) ├─┤ Rz(2.7234) ├─■──┤ Rx(-3.1416) ├─┤ Ry(-3.1416) ├─»
«      ├─────────────┤ ├────────────┤    ├─────────────┤ ├─────────────┤ »
« q_6: ┤ Ry(-2.1318) ├─┤ Rz(6.2938) ├─■──┤ Rx(-6.8818) ├─┤ Ry(-3.4122) ├─»
«      ├─────────────┤┌┴────────────┤ │  ├─────────────┤ └┬────────────┤ »
« q_7: ┤ Ry(-6.8931) ├┤ Rz(-4.6983) ├─■──┤ Rx(0.19584) ├──┤ Ry(6.0445) ├─»
«      └┬────────────┤└┬────────────┤   ┌┴─────────────┴┐┌┴────────────┴┐»
« q_8: ─┤ Ry(-3.045) ├─┤ Rz(2.2837) ├─■─┤ Rx(-0.071317) ├┤ Ry(-0.26167) ├»
«       ├────────────┤┌┴────────────┤ │ └┬─────────────┬┘├─────────────┬┘»
« q_9: ─┤ Ry(3.6896) ├┤ Rz(-4.4629) ├─■──┤ Rx(-3.7053) ├─┤ Ry(0.34498) ├─»
«       ├───────────┬┘└┬────────────┤    ├─────────────┤ ├─────────────┤ »
«q_10: ─┤ Ry(6.213) ├──┤ Rz(3.3675) ├─■──┤ Rx(-3.0865) ├─┤ Ry(0.19646) ├─»
«       ├───────────┴┐ └────────────┘ │  └┬────────────┤ ├─────────────┤ »
«q_11: ─┤ Rz(-3.244) ├────────────────■───┤ Rx(2.8474) ├─┤ Ry(-2.9923) ├─»
«       └────────────┘                    └────────────┘ └─────────────┘ »
«       ┌────────────┐ ┌────────────┐┌─────────────┐   ┌────────────┐  »
« q_0: ─┤ Rz(1.7481) ├─┤ Rx(5.0126) ├┤ Ry(-1.5743) ├───┤ Rz(6.3258) ├──»
«      ┌┴────────────┴┐└────────────┘└┬────────────┤   ├────────────┤  »
« q_1: ┤ Rz(-0.30534) ├──────■────────┤ Rx(3.8893) ├───┤ Ry(1.7846) ├──»
«      └┬────────────┬┘      │       ┌┴────────────┤ ┌─┴────────────┴─┐»
« q_2: ─┤ Rz(-1.721) ├───────■───────┤ Rx(-3.1417) ├─┤ Ry(0.00065233) ├»
«      ┌┴────────────┤               ├─────────────┤ ├────────────────┤»
« q_3: ┤ Rz(-1.8684) ├───────■───────┤ Rx(-3.1416) ├─┤ Ry(0.00019528) ├»
«      └┬────────────┤       │       └┬────────────┤ └┬─────────────┬─┘»
« q_4: ─┤ Rz(1.3006) ├───────■────────┤ Rx(4.8354) ├──┤ Ry(0.26151) ├──»
«       ├────────────┤               ┌┴────────────┤  └┬────────────┤  »
« q_5: ─┤ Rz(-3.709) ├───────■───────┤ Rx(-3.1416) ├───┤ Ry(3.1417) ├──»
«      ┌┴────────────┤       │       └┬────────────┤  ┌┴────────────┤  »
« q_6: ┤ Rz(-1.4494) ├───────■────────┤ Rx(3.2661) ├──┤ Ry(-9.2429) ├──»
«      ├─────────────┤               ┌┴────────────┤  ├─────────────┤  »
« q_7: ┤ Rz(-4.9913) ├───────■───────┤ Rx(-2.9595) ├──┤ Ry(-3.1644) ├──»
«      └┬────────────┤       │       ├─────────────┴┐ ├─────────────┤  »
« q_8: ─┤ Rz(1.5117) ├───────■───────┤ Rx(-0.34267) ├─┤ Ry(-1.5498) ├──»
«       ├────────────┤               └┬────────────┬┘ ├─────────────┤  »
« q_9: ─┤ Rz(-6.719) ├───────■────────┤ Rx(2.3144) ├──┤ Ry(-6.2739) ├──»
«      ┌┴────────────┤       │        ├────────────┤  └┬────────────┤  »
«q_10: ┤ Rz(-2.9911) ├───────■────────┤ Rx(2.4744) ├───┤ Ry(6.4269) ├──»
«      └┬────────────┤ ┌────────────┐┌┴────────────┤  ┌┴────────────┴┐ »
«q_11: ─┤ Rz(-3.412) ├─┤ Rx(3.4649) ├┤ Ry(-3.2021) ├──┤ Rz(-0.96247) ├─»
«       └────────────┘ └────────────┘└─────────────┘  └──────────────┘ »
«                           ┌──────────────┐   ┌────────────┐  ┌────────────┐ »
« q_0: ─────────────────■───┤ Rx(-0.10165) ├───┤ Ry(2.5087) ├──┤ Rz(1.3604) ├─»
«       ┌───────────┐   │   └┬────────────┬┘  ┌┴────────────┤  ├────────────┤ »
« q_1: ─┤ Rz(2.186) ├───■────┤ Rx(1.2937) ├───┤ Ry(-4.8494) ├──┤ Rz(-1.522) ├─»
«       ├───────────┴┐       ├────────────┤   ├─────────────┤  ├────────────┤ »
« q_2: ─┤ Rz(0.1631) ├──■────┤ Rx(3.6802) ├───┤ Ry(-5.4494) ├──┤ Rz(-1.402) ├─»
«       ├────────────┤  │    ├────────────┤   └┬───────────┬┘  ├────────────┤ »
« q_3: ─┤ Rz(3.7706) ├──■────┤ Rx(1.2223) ├────┤ Ry(0.821) ├───┤ Rz(1.2645) ├─»
«       ├───────────┬┘       ├────────────┤   ┌┴───────────┴┐  ├────────────┤ »
« q_4: ─┤ Rz(3.544) ├───■────┤ Rx(6.1088) ├───┤ Ry(0.21028) ├──┤ Rz(2.4284) ├─»
«      ┌┴───────────┴┐  │ ┌──┴────────────┴─┐ └┬────────────┤ ┌┴────────────┤ »
« q_5: ┤ Rz(0.31317) ├──■─┤ Rx(-1.7585e-05) ├──┤ Ry(3.1416) ├─┤ Rz(-1.3288) ├─»
«      └┬────────────┤    └──┬────────────┬─┘ ┌┴────────────┤ └┬────────────┤ »
« q_6: ─┤ Rz(-2.358) ├──■────┤ Rx(4.0183) ├───┤ Ry(-6.9957) ├──┤ Rz(1.6325) ├─»
«      ┌┴────────────┤  │    ├────────────┤   └┬────────────┤ ┌┴────────────┴┐»
« q_7: ┤ Rz(-1.6008) ├──■────┤ Rx(-1.518) ├────┤ Ry(1.9305) ├─┤ Rz(-0.50836) ├»
«      └┬────────────┤       ├────────────┤   ┌┴────────────┴┐├─────────────┬┘»
« q_8: ─┤ Rz(4.4813) ├──■────┤ Rx(3.2465) ├───┤ Ry(-0.25676) ├┤ Rz(0.95716) ├─»
«      ┌┴────────────┴┐ │    ├────────────┤  ┌┴──────────────┤└┬───────────┬┘ »
« q_9: ┤ Rz(-0.45946) ├─■────┤ Rx(6.1847) ├──┤ Ry(-0.014768) ├─┤ Rz(2.925) ├──»
«      ├─────────────┬┘      ├────────────┤  └─┬───────────┬─┘ ├───────────┤  »
«q_10: ┤ Rz(-6.2409) ├──■────┤ Rx(1.8414) ├────┤ Ry(5.703) ├───┤ Rz(4.754) ├──»
«      └─────────────┘  │    ├────────────┤   ┌┴───────────┴┐ ┌┴───────────┴┐ »
«q_11: ─────────────────■────┤ Rx(1.6865) ├───┤ Ry(-3.8281) ├─┤ Rz(-1.4273) ├─»
«                            └────────────┘   └─────────────┘ └─────────────┘ »
«      ┌─────────────┐┌─────────────┐  ┌────────────┐                     »
« q_0: ┤ Rx(-8.5616) ├┤ Ry(-8.1073) ├──┤ Rz(-6.907) ├───────────────────■─»
«      └─────────────┘├─────────────┤ ┌┴────────────┴┐  ┌────────────┐  │ »
« q_1: ───────■───────┤ Rx(-3.9321) ├─┤ Ry(-0.61641) ├──┤ Rz(6.2812) ├──■─»
«             │       └┬────────────┤ └┬────────────┬┘ ┌┴────────────┤    »
« q_2: ───────■────────┤ Rx(7.9047) ├──┤ Ry(2.0782) ├──┤ Rz(-4.2864) ├──■─»
«                     ┌┴────────────┤ ┌┴────────────┤  ├─────────────┤  │ »
« q_3: ───────■───────┤ Rx(-3.4947) ├─┤ Ry(-7.8403) ├──┤ Rz(-1.3273) ├──■─»
«             │       └┬───────────┬┘ ├─────────────┤  └┬───────────┬┘    »
« q_4: ───────■────────┤ Rx(5.941) ├──┤ Ry(-4.7872) ├───┤ Rz(3.845) ├───■─»
«                     ┌┴───────────┴┐ ├─────────────┤   ├───────────┤   │ »
« q_5: ───────■───────┤ Rx(-3.1416) ├─┤ Ry(-6.2833) ├───┤ Rz(2.196) ├───■─»
«             │       ├─────────────┴┐├─────────────┤ ┌─┴───────────┴─┐   »
« q_6: ───────■───────┤ Rx(-0.42551) ├┤ Ry(-4.1424) ├─┤ Rz(0.0077828) ├─■─»
«                     ├─────────────┬┘├─────────────┤ └─┬────────────┬┘ │ »
« q_7: ───────■───────┤ Rx(-4.2715) ├─┤ Ry(-8.6153) ├───┤ Rz(3.5692) ├──■─»
«             │       ├─────────────┤ ├─────────────┤   ├────────────┤    »
« q_8: ───────■───────┤ Rx(0.13974) ├─┤ Ry(-1.3964) ├───┤ Rz(1.6885) ├──■─»
«                     ├─────────────┤ └┬────────────┤   ├────────────┤  │ »
« q_9: ───────■───────┤ Rx(-9.1272) ├──┤ Ry(4.6904) ├───┤ Rz(3.4776) ├──■─»
«             │       ├─────────────┤  ├────────────┤  ┌┴────────────┤    »
«q_10: ───────■───────┤ Rx(-1.4865) ├──┤ Ry(6.5193) ├──┤ Rz(-3.6962) ├──■─»
«       ┌────────────┐├─────────────┤  ├────────────┤  └─────────────┘  │ »
«q_11: ─┤ Rx(2.4718) ├┤ Ry(-4.5996) ├──┤ Rz(4.9783) ├───────────────────■─»
«       └────────────┘└─────────────┘  └────────────┘                     »
«       ┌────────────┐ ┌────────────┐ ┌─────────────┐ ┌────────────┐ »
« q_0: ─┤ Rx(3.7962) ├─┤ Ry(3.8102) ├─┤ Rz(-6.3413) ├─┤ Rx(2.3439) ├─»
«      ┌┴────────────┤┌┴────────────┴┐└┬────────────┤┌┴────────────┴┐»
« q_1: ┤ Rx(-2.6845) ├┤ Ry(-0.15878) ├─┤ Rz(3.4215) ├┤ Rx(-0.44439) ├»
«      ├─────────────┤└┬────────────┬┘ ├────────────┤├─────────────┬┘»
« q_2: ┤ Rx(-1.3649) ├─┤ Ry(10.245) ├──┤ Rz(8.3141) ├┤ Rx(-1.7742) ├─»
«      └┬────────────┤ ├────────────┤ ┌┴────────────┤├─────────────┤ »
« q_3: ─┤ Rx(2.1292) ├─┤ Ry(7.1566) ├─┤ Rz(-2.9286) ├┤ Rx(-1.2641) ├─»
«       ├────────────┤┌┴────────────┤ ├─────────────┤└┬───────────┬┘ »
« q_4: ─┤ Rx(2.4748) ├┤ Ry(-5.1511) ├─┤ Rz(-3.0283) ├─┤ Rx(1.383) ├──»
«      ┌┴────────────┤├─────────────┤ ├─────────────┤┌┴───────────┴┐ »
« q_5: ┤ Rx(-4.5568) ├┤ Ry(-2.9242) ├─┤ Rz(-1.7682) ├┤ Rx(-2.3255) ├─»
«      ├─────────────┤└┬────────────┤ ├─────────────┤└┬────────────┤ »
« q_6: ┤ Rx(-1.4769) ├─┤ Ry(6.0824) ├─┤ Rz(-1.4471) ├─┤ Rx(5.7197) ├─»
«      └┬────────────┤┌┴────────────┤ ├─────────────┤ ├────────────┤ »
« q_7: ─┤ Rx(3.6618) ├┤ Ry(0.94246) ├─┤ Rz(-1.2474) ├─┤ Rx(4.0724) ├─»
«       ├────────────┤└┬────────────┤ └┬────────────┤┌┴────────────┤ »
« q_8: ─┤ Rx(-5.357) ├─┤ Ry(4.0319) ├──┤ Rz(2.1472) ├┤ Rx(-3.5065) ├─»
«       ├────────────┤┌┴────────────┴┐ ├────────────┤└┬────────────┤ »
« q_9: ─┤ Rx(6.3777) ├┤ Ry(-0.34247) ├─┤ Rz(2.5124) ├─┤ Rx(4.8112) ├─»
«      ┌┴────────────┤└┬────────────┬┘┌┴────────────┤┌┴────────────┤ »
«q_10: ┤ Rx(-8.9451) ├─┤ Ry(6.5718) ├─┤ Rz(0.20736) ├┤ Rx(-5.7192) ├─»
«      └┬────────────┤ ├────────────┤ └┬────────────┤└┬────────────┤ »
«q_11: ─┤ Rx(3.0939) ├─┤ Ry(3.0163) ├──┤ Rz(6.0677) ├─┤ Rx(3.1211) ├─»
«       └────────────┘ └────────────┘  └────────────┘ └────────────┘ »
«      ┌──────────────┐┌─────────────┐                                        »
« q_0: ┤ Ry(-0.15093) ├┤ Rz(-6.6825) ├──■────────────────────────────────■──■─»
«      ├─────────────┬┘└┬────────────┤  │                                │  │ »
« q_1: ┤ Ry(-1.6749) ├──┤ Rz(3.5309) ├──■──■────────■────────────────────┼──┼─»
«      └┬────────────┤ ┌┴────────────┤     │        │                    │  │ »
« q_2: ─┤ Ry(-5.338) ├─┤ Rz(-1.0708) ├─────■──■─────┼────────────────────┼──■─»
«       ├────────────┤ └┬────────────┤        │     │                    │    »
« q_3: ─┤ Ry(3.3852) ├──┤ Rz(1.7598) ├────────■──■──■─────■──────────────┼────»
«      ┌┴────────────┤ ┌┴────────────┴┐          │        │              │    »
« q_4: ┤ Ry(-3.7955) ├─┤ Rz(-0.11901) ├──────────■──■─────┼──────────────┼────»
«      └┬────────────┤ ├─────────────┬┘             │     │              │    »
« q_5: ─┤ Ry(1.7935) ├─┤ Rz(0.42294) ├──────────────■──■──■─────■────────┼────»
«       ├───────────┬┘ ├─────────────┤                 │        │        │    »
« q_6: ─┤ Ry(11.01) ├──┤ Rz(-8.1998) ├─────────────────■──■─────┼────────┼────»
«       ├───────────┴┐ └┬────────────┤                    │     │        │    »
« q_7: ─┤ Ry(2.2034) ├──┤ Rz(11.862) ├────────────────────■──■──■─────■──┼────»
«       ├────────────┤  ├────────────┤                       │        │  │    »
« q_8: ─┤ Ry(5.1131) ├──┤ Rz(12.997) ├───────────────────────■──■─────┼──┼────»
«      ┌┴────────────┤  ├────────────┤                          │     │  │    »
« q_9: ┤ Ry(-4.7277) ├──┤ Rz(2.5035) ├──────────────────────────■──■──■──┼──■─»
«      └┬────────────┤  ├────────────┤                             │     │  │ »
«q_10: ─┤ Ry(4.0215) ├──┤ Rz(7.8889) ├─────────────────────────────■──■──┼──┼─»
«       ├────────────┤  ├────────────┤                                │  │  │ »
«q_11: ─┤ Ry(3.0095) ├──┤ Rz(2.1927) ├────────────────────────────────■──■──■─»
«       └────────────┘  └────────────┘                                        »
«                                                                         »
« q_0: ───────────────────■───────■───────────────────────────────────────»
«                         │       │                                       »
« q_1: ────■────────■─────┼───────┼─────────────────────────────────────■─»
«          │        │     │       │                                     │ »
« q_2: ─■──┼─────■──┼─────┼───────┼─────────────────────────────────────┼─»
«       │  │     │  │     │       │                                     │ »
« q_3: ─┼──┼─────┼──┼─────┼───────■────────────────────────────■────────┼─»
«       │  │     │  │     │ ┌────────────┐ ┌────────────┐      │        │ »
« q_4: ─■──┼──■──┼──■──■──┼─┤ Rx(-6.283) ├─┤ Ry(3.1413) ├──────┼────────┼─»
«          │  │  │     │  │ └────────────┘┌┴────────────┤      │        │ »
« q_5: ────┼──┼──■─────┼──┼───────■───────┤ Rx(-3.1416) ├──────┼────────┼─»
«          │  │        │  │       │       └─────────────┘      │        │ »
« q_6: ────┼──■──■─────┼──┼───────┼────────────────────────────■────────┼─»
«          │     │     │  │       │                      ┌────────────┐ │ »
« q_7: ────┼─────┼─────■──┼───────┼──────────────■───────┤ Rx(9.4181) ├─┼─»
«          │     │        │       │              │       └────────────┘ │ »
« q_8: ────┼─────■──■─────┼───────■──────────────┼─────────────■────────┼─»
«          │        │     │                      │             │        │ »
« q_9: ────┼────────┼─────┼──────────────────────┼─────────────┼────────┼─»
«          │        │     │                      │             │        │ »
«q_10: ────┼────────■─────■──────────────────────■─────────────┼────────■─»
«          │                                                   │          »
«q_11: ────■───────────────────────────────────────────────────■──────────»
«                                                                         »
«                                                                           »
« q_0: ───────────────────────────────────────────────────────────────────■─»
«      ┌────────────┐  ┌─────────────┐   ┌─────────────┐                  │ »
« q_1: ┤ Rx(3.1416) ├──┤ Ry(-3.1418) ├───┤ Rz(-6.5497) ├──────────────────┼─»
«      └────────────┘┌─┴─────────────┴─┐┌┴─────────────┴─┐┌─────────────┐ │ »
« q_2: ──────■───────┤ Rx(-1.5909e-05) ├┤ Ry(7.3443e-06) ├┤ Rz(-3.0847) ├─┼─»
«            │       └─┬─────────────┬─┘└┬─────────────┬─┘└┬────────────┤ │ »
« q_3: ──────┼─────────┤ Rx(-3.1413) ├───┤ Ry(-3.1416) ├───┤ Rz(-7.862) ├─┼─»
«            │         └┬────────────┤   └─────────────┘   └────────────┘ │ »
« q_4: ──────┼──────────┤ Rz(7.2968) ├────────────────────────────────────┼─»
«            │         ┌┴────────────┤    ┌────────────┐                  │ »
« q_5: ──────┼─────────┤ Ry(-3.1416) ├────┤ Rz(3.5115) ├──────────────────┼─»
«            │         └─────────────┘    └────────────┘   ┌────────────┐ │ »
« q_6: ──────┼──────────────────────────────────■──────────┤ Rx(3.0797) ├─┼─»
«            │         ┌─────────────┐          │          ├────────────┤ │ »
« q_7: ──────┼─────────┤ Ry(0.01854) ├──────────┼──────────┤ Rz(3.0754) ├─┼─»
«            │         └┬────────────┤          │         ┌┴────────────┤ │ »
« q_8: ──────┼──────────┤ Rx(7.9584) ├──────────┼─────────┤ Ry(-8.5064) ├─┼─»
«            │          └────────────┘          │         └─────────────┘ │ »
« q_9: ──────┼──────────────────────────────────■─────────────────────────■─»
«            │        ┌────────────────┐ ┌─────────────┐   ┌────────────┐   »
«q_10: ──────┼────────┤ Rx(-0.0085452) ├─┤ Ry(-3.1369) ├───┤ Rz(4.1582) ├───»
«            │        └┬─────────────┬─┘ ├─────────────┤  ┌┴────────────┤   »
«q_11: ──────■─────────┤ Rx(-3.1416) ├───┤ Ry(-3.1415) ├──┤ Rz(-1.9293) ├───»
«                      └─────────────┘   └─────────────┘  └─────────────┘   »
«       ┌────────────┐┌───────────────┐┌────────────┐
« q_0: ─┤ Rx(6.2846) ├┤ Ry(0.0018276) ├┤ Rz(1.1766) ├
«       └────────────┘└───────────────┘└────────────┘
« q_1: ──────────────────────────────────────────────
«                                                    
« q_2: ──────────────────────────────────────────────
«                                                    
« q_3: ──────────────────────────────────────────────
«                                                    
« q_4: ──────────────────────────────────────────────
«                                                    
« q_5: ──────────────────────────────────────────────
«      ┌─────────────┐ ┌─────────────┐               
« q_6: ┤ Ry(-3.0524) ├─┤ Rz(-9.3367) ├───────────────
«      └─────────────┘ └─────────────┘               
« q_7: ──────────────────────────────────────────────
«       ┌────────────┐                               
« q_8: ─┤ Rz(7.3219) ├───────────────────────────────
«       ├────────────┤  ┌────────────┐ ┌────────────┐
« q_9: ─┤ Rx(3.1629) ├──┤ Ry(3.1311) ├─┤ Rz(7.1145) ├
«       └────────────┘  └────────────┘ └────────────┘
«q_10: ──────────────────────────────────────────────
«                                                    
«q_11: ──────────────────────────────────────────────
«                                                    
