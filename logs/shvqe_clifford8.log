Train hybrid.
----------epoch 0-----------
batched average loss:  -40.7007 minimum candidate loss:  -40.92804
probability converged
strcuture parameter: 
 [[0.40000862 1.5999913 ]
 [0.4000408  1.5999591 ]
 [0.40000927 1.5999907 ]
 [1.5999867  0.40001333]
 [1.5999918  0.40000814]
 [0.40072674 1.5992732 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-51.4329, shape=(), dtype=float32)
----------epoch 50-----------
batched average loss:  -78.39886 minimum candidate loss:  -78.39886
probability converged
strcuture parameter: 
 [[-7.2486115  6.0938296]
 [-7.054214   5.623999 ]
 [-7.2330227  6.063987 ]
 [ 5.770394  -7.1629806]
 [ 6.091013  -7.2310896]
 [-7.05198    5.4800253]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.471725, shape=(), dtype=float32)
----------epoch 100-----------
batched average loss:  -78.69654 minimum candidate loss:  -78.69654
probability converged
strcuture parameter: 
 [[-7.652342   6.124491 ]
 [-7.457537   5.65202  ]
 [-7.636144   6.0945225]
 [ 5.7990603 -7.5640473]
 [ 6.121588  -7.6318164]
 [-7.4534125  5.5070796]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.692856, shape=(), dtype=float32)
----------epoch 150-----------
batched average loss:  -78.71332 minimum candidate loss:  -78.713326
probability converged
strcuture parameter: 
 [[-7.66778    6.124684 ]
 [-7.473002   5.652197 ]
 [-7.6516614  6.0947137]
 [ 5.7992396 -7.57937  ]
 [ 6.12178   -7.647129 ]
 [-7.468777   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71335, shape=(), dtype=float32)
----------epoch 200-----------
batched average loss:  -78.71616 minimum candidate loss:  -78.716156
probability converged
strcuture parameter: 
 [[-7.669142   6.124684 ]
 [-7.474424   5.652197 ]
 [-7.6530232  6.0947137]
 [ 5.7992396 -7.5807242]
 [ 6.12178   -7.6484814]
 [-7.470136   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71607, shape=(), dtype=float32)
----------epoch 250-----------
batched average loss:  -78.71649 minimum candidate loss:  -78.7165
probability converged
strcuture parameter: 
 [[-7.66939    6.124684 ]
 [-7.474679   5.652197 ]
 [-7.6532717  6.0947137]
 [ 5.7992396 -7.580972 ]
 [ 6.12178   -7.6487293]
 [-7.4705048  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71674, shape=(), dtype=float32)
----------epoch 300-----------
batched average loss:  -78.71673 minimum candidate loss:  -78.71673
probability converged
strcuture parameter: 
 [[-7.6694894  6.124684 ]
 [-7.474778   5.652197 ]
 [-7.6533704  6.0947137]
 [ 5.7992396 -7.58107  ]
 [ 6.12178   -7.648827 ]
 [-7.4706106  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71679, shape=(), dtype=float32)
----------epoch 350-----------
batched average loss:  -78.716896 minimum candidate loss:  -78.71689
probability converged
strcuture parameter: 
 [[-7.669543   6.124684 ]
 [-7.4748316  5.652197 ]
 [-7.6535497  6.0947137]
 [ 5.7992396 -7.5811243]
 [ 6.12178   -7.6488814]
 [-7.47079    5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71687, shape=(), dtype=float32)
----------epoch 400-----------
batched average loss:  -78.71698 minimum candidate loss:  -78.71699
probability converged
strcuture parameter: 
 [[-7.669565   6.124684 ]
 [-7.474854   5.652197 ]
 [-7.653575   6.0947137]
 [ 5.7992396 -7.5811477]
 [ 6.12178   -7.648905 ]
 [-7.470817   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71675, shape=(), dtype=float32)
----------epoch 450-----------
batched average loss:  -78.71728 minimum candidate loss:  -78.71727
probability converged
strcuture parameter: 
 [[-7.669647   6.124684 ]
 [-7.474936   5.652197 ]
 [-7.653657   6.0947137]
 [ 5.7992396 -7.581229 ]
 [ 6.12178   -7.6489863]
 [-7.470899   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71731, shape=(), dtype=float32)
----------epoch 500-----------
batched average loss:  -78.71832 minimum candidate loss:  -78.71832
probability converged
strcuture parameter: 
 [[-7.6698837  6.124684 ]
 [-7.4751725  5.652197 ]
 [-7.6538925  6.0947137]
 [ 5.7992396 -7.5814633]
 [ 6.12178   -7.6492205]
 [-7.471134   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71834, shape=(), dtype=float32)
----------epoch 550-----------
batched average loss:  -78.719475 minimum candidate loss:  -78.719475
probability converged
strcuture parameter: 
 [[-7.6702213  6.124684 ]
 [-7.4755106  5.652197 ]
 [-7.654337   6.0947137]
 [ 5.7992396 -7.5817986]
 [ 6.12178   -7.6495547]
 [-7.47147    5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71944, shape=(), dtype=float32)
----------epoch 600-----------
batched average loss:  -78.72071 minimum candidate loss:  -78.72072
probability converged
strcuture parameter: 
 [[-7.670599   6.124684 ]
 [-7.4758887  5.652197 ]
 [-7.654714   6.0947137]
 [ 5.7992396 -7.5821714]
 [ 6.12178   -7.649927 ]
 [-7.4718456  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.720764, shape=(), dtype=float32)
----------epoch 650-----------
batched average loss:  -78.72126 minimum candidate loss:  -78.72127
probability converged
strcuture parameter: 
 [[-7.670759   6.124684 ]
 [-7.4760494  5.652197 ]
 [-7.6548743  6.0947137]
 [ 5.7992396 -7.5823307]
 [ 6.12178   -7.6500864]
 [-7.472005   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72122, shape=(), dtype=float32)
----------epoch 700-----------
batched average loss:  -78.7213 minimum candidate loss:  -78.72129
probability converged
strcuture parameter: 
 [[-7.6707835  6.124684 ]
 [-7.4760737  5.652197 ]
 [-7.6548986  6.0947137]
 [ 5.7992396 -7.5823555]
 [ 6.12178   -7.650111 ]
 [-7.472132   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72142, shape=(), dtype=float32)
----------epoch 750-----------
batched average loss:  -78.72127 minimum candidate loss:  -78.721275
probability converged
strcuture parameter: 
 [[-7.670804   6.124684 ]
 [-7.4760942  5.652197 ]
 [-7.654919   6.0947137]
 [ 5.7992396 -7.582375 ]
 [ 6.12178   -7.6501303]
 [-7.4721546  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7214, shape=(), dtype=float32)
----------epoch 800-----------
batched average loss:  -78.721306 minimum candidate loss:  -78.721306
probability converged
strcuture parameter: 
 [[-7.67077    6.124684 ]
 [-7.4760604  5.652197 ]
 [-7.6548853  6.0947137]
 [ 5.7992396 -7.582341 ]
 [ 6.12178   -7.6500964]
 [-7.4721203  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72137, shape=(), dtype=float32)
----------epoch 850-----------
batched average loss:  -78.72141 minimum candidate loss:  -78.721405
probability converged
strcuture parameter: 
 [[-7.6708074  6.124684 ]
 [-7.4760966  5.652197 ]
 [-7.6549954  6.0947137]
 [ 5.7992396 -7.5823784]
 [ 6.12178   -7.650133 ]
 [-7.4721575  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72124, shape=(), dtype=float32)
----------epoch 900-----------
batched average loss:  -78.72125 minimum candidate loss:  -78.72125
probability converged
strcuture parameter: 
 [[-7.6707907  6.124684 ]
 [-7.4760795  5.652197 ]
 [-7.654979   6.0947137]
 [ 5.7992396 -7.5823617]
 [ 6.12178   -7.6501164]
 [-7.472141   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72131, shape=(), dtype=float32)
----------epoch 950-----------
batched average loss:  -78.72136 minimum candidate loss:  -78.72135
probability converged
strcuture parameter: 
 [[-7.670845   6.124684 ]
 [-7.476116   5.652197 ]
 [-7.655006   6.0947137]
 [ 5.7992396 -7.5823884]
 [ 6.12178   -7.650143 ]
 [-7.4721675  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721405, shape=(), dtype=float32)
----------epoch 1000-----------
batched average loss:  -78.72139 minimum candidate loss:  -78.7214
probability converged
strcuture parameter: 
 [[-7.670844   6.124684 ]
 [-7.4761395  5.652197 ]
 [-7.655112   6.0947137]
 [ 5.7992396 -7.5823874]
 [ 6.12178   -7.650142 ]
 [-7.472167   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72142, shape=(), dtype=float32)
----------epoch 1050-----------
batched average loss:  -78.721375 minimum candidate loss:  -78.721375
probability converged
strcuture parameter: 
 [[-7.6708403  6.124684 ]
 [-7.4761357  5.652197 ]
 [-7.6551194  6.0947137]
 [ 5.7992396 -7.5823827]
 [ 6.12178   -7.6501374]
 [-7.472163   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721275, shape=(), dtype=float32)
----------epoch 1100-----------
batched average loss:  -78.721306 minimum candidate loss:  -78.7213
probability converged
strcuture parameter: 
 [[-7.6708517  6.124684 ]
 [-7.476147   5.652197 ]
 [-7.655131   6.0947137]
 [ 5.7992396 -7.582394 ]
 [ 6.12178   -7.650149 ]
 [-7.4721746  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7214, shape=(), dtype=float32)
----------epoch 1150-----------
batched average loss:  -78.72134 minimum candidate loss:  -78.721344
probability converged
strcuture parameter: 
 [[-7.670838   6.124684 ]
 [-7.4761333  5.652197 ]
 [-7.655117   6.0947137]
 [ 5.7992396 -7.5823803]
 [ 6.12178   -7.650135 ]
 [-7.472161   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721466, shape=(), dtype=float32)
----------epoch 1200-----------
batched average loss:  -78.721306 minimum candidate loss:  -78.721306
probability converged
strcuture parameter: 
 [[-7.6708508  6.124684 ]
 [-7.476146   5.652197 ]
 [-7.65513    6.0947137]
 [ 5.7992396 -7.582393 ]
 [ 6.12178   -7.650148 ]
 [-7.4721737  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72146, shape=(), dtype=float32)
----------epoch 1250-----------
batched average loss:  -78.7213 minimum candidate loss:  -78.72129
probability converged
strcuture parameter: 
 [[-7.670839   6.124684 ]
 [-7.4761343  5.652197 ]
 [-7.655118   6.0947137]
 [ 5.7992396 -7.5823927]
 [ 6.12178   -7.650136 ]
 [-7.472162   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72138, shape=(), dtype=float32)
----------epoch 1300-----------
batched average loss:  -78.721375 minimum candidate loss:  -78.72139
probability converged
strcuture parameter: 
 [[-7.670834   6.124684 ]
 [-7.4761233  5.652197 ]
 [-7.655107   6.0947137]
 [ 5.7992396 -7.5823827]
 [ 6.12178   -7.6501255]
 [-7.4721513  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72146, shape=(), dtype=float32)
----------epoch 1350-----------
batched average loss:  -78.72132 minimum candidate loss:  -78.72133
probability converged
strcuture parameter: 
 [[-7.670835   6.124684 ]
 [-7.476137   5.652197 ]
 [-7.6551     6.0947137]
 [ 5.7992396 -7.582376 ]
 [ 6.12178   -7.650119 ]
 [-7.4721446  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72133, shape=(), dtype=float32)
----------epoch 1400-----------
batched average loss:  -78.72132 minimum candidate loss:  -78.72133
probability converged
strcuture parameter: 
 [[-7.6708264  6.124684 ]
 [-7.476129   5.652197 ]
 [-7.6550913  6.0947137]
 [ 5.7992396 -7.5823674]
 [ 6.12178   -7.6501102]
 [-7.472136   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72126, shape=(), dtype=float32)
----------epoch 1450-----------
batched average loss:  -78.721375 minimum candidate loss:  -78.72139
probability converged
strcuture parameter: 
 [[-7.670813   6.124684 ]
 [-7.4761157  5.652197 ]
 [-7.655078   6.0947137]
 [ 5.7992396 -7.582354 ]
 [ 6.12178   -7.650097 ]
 [-7.4721227  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72143, shape=(), dtype=float32)
----------epoch 1500-----------
batched average loss:  -78.72141 minimum candidate loss:  -78.721405
probability converged
strcuture parameter: 
 [[-7.670811   6.124684 ]
 [-7.476114   5.652197 ]
 [-7.6551056  6.0947137]
 [ 5.7992396 -7.582352 ]
 [ 6.12178   -7.650095 ]
 [-7.472121   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721405, shape=(), dtype=float32)
----------epoch 1550-----------
batched average loss:  -78.72142 minimum candidate loss:  -78.72141
probability converged
strcuture parameter: 
 [[-7.6708093  6.124684 ]
 [-7.476112   5.652197 ]
 [-7.655104   6.0947137]
 [ 5.7992396 -7.5823503]
 [ 6.12178   -7.650093 ]
 [-7.472147   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72143, shape=(), dtype=float32)
----------epoch 1600-----------
batched average loss:  -78.72148 minimum candidate loss:  -78.72147
probability converged
strcuture parameter: 
 [[-7.6707993  6.124684 ]
 [-7.476102   5.652197 ]
 [-7.655094   6.0947137]
 [ 5.7992396 -7.5823402]
 [ 6.12178   -7.650083 ]
 [-7.4721394  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72147, shape=(), dtype=float32)
----------epoch 1650-----------
batched average loss:  -78.72143 minimum candidate loss:  -78.72142
probability converged
strcuture parameter: 
 [[-7.670799   6.124684 ]
 [-7.4761133  5.652197 ]
 [-7.6550937  6.0947137]
 [ 5.7992396 -7.58234  ]
 [ 6.12178   -7.650089 ]
 [-7.472139   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72139, shape=(), dtype=float32)
----------epoch 1700-----------
batched average loss:  -78.721214 minimum candidate loss:  -78.72122
probability converged
strcuture parameter: 
 [[-7.6707954  6.124684 ]
 [-7.47611    5.652197 ]
 [-7.6550903  6.0947137]
 [ 5.7992396 -7.5823364]
 [ 6.12178   -7.650087 ]
 [-7.4721355  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721245, shape=(), dtype=float32)
----------epoch 1750-----------
batched average loss:  -78.72126 minimum candidate loss:  -78.72127
probability converged
strcuture parameter: 
 [[-7.670791   6.124684 ]
 [-7.4761057  5.652197 ]
 [-7.6550937  6.0947137]
 [ 5.7992396 -7.5823317]
 [ 6.12178   -7.6500826]
 [-7.4721317  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72146, shape=(), dtype=float32)
----------epoch 1800-----------
batched average loss:  -78.72132 minimum candidate loss:  -78.72133
probability converged
strcuture parameter: 
 [[-7.670789   6.124684 ]
 [-7.4761033  5.652197 ]
 [-7.655106   6.0947137]
 [ 5.7992396 -7.582329 ]
 [ 6.12178   -7.6500797]
 [-7.472129   5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721245, shape=(), dtype=float32)
----------epoch 1850-----------
batched average loss:  -78.72133 minimum candidate loss:  -78.72134
probability converged
strcuture parameter: 
 [[-7.670784   6.124684 ]
 [-7.4760985  5.652197 ]
 [-7.6551123  6.0947137]
 [ 5.7992396 -7.582328 ]
 [ 6.12178   -7.6500797]
 [-7.4721413  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721306, shape=(), dtype=float32)
----------epoch 1900-----------
batched average loss:  -78.72144 minimum candidate loss:  -78.72145
probability converged
strcuture parameter: 
 [[-7.6707964  6.124684 ]
 [-7.476106   5.652197 ]
 [-7.65512    6.0947137]
 [ 5.7992396 -7.5823355]
 [ 6.12178   -7.6500907]
 [-7.4721503  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721275, shape=(), dtype=float32)
----------epoch 1950-----------
batched average loss:  -78.72137 minimum candidate loss:  -78.72136
probability converged
strcuture parameter: 
 [[-7.6707935  6.124684 ]
 [-7.4761004  5.652197 ]
 [-7.655114   6.0947137]
 [ 5.7992396 -7.5823298]
 [ 6.12178   -7.650088 ]
 [-7.4721565  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72134, shape=(), dtype=float32)
----------epoch 1999-----------
batched average loss:  -78.72136 minimum candidate loss:  -78.72135
probability converged
strcuture parameter: 
 [[-7.670787   6.124684 ]
 [-7.476094   5.652197 ]
 [-7.6551075  6.0947137]
 [ 5.7992396 -7.5823226]
 [ 6.12178   -7.6500807]
 [-7.4721503  5.50725  ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.721466, shape=(), dtype=float32)
Energy: tf.Tensor(-78.721466, shape=(), dtype=float32)
Ref energy: -74.38714627
Error rate: tf.Tensor(0.041743282, shape=(), dtype=float32)
        ┌────────────┐ ┌─────────────┐  ┌────────────┐┌─────────────┐»
 q_0: ──┤ Rx(2.1048) ├─┤ Ry(-2.4823) ├──┤ Rz(1.0971) ├┤ Rx(-3.3792) ├»
       ┌┴────────────┤ ├─────────────┤  ├────────────┤└─────────────┘»
 q_1: ─┤ Rx(0.35739) ├─┤ Ry(-3.0317) ├──┤ Rz(4.3434) ├───────■───────»
       ├─────────────┤ ├─────────────┤  ├───────────┬┘       │       »
 q_2: ─┤ Rx(-4.0392) ├─┤ Ry(-1.4141) ├──┤ Rz(1.232) ├────────■───────»
       ├─────────────┤ └┬────────────┤ ┌┴───────────┴┐               »
 q_3: ─┤ Rx(-3.1416) ├──┤ Ry(3.1416) ├─┤ Rz(-1.3348) ├───────■───────»
       ├─────────────┤ ┌┴────────────┤ └┬────────────┤       │       »
 q_4: ─┤ Rx(0.56321) ├─┤ Ry(-2.7529) ├──┤ Rz(1.8855) ├───────■───────»
       ├─────────────┤ ├─────────────┤ ┌┴────────────┤               »
 q_5: ─┤ Rx(-2.6039) ├─┤ Ry(-1.9961) ├─┤ Rz(-6.0606) ├───────■───────»
       └┬────────────┤ └┬────────────┤ ├─────────────┤       │       »
 q_6: ──┤ Rx(-2.556) ├──┤ Ry(2.4023) ├─┤ Rz(-1.7737) ├───────■───────»
       ┌┴────────────┤ ┌┴────────────┤ ├─────────────┤               »
 q_7: ─┤ Rx(-3.8093) ├─┤ Ry(-2.8054) ├─┤ Rz(-3.3331) ├───────■───────»
      ┌┴─────────────┴┐├─────────────┴┐├─────────────┤       │       »
 q_8: ┤ Rx(0.0060935) ├┤ Ry(0.046752) ├┤ Rz(-1.4523) ├───────■───────»
      └─┬────────────┬┘└┬────────────┬┘├─────────────┤               »
 q_9: ──┤ Rx(3.1412) ├──┤ Ry(3.1434) ├─┤ Rz(0.85926) ├───────■───────»
       ┌┴────────────┤  ├────────────┤ ├─────────────┤       │       »
q_10: ─┤ Rx(-5.9222) ├──┤ Ry(1.0121) ├─┤ Rz(0.48738) ├───────■───────»
       └┬────────────┤  ├────────────┤ └┬────────────┤ ┌────────────┐»
q_11: ──┤ Rx(1.4354) ├──┤ Ry(2.5452) ├──┤ Rz(2.4731) ├─┤ Rx(1.6046) ├»
        └────────────┘  └────────────┘  └────────────┘ └────────────┘»
«      ┌─────────────┐┌─────────────┐                    ┌────────────┐»
« q_0: ┤ Ry(-2.0976) ├┤ Rz(-4.9866) ├─────────────────■──┤ Rx(2.3465) ├»
«      ├─────────────┤├─────────────┤  ┌────────────┐ │ ┌┴────────────┤»
« q_1: ┤ Rx(-3.9782) ├┤ Ry(0.63619) ├──┤ Rz(1.7393) ├─■─┤ Rx(-4.3455) ├»
«      ├─────────────┤├─────────────┤  ├────────────┤   ├─────────────┤»
« q_2: ┤ Rx(0.16795) ├┤ Ry(-1.6527) ├──┤ Rz(1.9418) ├─■─┤ Rx(-3.9877) ├»
«      ├─────────────┤├─────────────┴┐┌┴────────────┤ │ ├─────────────┤»
« q_3: ┤ Rx(-3.0681) ├┤ Ry(0.014378) ├┤ Rz(-4.3646) ├─■─┤ Rx(-3.1642) ├»
«      ├─────────────┤├─────────────┬┘└┬────────────┤   └┬───────────┬┘»
« q_4: ┤ Rx(0.17621) ├┤ Ry(-2.4896) ├──┤ Rz(4.5727) ├─■──┤ Rx(3.141) ├─»
«      ├─────────────┤├─────────────┤ ┌┴────────────┤ │  ├───────────┴┐»
« q_5: ┤ Rx(-1.9194) ├┤ Ry(-3.6832) ├─┤ Rz(-1.0039) ├─■──┤ Rx(3.7971) ├»
«      ├─────────────┤├─────────────┴┐├─────────────┤    ├────────────┤»
« q_6: ┤ Rx(0.18656) ├┤ Ry(-0.97335) ├┤ Rz(-4.3283) ├─■──┤ Rx(6.7931) ├»
«      ├─────────────┤├─────────────┬┘└┬────────────┤ │ ┌┴────────────┤»
« q_7: ┤ Rx(-1.8624) ├┤ Ry(-3.5273) ├──┤ Rz(-2.056) ├─■─┤ Rx(-2.9495) ├»
«      └┬────────────┤├─────────────┤  ├────────────┤   └┬────────────┤»
« q_8: ─┤ Rx(3.0658) ├┤ Ry(0.10365) ├──┤ Rz(3.7513) ├─■──┤ Rx(2.0555) ├»
«       ├────────────┤└┬────────────┤  ├────────────┤ │  ├────────────┤»
« q_9: ─┤ Rx(5.8167) ├─┤ Ry(0.5434) ├──┤ Rz(1.4542) ├─■──┤ Rx(5.6247) ├»
«      ┌┴────────────┤ ├────────────┤  ├────────────┤    ├────────────┤»
«q_10: ┤ Rx(-3.3135) ├─┤ Ry(4.1782) ├──┤ Rz(2.1568) ├─■──┤ Rx(1.1924) ├»
«      └┬────────────┤ ├────────────┤  └────────────┘ │  ├────────────┤»
«q_11: ─┤ Ry(2.3451) ├─┤ Rz(2.0968) ├─────────────────■──┤ Rx(3.7826) ├»
«       └────────────┘ └────────────┘                    └────────────┘»
«       ┌─────────────┐  ┌───────────┐ ┌────────────┐ ┌─────────────┐ »
« q_0: ─┤ Ry(-2.4528) ├──┤ Rz(1.609) ├─┤ Rx(3.3583) ├─┤ Ry(-2.9267) ├─»
«       ├─────────────┤  ├───────────┴┐└────────────┘ ├─────────────┤ »
« q_1: ─┤ Ry(-2.1916) ├──┤ Rz(3.5809) ├──────■────────┤ Rx(-2.9464) ├─»
«       ├─────────────┤ ┌┴────────────┤      │        ├─────────────┤ »
« q_2: ─┤ Ry(-3.7271) ├─┤ Rz(-3.7664) ├──────■────────┤ Rx(-2.2409) ├─»
«      ┌┴─────────────┴┐└┬────────────┤               └┬────────────┤ »
« q_3: ┤ Ry(-0.079286) ├─┤ Rz(1.9428) ├──────■─────────┤ Rx(-3.155) ├─»
«      └┬─────────────┬┘┌┴────────────┤      │         ├────────────┤ »
« q_4: ─┤ Ry(-3.1412) ├─┤ Rz(0.57397) ├──────■─────────┤ Rx(3.2129) ├─»
«       ├─────────────┤ └┬────────────┤                ├────────────┤ »
« q_5: ─┤ Ry(-1.7752) ├──┤ Rz(2.8319) ├──────■─────────┤ Rx(3.5807) ├─»
«       ├─────────────┤  ├───────────┬┘      │         ├────────────┤ »
« q_6: ─┤ Ry(-1.1755) ├──┤ Rz(1.579) ├───────■─────────┤ Rx(-3.926) ├─»
«       ├─────────────┤  ├───────────┴┐               ┌┴────────────┤ »
« q_7: ─┤ Ry(-3.1451) ├──┤ Rz(2.3718) ├──────■────────┤ Rx(-6.2777) ├─»
«       ├─────────────┴┐ ├────────────┤      │        ├─────────────┤ »
« q_8: ─┤ Ry(-0.39016) ├─┤ Rz(5.7783) ├──────■────────┤ Rx(-2.9494) ├─»
«       ├─────────────┬┘ ├────────────┤               └┬────────────┤ »
« q_9: ─┤ Ry(-3.6795) ├──┤ Rz(3.9868) ├──────■─────────┤ Rx(3.3097) ├─»
«       └┬────────────┤  ├────────────┤      │       ┌─┴────────────┴┐»
«q_10: ──┤ Ry(1.3676) ├──┤ Rz(1.3385) ├──────■───────┤ Rx(-0.016432) ├»
«        ├────────────┤  ├────────────┤┌────────────┐└─┬────────────┬┘»
«q_11: ──┤ Ry(1.7358) ├──┤ Rz(3.1664) ├┤ Rx(4.6188) ├──┤ Ry(2.3231) ├─»
«        └────────────┘  └────────────┘└────────────┘  └────────────┘ »
«       ┌────────────┐                     ┌───────────────┐┌─────────────┐ »
« q_0: ─┤ Rz(1.2018) ├───────────────────■─┤ Rx(-0.080736) ├┤ Ry(-3.0481) ├─»
«       ├────────────┤   ┌────────────┐  │ └┬─────────────┬┘├─────────────┤ »
« q_1: ─┤ Ry(3.0986) ├───┤ Rz(2.4417) ├──■──┤ Rx(-3.2251) ├─┤ Ry(0.32254) ├─»
«      ┌┴────────────┴┐ ┌┴────────────┴┐    ├─────────────┤ └┬────────────┤ »
« q_2: ┤ Ry(-0.33852) ├─┤ Rz(-0.20952) ├─■──┤ Rx(-4.4562) ├──┤ Ry(-3.132) ├─»
«      ├──────────────┤ └┬───────────┬─┘ │  ├─────────────┤  ├────────────┤ »
« q_3: ┤ Ry(0.015963) ├──┤ Rz(3.001) ├───■──┤ Rx(-2.8408) ├──┤ Ry(1.5497) ├─»
«      ├─────────────┬┘┌─┴───────────┴─┐    └┬────────────┤ ┌┴────────────┤ »
« q_4: ┤ Ry(-4.6518) ├─┤ Rz(-0.061811) ├─■───┤ Rx(2.0352) ├─┤ Ry(-1.7257) ├─»
«      ├─────────────┤ └─┬────────────┬┘ │   ├────────────┤ ├─────────────┤ »
« q_5: ┤ Ry(-3.9525) ├───┤ Rz(2.0202) ├──■───┤ Rx(2.9947) ├─┤ Ry(-4.7123) ├─»
«      ├─────────────┤  ┌┴────────────┴┐     ├────────────┤ ├─────────────┤ »
« q_6: ┤ Ry(-3.9881) ├──┤ Rz(0.016187) ├─■───┤ Rx(2.6218) ├─┤ Ry(0.59448) ├─»
«      ├─────────────┤  └┬────────────┬┘ │  ┌┴────────────┤ └┬───────────┬┘ »
« q_7: ┤ Ry(-3.1341) ├───┤ Rz(3.7888) ├──■──┤ Rx(-1.7715) ├──┤ Ry(4.666) ├──»
«      └┬────────────┤   ├────────────┤     ├─────────────┴┐┌┴───────────┴┐ »
« q_8: ─┤ Ry(-3.462) ├───┤ Rz(-3.616) ├──■──┤ Rx(-0.59957) ├┤ Ry(-7.0451) ├─»
«       ├───────────┬┘  ┌┴────────────┴┐ │ ┌┴──────────────┤├─────────────┴┐»
« q_9: ─┤ Ry(-2.99) ├───┤ Rz(-0.35794) ├─■─┤ Rx(-0.014376) ├┤ Ry(-0.12667) ├»
«       ├───────────┴┐  ├──────────────┤   └─┬────────────┬┘└┬────────────┬┘»
«q_10: ─┤ Ry(3.3392) ├──┤ Rz(0.077846) ├─■───┤ Rx(3.4924) ├──┤ Ry(3.0201) ├─»
«       ├────────────┤  └──────────────┘ │  ┌┴────────────┤  ├────────────┤ »
«q_11: ─┤ Rz(2.5545) ├───────────────────■──┤ Rx(-2.2027) ├──┤ Ry(1.0407) ├─»
«       └────────────┘                      └─────────────┘  └────────────┘ »
«        ┌────────────┐  ┌───────────┐  ┌──────────────┐  ┌────────────┐  »
« q_0: ──┤ Rz(1.1823) ├──┤ Rx(1.139) ├──┤ Ry(-0.39841) ├──┤ Rz(0.3476) ├──»
«       ┌┴────────────┤  └───────────┘  ├─────────────┬┘ ┌┴────────────┤  »
« q_1: ─┤ Rz(0.61199) ├────────■────────┤ Rx(-2.4425) ├──┤ Ry(-1.4597) ├──»
«       ├─────────────┤        │        ├─────────────┤  ├─────────────┤  »
« q_2: ─┤ Rz(-2.3058) ├────────■────────┤ Rx(-2.3153) ├──┤ Ry(-5.7905) ├──»
«       └┬────────────┤                 ├─────────────┤  └┬────────────┤  »
« q_3: ──┤ Rz(3.8737) ├────────■────────┤ Rx(-1.5523) ├───┤ Ry(4.3849) ├──»
«       ┌┴────────────┤        │        ├─────────────┴┐ ┌┴────────────┤  »
« q_4: ─┤ Rz(0.40064) ├────────■────────┤ Rx(0.047858) ├─┤ Ry(-4.1818) ├──»
«       └┬────────────┤                 └┬────────────┬┘ ├─────────────┤  »
« q_5: ──┤ Rz(4.4468) ├────────■─────────┤ Rx(1.8312) ├──┤ Ry(-4.8352) ├──»
«        ├────────────┤        │         ├────────────┤ ┌┴─────────────┴─┐»
« q_6: ──┤ Rz(1.6707) ├────────■─────────┤ Rx(3.1416) ├─┤ Ry(4.3721e-05) ├»
«       ┌┴────────────┤                 ┌┴────────────┤ └┬─────────────┬─┘»
« q_7: ─┤ Rz(0.87067) ├────────■────────┤ Rx(-4.2842) ├──┤ Ry(-3.9899) ├──»
«       ├─────────────┤        │        ├─────────────┤  └┬────────────┤  »
« q_8: ─┤ Rz(0.62833) ├────────■────────┤ Rx(0.63574) ├───┤ Ry(3.0504) ├──»
«       └┬────────────┤                 └┬────────────┤  ┌┴────────────┤  »
« q_9: ──┤ Rz(1.4249) ├────────■─────────┤ Rx(3.2554) ├──┤ Ry(-1.5963) ├──»
«      ┌─┴────────────┴┐       │        ┌┴────────────┤  └┬────────────┤  »
«q_10: ┤ Rz(-0.094222) ├───────■────────┤ Rx(-5.7379) ├───┤ Ry(1.1117) ├──»
«      └┬─────────────┬┘┌──────────────┐└┬────────────┤  ┌┴────────────┴┐ »
«q_11: ─┤ Rz(0.56837) ├─┤ Rx(-0.97186) ├─┤ Ry(2.1238) ├──┤ Rz(-0.75422) ├─»
«       └─────────────┘ └──────────────┘ └────────────┘  └──────────────┘ »
«                          ┌────────────┐   ┌─────────────┐   ┌────────────┐ »
« q_0: ────────────────■───┤ Rx(3.6068) ├───┤ Ry(-3.4593) ├───┤ Rz(4.6088) ├─»
«       ┌────────────┐ │  ┌┴────────────┤   ├─────────────┴┐ ┌┴────────────┤ »
« q_1: ─┤ Rz(3.3458) ├─■──┤ Rx(-2.3239) ├───┤ Ry(-0.82174) ├─┤ Rz(-1.2215) ├─»
«      ┌┴────────────┤    ├─────────────┤  ┌┴──────────────┴┐├─────────────┤ »
« q_2: ┤ Rz(-3.3232) ├─■──┤ Rx(-3.1421) ├──┤ Ry(-0.0011498) ├┤ Rz(-2.0515) ├─»
«      └┬────────────┤ │  ├─────────────┤  └─┬────────────┬─┘└┬────────────┤ »
« q_3: ─┤ Rz(1.1438) ├─■──┤ Rx(-3.1337) ├────┤ Ry(3.1445) ├───┤ Rz(3.1966) ├─»
«       ├────────────┤    ├─────────────┤   ┌┴────────────┤   ├────────────┤ »
« q_4: ─┤ Rz(-4.742) ├─■──┤ Rx(0.88868) ├───┤ Ry(-1.6802) ├───┤ Rz(-2.552) ├─»
«      ┌┴────────────┤ │  └┬────────────┤   ├─────────────┤  ┌┴────────────┴┐»
« q_5: ┤ Rz(0.40032) ├─■───┤ Rx(3.1416) ├───┤ Ry(-3.1416) ├──┤ Rz(-0.24248) ├»
«      ├─────────────┤    ┌┴────────────┤   ├─────────────┤  ├─────────────┬┘»
« q_6: ┤ Rz(0.31969) ├─■──┤ Rx(-3.1416) ├───┤ Ry(-3.1416) ├──┤ Rz(-3.4006) ├─»
«      ├─────────────┤ │  ├─────────────┤   ├─────────────┤  ├─────────────┤ »
« q_7: ┤ Rz(-1.1426) ├─■──┤ Rx(-3.1844) ├───┤ Ry(-6.2842) ├──┤ Rz(-1.0801) ├─»
«      ├─────────────┤   ┌┴─────────────┴─┐ └┬────────────┤  ├─────────────┤ »
« q_8: ┤ Rz(-3.0563) ├─■─┤ Rx(0.00060788) ├──┤ Ry(3.1394) ├──┤ Rz(-3.3058) ├─»
«      └┬────────────┤ │ └┬──────────────┬┘ ┌┴────────────┤  ├─────────────┤ »
« q_9: ─┤ Rz(4.8916) ├─■──┤ Rx(-0.49035) ├──┤ Ry(-2.0033) ├──┤ Rz(-3.7297) ├─»
«       ├────────────┤    ├──────────────┤  ├─────────────┴┐ ├─────────────┤ »
«q_10: ─┤ Rz(1.9683) ├─■──┤ Rx(0.062485) ├──┤ Ry(-0.31027) ├─┤ Rz(-1.2906) ├─»
«       └────────────┘ │  ├─────────────┬┘  └┬────────────┬┘ ├─────────────┤ »
«q_11: ────────────────■──┤ Rx(-1.5621) ├────┤ Ry(2.3239) ├──┤ Rz(-1.5625) ├─»
«                         └─────────────┘    └────────────┘  └─────────────┘ »
«      ┌──────────────┐┌─────────────┐ ┌────────────┐                    »
« q_0: ┤ Rx(-0.46579) ├┤ Ry(-1.4849) ├─┤ Rz(5.6926) ├──────────────────■─»
«      └──────────────┘├─────────────┤ ├────────────┤ ┌─────────────┐  │ »
« q_1: ───────■────────┤ Rx(-4.0026) ├─┤ Ry(4.3544) ├─┤ Rz(-1.9486) ├──■─»
«             │        ├─────────────┤┌┴────────────┴┐├─────────────┤    »
« q_2: ───────■────────┤ Rx(-1.5702) ├┤ Ry(-0.82708) ├┤ Rz(0.94917) ├──■─»
«                      ├─────────────┤└┬───────────┬─┘└┬────────────┤  │ »
« q_3: ───────■────────┤ Rx(-4.7245) ├─┤ Ry(1.881) ├───┤ Rz(3.3378) ├──■─»
«             │        └┬────────────┤┌┴───────────┴┐ ┌┴────────────┴┐   »
« q_4: ───────■─────────┤ Rx(1.8611) ├┤ Ry(-1.6157) ├─┤ Rz(-0.28354) ├─■─»
«                       ├────────────┤├─────────────┤ └┬────────────┬┘ │ »
« q_5: ───────■─────────┤ Rx(1.4513) ├┤ Ry(-1.6015) ├──┤ Rz(3.9983) ├──■─»
«             │         ├───────────┬┘└┬────────────┤ ┌┴────────────┤    »
« q_6: ───────■─────────┤ Rx(5.762) ├──┤ Ry(5.2778) ├─┤ Rz(-2.7232) ├──■─»
«                      ┌┴───────────┴┐┌┴────────────┤ └┬────────────┤  │ »
« q_7: ───────■────────┤ Rx(-4.6997) ├┤ Ry(-4.3121) ├──┤ Rz(4.2397) ├──■─»
«             │        └┬───────────┬┘└┬────────────┤  ├────────────┤    »
« q_8: ───────■─────────┤ Rx(1.829) ├──┤ Ry(1.5143) ├──┤ Rz(-2.952) ├──■─»
«                       ├───────────┴┐ ├───────────┬┘ ┌┴────────────┤  │ »
« q_9: ───────■─────────┤ Rx(1.5033) ├─┤ Ry(-7.37) ├──┤ Rz(0.61671) ├──■─»
«             │        ┌┴────────────┤ ├───────────┴┐ ├─────────────┤    »
«q_10: ───────■────────┤ Rx(-1.0596) ├─┤ Ry(5.7292) ├─┤ Rz(-2.2554) ├──■─»
«       ┌────────────┐ └┬───────────┬┘┌┴────────────┤ └─────────────┘  │ »
«q_11: ─┤ Rx(-3.586) ├──┤ Ry(1.587) ├─┤ Rz(0.58206) ├──────────────────■─»
«       └────────────┘  └───────────┘ └─────────────┘                    »
«       ┌────────────┐┌─────────────┐ ┌──────────────┐  ┌────────────┐ »
« q_0: ─┤ Rx(5.7305) ├┤ Ry(-6.2369) ├─┤ Rz(-0.27791) ├──┤ Rx(5.1145) ├─»
«      ┌┴────────────┤└┬────────────┤ ├─────────────┬┘ ┌┴────────────┤ »
« q_1: ┤ Rx(-3.3078) ├─┤ Ry(2.3405) ├─┤ Rz(-1.2186) ├──┤ Rx(-3.1727) ├─»
«      ├─────────────┤ ├────────────┤ ├─────────────┤  ├─────────────┤ »
« q_2: ┤ Rx(-3.8533) ├─┤ Ry(3.0185) ├─┤ Rz(0.54103) ├──┤ Rx(-3.3612) ├─»
«      ├─────────────┤ ├────────────┤ ├─────────────┴┐ ├─────────────┤ »
« q_3: ┤ Rx(0.32984) ├─┤ Ry(4.6633) ├─┤ Rz(-0.29234) ├─┤ Rx(-4.6103) ├─»
«      ├─────────────┤ ├────────────┤ ├─────────────┬┘┌┴─────────────┴┐»
« q_4: ┤ Rx(-1.5187) ├─┤ Ry(5.9721) ├─┤ Rz(-3.1515) ├─┤ Rx(0.0057624) ├»
«      ├─────────────┤┌┴────────────┤ └┬────────────┤ └─┬────────────┬┘»
« q_5: ┤ Rx(-3.5358) ├┤ Ry(-4.6928) ├──┤ Rz(3.9297) ├───┤ Rx(-3.531) ├─»
«      ├─────────────┤├─────────────┤ ┌┴────────────┤  ┌┴────────────┤ »
« q_6: ┤ Rx(-4.0019) ├┤ Ry(-1.7433) ├─┤ Rz(-5.4902) ├──┤ Rx(-3.8544) ├─»
«      ├─────────────┤├─────────────┤ ├─────────────┤  ├─────────────┤ »
« q_7: ┤ Rx(-2.2458) ├┤ Ry(-2.2905) ├─┤ Rz(-3.5393) ├──┤ Rx(-1.7617) ├─»
«      ├─────────────┤├─────────────┤ └┬────────────┤  ├─────────────┤ »
« q_8: ┤ Rx(-5.2108) ├┤ Ry(-5.4316) ├──┤ Rz(2.4365) ├──┤ Rx(-2.9778) ├─»
«      └┬────────────┤├─────────────┤  ├────────────┤  └┬───────────┬┘ »
« q_9: ─┤ Rx(3.5656) ├┤ Ry(-3.8699) ├──┤ Rz(3.2088) ├───┤ Rx(1.814) ├──»
«       ├────────────┤├─────────────┤┌─┴────────────┴┐  ├───────────┤  »
«q_10: ─┤ Rx(1.3193) ├┤ Ry(0.75281) ├┤ Rz(-0.044318) ├──┤ Rx(2.725) ├──»
«      ┌┴────────────┤└─┬─────────┬─┘└─┬────────────┬┘  ├───────────┤  »
«q_11: ┤ Rx(-1.5744) ├──┤ Ry(3.2) ├────┤ Rz(1.5681) ├───┤ Rx(4.175) ├──»
«      └─────────────┘  └─────────┘    └────────────┘   └───────────┘  »
«      ┌──────────────┐ ┌────────────┐                                        »
« q_0: ┤ Ry(-0.71024) ├─┤ Rz(5.2263) ├──■────────────────────────────────■──■─»
«      ├─────────────┬┘┌┴────────────┤  │                                │  │ »
« q_1: ┤ Ry(0.31188) ├─┤ Rz(-7.5695) ├──■──■────────■────────────────────┼──┼─»
«      └┬────────────┤ └┬────────────┤     │        │                    │  │ »
« q_2: ─┤ Ry(1.8592) ├──┤ Rz(1.6378) ├─────■──■─────┼────────────────────┼──■─»
«       ├────────────┤ ┌┴────────────┴┐       │     │                    │    »
« q_3: ─┤ Ry(4.8755) ├─┤ Rz(-0.93476) ├───────■──■──■─────■──────────────┼────»
«       ├────────────┤ └┬────────────┬┘          │        │              │    »
« q_4: ─┤ Ry(1.2669) ├──┤ Rz(-8.111) ├───────────■──■─────┼──────────────┼────»
«      ┌┴────────────┤ ┌┴────────────┤              │     │              │    »
« q_5: ┤ Ry(-4.0422) ├─┤ Rz(-1.7936) ├──────────────■──■──■─────■────────┼────»
«      ├─────────────┤ ├─────────────┤                 │        │        │    »
« q_6: ┤ Ry(-2.8874) ├─┤ Rz(-4.4889) ├─────────────────■──■─────┼────────┼────»
«      ├─────────────┤ └┬────────────┤                    │     │        │    »
« q_7: ┤ Ry(-1.5266) ├──┤ Rz(-0.182) ├────────────────────■──■──■─────■──┼────»
«      └┬───────────┬┘ ┌┴────────────┤                       │        │  │    »
« q_8: ─┤ Ry(-4.13) ├──┤ Rz(-1.9643) ├───────────────────────■──■─────┼──┼────»
«      ┌┴───────────┴┐ └┬────────────┤                          │     │  │    »
« q_9: ┤ Ry(-3.8473) ├──┤ Rz(4.5282) ├──────────────────────────■──■──■──┼──■─»
«      └┬────────────┤ ┌┴────────────┤                             │     │  │ »
«q_10: ─┤ Ry(2.9659) ├─┤ Rz(-2.1976) ├─────────────────────────────■──■──┼──┼─»
«       ├────────────┤ └┬────────────┤                                │  │  │ »
«q_11: ─┤ Ry(1.5756) ├──┤ Rz(5.3899) ├────────────────────────────────■──■──■─»
«       └────────────┘  └────────────┘                                        »
«                                                
« q_0: ───────────────────■──■─────────────────■─
«                         │  │                 │ 
« q_1: ────■────────■─────┼──┼────────■────────┼─
«          │        │     │  │        │        │ 
« q_2: ─■──┼─────■──┼─────┼──┼────────┼──■─────┼─
«       │  │     │  │     │  │        │  │     │ 
« q_3: ─┼──┼─────┼──┼─────┼──■──■─────┼──┼─────┼─
«       │  │     │  │     │     │     │  │     │ 
« q_4: ─■──┼──■──┼──■──■──┼─────┼─────┼──┼─────┼─
«          │  │  │     │  │     │     │  │     │ 
« q_5: ────┼──┼──■─────┼──┼──■──┼─────┼──┼─────┼─
«          │  │        │  │  │  │     │  │     │ 
« q_6: ────┼──■──■─────┼──┼──┼──■─────┼──┼──■──┼─
«          │     │     │  │  │        │  │  │  │ 
« q_7: ────┼─────┼─────■──┼──┼──■─────┼──┼──┼──┼─
«          │     │        │  │  │     │  │  │  │ 
« q_8: ────┼─────■──■─────┼──■──┼──■──┼──┼──┼──┼─
«          │        │     │     │  │  │  │  │  │ 
« q_9: ────┼────────┼─────┼─────┼──┼──┼──┼──■──■─
«          │        │     │     │  │  │  │       
«q_10: ────┼────────■─────■─────■──┼──■──┼───────
«          │                       │     │       
«q_11: ────■───────────────────────■─────■───────
«                                                
