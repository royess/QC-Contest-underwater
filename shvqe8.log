Train hybrid.
----------epoch 0-----------
batched average loss:  -41.70125 minimum candidate loss:  -42.802288
probability converged
strcuture parameter: 
 [[0.40000844 1.5999916 ]
 [0.40367508 1.5963249 ]
 [0.40000963 1.5999904 ]
 [1.5999879  0.40001214]
 [1.599992   0.4000079 ]
 [1.5999151  0.40008485]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-51.227467, shape=(), dtype=float32)
----------epoch 50-----------
batched average loss:  -78.47863 minimum candidate loss:  -78.47863
probability converged
strcuture parameter: 
 [[-9.99243    5.6797795]
 [-9.740885   4.96028  ]
 [-9.948795   5.572324 ]
 [ 5.3749614 -9.801095 ]
 [ 5.733709  -9.988003 ]
 [ 5.019949  -9.785441 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.48564, shape=(), dtype=float32)
----------epoch 100-----------
batched average loss:  -78.701355 minimum candidate loss:  -78.70136
probability converged
strcuture parameter: 
 [[-10.512785    5.707386 ]
 [-10.262986    4.9841743]
 [-10.468784    5.599356 ]
 [  5.400795  -10.315507 ]
 [  5.7615848 -10.505677 ]
 [  5.043955  -10.304667 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7007, shape=(), dtype=float32)
----------epoch 150-----------
batched average loss:  -78.703026 minimum candidate loss:  -78.70303
probability converged
strcuture parameter: 
 [[-10.519059    5.7075586]
 [-10.269291    4.9843245]
 [-10.475058    5.599526 ]
 [  5.4009566 -10.321708 ]
 [  5.761761  -10.511918 ]
 [  5.044105  -10.310938 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.70321, shape=(), dtype=float32)
----------epoch 200-----------
batched average loss:  -78.613785 minimum candidate loss:  -78.61379
probability converged
strcuture parameter: 
 [[-10.499319    5.7075586]
 [-10.249432    4.9843245]
 [-10.455334    5.599526 ]
 [  5.4009566 -10.302207 ]
 [  5.761761  -10.492299 ]
 [  5.044105  -10.291213 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.670235, shape=(), dtype=float32)
----------epoch 250-----------
batched average loss:  -78.70373 minimum candidate loss:  -78.70373
probability converged
strcuture parameter: 
 [[-10.520784    5.7075586]
 [-10.271029    4.9843245]
 [-10.47678     5.599526 ]
 [  5.4009566 -10.323409 ]
 [  5.761761  -10.513634 ]
 [  5.044105  -10.31266  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.70369, shape=(), dtype=float32)
----------epoch 300-----------
batched average loss:  -78.70427 minimum candidate loss:  -78.70426
probability converged
strcuture parameter: 
 [[-10.521434    5.7075586]
 [-10.271683    4.9843245]
 [-10.477429    5.599526 ]
 [  5.4009566 -10.32405  ]
 [  5.761761  -10.51428  ]
 [  5.044105  -10.31331  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.70409, shape=(), dtype=float32)
----------epoch 350-----------
batched average loss:  -78.70428 minimum candidate loss:  -78.70427
probability converged
strcuture parameter: 
 [[-10.521523    5.7075586]
 [-10.271772    4.9843245]
 [-10.477519    5.599526 ]
 [  5.4009566 -10.324139 ]
 [  5.761761  -10.51437  ]
 [  5.044105  -10.313399 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.704384, shape=(), dtype=float32)
----------epoch 400-----------
batched average loss:  -78.7061 minimum candidate loss:  -78.70609
probability converged
strcuture parameter: 
 [[-10.522112    5.7075586]
 [-10.272366    4.9843245]
 [-10.4781065   5.599526 ]
 [  5.4009566 -10.324722 ]
 [  5.761761  -10.5149555]
 [  5.044105  -10.313987 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.70594, shape=(), dtype=float32)
----------epoch 450-----------
batched average loss:  -78.694435 minimum candidate loss:  -78.69443
probability converged
strcuture parameter: 
 [[-10.522115    5.7075586]
 [-10.272372    4.9843245]
 [-10.478109    5.599526 ]
 [  5.4009566 -10.324724 ]
 [  5.761761  -10.514959 ]
 [  5.044105  -10.31399  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.69237, shape=(), dtype=float32)
----------epoch 500-----------
batched average loss:  -78.70959 minimum candidate loss:  -78.70958
probability converged
strcuture parameter: 
 [[-10.523741    5.7075586]
 [-10.274007    4.9843245]
 [-10.479735    5.599526 ]
 [  5.4009566 -10.32633  ]
 [  5.761761  -10.516578 ]
 [  5.044105  -10.315617 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.70962, shape=(), dtype=float32)
----------epoch 550-----------
batched average loss:  -78.709785 minimum candidate loss:  -78.70979
probability converged
strcuture parameter: 
 [[-10.523969    5.7075586]
 [-10.274237    4.9843245]
 [-10.479962    5.599526 ]
 [  5.4009566 -10.326556 ]
 [  5.761761  -10.516804 ]
 [  5.044105  -10.315844 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71016, shape=(), dtype=float32)
----------epoch 600-----------
batched average loss:  -78.711 minimum candidate loss:  -78.71098
probability converged
strcuture parameter: 
 [[-10.524235    5.7075586]
 [-10.274503    4.9843245]
 [-10.480228    5.599526 ]
 [  5.4009566 -10.326818 ]
 [  5.761761  -10.517069 ]
 [  5.044105  -10.31611  ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71111, shape=(), dtype=float32)
----------epoch 650-----------
batched average loss:  -78.71467 minimum candidate loss:  -78.714676
probability converged
strcuture parameter: 
 [[-10.525569    5.7075586]
 [-10.275843    4.9843245]
 [-10.48156     5.599526 ]
 [  5.4009566 -10.328131 ]
 [  5.761761  -10.518393 ]
 [  5.044105  -10.317441 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.715, shape=(), dtype=float32)
----------epoch 700-----------
batched average loss:  -78.715744 minimum candidate loss:  -78.71574
probability converged
strcuture parameter: 
 [[-10.526204    5.7075586]
 [-10.27648     4.9843245]
 [-10.482194    5.599526 ]
 [  5.4009566 -10.328757 ]
 [  5.761761  -10.519022 ]
 [  5.044105  -10.318075 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7159, shape=(), dtype=float32)
----------epoch 750-----------
batched average loss:  -78.71644 minimum candidate loss:  -78.71644
probability converged
strcuture parameter: 
 [[-10.526411    5.7075586]
 [-10.276689    4.9843245]
 [-10.482401    5.599526 ]
 [  5.4009566 -10.32896  ]
 [  5.761761  -10.519226 ]
 [  5.044105  -10.318282 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71636, shape=(), dtype=float32)
----------epoch 800-----------
batched average loss:  -78.71808 minimum candidate loss:  -78.71808
probability converged
strcuture parameter: 
 [[-10.526884    5.7075586]
 [-10.277165    4.9843245]
 [-10.482874    5.599526 ]
 [  5.4009566 -10.329432 ]
 [  5.761761  -10.519699 ]
 [  5.044105  -10.318755 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71822, shape=(), dtype=float32)
----------epoch 850-----------
batched average loss:  -78.72108 minimum candidate loss:  -78.72108
probability converged
strcuture parameter: 
 [[-10.527806    5.7075586]
 [-10.278092    4.9843245]
 [-10.483796    5.599526 ]
 [  5.4009566 -10.330348 ]
 [  5.761761  -10.520617 ]
 [  5.044105  -10.319677 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72122, shape=(), dtype=float32)
----------epoch 900-----------
batched average loss:  -78.72223 minimum candidate loss:  -78.72222
probability converged
strcuture parameter: 
 [[-10.528243    5.7075586]
 [-10.278529    4.9843245]
 [-10.484233    5.599526 ]
 [  5.4009566 -10.330777 ]
 [  5.761761  -10.521051 ]
 [  5.044105  -10.320114 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72227, shape=(), dtype=float32)
----------epoch 950-----------
batched average loss:  -78.72221 minimum candidate loss:  -78.722206
probability converged
strcuture parameter: 
 [[-10.528307    5.7075586]
 [-10.278593    4.9843245]
 [-10.484297    5.599526 ]
 [  5.4009566 -10.330841 ]
 [  5.761761  -10.521115 ]
 [  5.044105  -10.320178 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72247, shape=(), dtype=float32)
----------epoch 1000-----------
batched average loss:  -78.7224 minimum candidate loss:  -78.72239
probability converged
strcuture parameter: 
 [[-10.528347    5.7075586]
 [-10.278633    4.9843245]
 [-10.484337    5.599526 ]
 [  5.4009566 -10.33088  ]
 [  5.761761  -10.521155 ]
 [  5.044105  -10.320218 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.722496, shape=(), dtype=float32)
----------epoch 1050-----------
batched average loss:  -78.72256 minimum candidate loss:  -78.722565
probability converged
strcuture parameter: 
 [[-10.528378    5.7075586]
 [-10.278663    4.9843245]
 [-10.484367    5.599526 ]
 [  5.4009566 -10.330911 ]
 [  5.761761  -10.521186 ]
 [  5.044105  -10.320249 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72257, shape=(), dtype=float32)
----------epoch 1100-----------
batched average loss:  -78.72259 minimum candidate loss:  -78.72259
probability converged
strcuture parameter: 
 [[-10.528438    5.7075586]
 [-10.278724    4.9843245]
 [-10.484427    5.599526 ]
 [  5.4009566 -10.330968 ]
 [  5.761761  -10.521245 ]
 [  5.044105  -10.320309 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72266, shape=(), dtype=float32)
----------epoch 1150-----------
batched average loss:  -78.72268 minimum candidate loss:  -78.72269
probability converged
strcuture parameter: 
 [[-10.528428    5.7075586]
 [-10.278716    4.9843245]
 [-10.484418    5.599526 ]
 [  5.4009566 -10.330958 ]
 [  5.761761  -10.5212345]
 [  5.044105  -10.320299 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72294, shape=(), dtype=float32)
----------epoch 1200-----------
batched average loss:  -78.722916 minimum candidate loss:  -78.72292
probability converged
strcuture parameter: 
 [[-10.528422    5.7075586]
 [-10.27871     4.9843245]
 [-10.484412    5.599526 ]
 [  5.4009566 -10.330953 ]
 [  5.761761  -10.521229 ]
 [  5.044105  -10.320293 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72277, shape=(), dtype=float32)
----------epoch 1250-----------
batched average loss:  -78.722916 minimum candidate loss:  -78.72292
probability converged
strcuture parameter: 
 [[-10.528441    5.7075586]
 [-10.278729    4.9843245]
 [-10.484431    5.599526 ]
 [  5.4009566 -10.330972 ]
 [  5.761761  -10.521248 ]
 [  5.044105  -10.3203125]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72297, shape=(), dtype=float32)
----------epoch 1300-----------
batched average loss:  -78.72317 minimum candidate loss:  -78.723175
probability converged
strcuture parameter: 
 [[-10.528475    5.7075586]
 [-10.278763    4.9843245]
 [-10.484465    5.599526 ]
 [  5.4009566 -10.331005 ]
 [  5.761761  -10.521281 ]
 [  5.044105  -10.320346 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72319, shape=(), dtype=float32)
----------epoch 1350-----------
batched average loss:  -78.723274 minimum candidate loss:  -78.72328
probability converged
strcuture parameter: 
 [[-10.528491    5.7075586]
 [-10.278779    4.9843245]
 [-10.484481    5.599526 ]
 [  5.4009566 -10.331021 ]
 [  5.761761  -10.521297 ]
 [  5.044105  -10.320362 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.723236, shape=(), dtype=float32)
----------epoch 1400-----------
batched average loss:  -78.72357 minimum candidate loss:  -78.72357
probability converged
strcuture parameter: 
 [[-10.528507    5.7075586]
 [-10.278795    4.9843245]
 [-10.484497    5.599526 ]
 [  5.4009566 -10.3310375]
 [  5.761761  -10.521314 ]
 [  5.044105  -10.320378 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72331, shape=(), dtype=float32)
----------epoch 1450-----------
batched average loss:  -78.72329 minimum candidate loss:  -78.7233
probability converged
strcuture parameter: 
 [[-10.528525    5.7075586]
 [-10.278813    4.9843245]
 [-10.484515    5.599526 ]
 [  5.4009566 -10.331057 ]
 [  5.761761  -10.521333 ]
 [  5.044105  -10.320396 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72341, shape=(), dtype=float32)
----------epoch 1500-----------
batched average loss:  -78.72351 minimum candidate loss:  -78.72351
probability converged
strcuture parameter: 
 [[-10.528536    5.7075586]
 [-10.278825    4.9843245]
 [-10.484526    5.599526 ]
 [  5.4009566 -10.331067 ]
 [  5.761761  -10.521343 ]
 [  5.044105  -10.320407 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72351, shape=(), dtype=float32)
----------epoch 1550-----------
batched average loss:  -78.72346 minimum candidate loss:  -78.72346
probability converged
strcuture parameter: 
 [[-10.528565    5.7075586]
 [-10.278853    4.9843245]
 [-10.484555    5.599526 ]
 [  5.4009566 -10.331094 ]
 [  5.761761  -10.521372 ]
 [  5.044105  -10.3204365]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.723625, shape=(), dtype=float32)
----------epoch 1600-----------
batched average loss:  -78.72359 minimum candidate loss:  -78.723595
probability converged
strcuture parameter: 
 [[-10.528572    5.7075586]
 [-10.278861    4.9843245]
 [-10.484562    5.599526 ]
 [  5.4009566 -10.3311   ]
 [  5.761761  -10.5213785]
 [  5.044105  -10.320443 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72358, shape=(), dtype=float32)
----------epoch 1650-----------
batched average loss:  -78.723564 minimum candidate loss:  -78.72356
probability converged
strcuture parameter: 
 [[-10.528581    5.7075586]
 [-10.27887     4.9843245]
 [-10.4845705   5.599526 ]
 [  5.4009566 -10.331109 ]
 [  5.761761  -10.521387 ]
 [  5.044105  -10.320452 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72362, shape=(), dtype=float32)
----------epoch 1700-----------
batched average loss:  -78.723625 minimum candidate loss:  -78.72362
probability converged
strcuture parameter: 
 [[-10.528596    5.7075586]
 [-10.278885    4.9843245]
 [-10.484586    5.599526 ]
 [  5.4009566 -10.331123 ]
 [  5.761761  -10.521401 ]
 [  5.044105  -10.320467 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.723694, shape=(), dtype=float32)
----------epoch 1750-----------
batched average loss:  -78.7238 minimum candidate loss:  -78.72379
probability converged
strcuture parameter: 
 [[-10.528597    5.7075586]
 [-10.278886    4.9843245]
 [-10.484587    5.599526 ]
 [  5.4009566 -10.331124 ]
 [  5.761761  -10.521402 ]
 [  5.044105  -10.320468 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.723694, shape=(), dtype=float32)
----------epoch 1800-----------
batched average loss:  -78.72373 minimum candidate loss:  -78.723724
probability converged
strcuture parameter: 
 [[-10.528607    5.7075586]
 [-10.278896    4.9843245]
 [-10.484597    5.599526 ]
 [  5.4009566 -10.331135 ]
 [  5.761761  -10.521413 ]
 [  5.044105  -10.320478 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72381, shape=(), dtype=float32)
----------epoch 1850-----------
batched average loss:  -78.723816 minimum candidate loss:  -78.72383
probability converged
strcuture parameter: 
 [[-10.528622    5.7075586]
 [-10.278911    4.9843245]
 [-10.4846115   5.599526 ]
 [  5.4009566 -10.331149 ]
 [  5.761761  -10.521427 ]
 [  5.044105  -10.320493 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72381, shape=(), dtype=float32)
----------epoch 1900-----------
batched average loss:  -78.72378 minimum candidate loss:  -78.723785
probability converged
strcuture parameter: 
 [[-10.528623    5.7075586]
 [-10.278912    4.9843245]
 [-10.484612    5.599526 ]
 [  5.4009566 -10.33115  ]
 [  5.761761  -10.521428 ]
 [  5.044105  -10.320494 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72376, shape=(), dtype=float32)
----------epoch 1950-----------
batched average loss:  -78.724014 minimum candidate loss:  -78.72402
probability converged
strcuture parameter: 
 [[-10.52863     5.7075586]
 [-10.278919    4.9843245]
 [-10.48462     5.599526 ]
 [  5.4009566 -10.331158 ]
 [  5.761761  -10.521436 ]
 [  5.044105  -10.320501 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.723885, shape=(), dtype=float32)
----------epoch 1999-----------
batched average loss:  -78.72398 minimum candidate loss:  -78.723976
probability converged
strcuture parameter: 
 [[-10.528627    5.7075586]
 [-10.278916    4.9843245]
 [-10.484617    5.599526 ]
 [  5.4009566 -10.331155 ]
 [  5.761761  -10.521433 ]
 [  5.044105  -10.320498 ]]
tf.Tensor([1 1 1 0 0 0], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72387, shape=(), dtype=float32)
Energy: tf.Tensor(-78.72387, shape=(), dtype=float32)
Ref energy: -74.38714627
Error rate: tf.Tensor(0.038512535, shape=(), dtype=float32)
       ┌────────────┐ ┌──────────────┐ ┌────────────┐ ┌─────────────┐»
 q_0: ─┤ Rx(1.7387) ├─┤ Ry(-0.10498) ├─┤ Rz(3.7109) ├─┤ Rx(0.29494) ├»
      ┌┴────────────┤ ├─────────────┬┘ ├────────────┤ └─────────────┘»
 q_1: ┤ Rx(-2.3943) ├─┤ Ry(-4.7412) ├──┤ Rz(1.2246) ├────────■───────»
      ├─────────────┤ ├─────────────┤  ├───────────┬┘        │       »
 q_2: ┤ Rx(0.41345) ├─┤ Ry(-4.3094) ├──┤ Rz(3.275) ├─────────■───────»
      ├─────────────┤ └┬────────────┤ ┌┴───────────┴┐                »
 q_3: ┤ Rx(-3.1302) ├──┤ Ry(3.1153) ├─┤ Rz(-4.0406) ├────────■───────»
      ├─────────────┤ ┌┴────────────┤ ├─────────────┴┐       │       »
 q_4: ┤ Rx(-1.1319) ├─┤ Ry(-2.1099) ├─┤ Rz(-0.32559) ├───────■───────»
      ├─────────────┤ ├─────────────┤ ├─────────────┬┘               »
 q_5: ┤ Rx(-1.6382) ├─┤ Ry(-2.0833) ├─┤ Rz(-2.1281) ├────────■───────»
      ├─────────────┤ ├─────────────┤ └┬────────────┤        │       »
 q_6: ┤ Rx(-1.0513) ├─┤ Ry(-3.5468) ├──┤ Rz(2.2417) ├────────■───────»
      ├─────────────┤ ├─────────────┤ ┌┴────────────┤                »
 q_7: ┤ Rx(-3.1408) ├─┤ Ry(-3.1417) ├─┤ Rz(-2.6045) ├────────■───────»
      ├─────────────┴┐└┬────────────┤ ├─────────────┤        │       »
 q_8: ┤ Rx(-0.52381) ├─┤ Ry(1.4607) ├─┤ Rz(-3.7051) ├────────■───────»
      └┬────────────┬┘┌┴────────────┴┐└┬───────────┬┘                »
 q_9: ─┤ Rx(3.1872) ├─┤ Ry(0.022439) ├─┤ Rz(5.175) ├─────────■───────»
      ┌┴────────────┤ ├─────────────┬┘ ├───────────┴┐        │       »
q_10: ┤ Rx(-4.2039) ├─┤ Ry(0.29662) ├──┤ Rz(-1.496) ├────────■───────»
      └┬────────────┤ └┬────────────┤  ├────────────┤  ┌────────────┐»
q_11: ─┤ Rx(3.1853) ├──┤ Ry(2.7365) ├──┤ Rz(1.6614) ├──┤ Rx(2.7298) ├»
       └────────────┘  └────────────┘  └────────────┘  └────────────┘»
«      ┌─────────────┐┌──────────────┐                    ┌────────────┐  »
« q_0: ┤ Ry(-4.7484) ├┤ Rz(-0.85762) ├────────────────■───┤ Rx(4.1793) ├──»
«      ├─────────────┤└┬────────────┬┘ ┌────────────┐ │  ┌┴────────────┤  »
« q_1: ┤ Rx(-4.3014) ├─┤ Ry(-4.422) ├──┤ Rz(2.6557) ├─■──┤ Rx(-4.1653) ├──»
«      ├─────────────┤┌┴────────────┤  ├────────────┤    ├─────────────┴┐ »
« q_2: ┤ Rx(-3.3703) ├┤ Ry(0.88736) ├──┤ Rz(2.7924) ├─■──┤ Rx(-0.85223) ├─»
«      ├─────────────┤└┬────────────┤ ┌┴────────────┤ │  ├─────────────┬┘ »
« q_3: ┤ Rx(-4.0114) ├─┤ Ry(2.0729) ├─┤ Rz(-1.9398) ├─■──┤ Rx(-3.3764) ├──»
«      ├─────────────┤┌┴────────────┤ ├─────────────┤   ┌┴─────────────┴─┐»
« q_4: ┤ Rx(-1.3884) ├┤ Ry(-3.2132) ├─┤ Rz(0.94361) ├─■─┤ Rx(-0.0027755) ├»
«      ├─────────────┤└┬────────────┤ └┬────────────┤ │ └┬──────────────┬┘»
« q_5: ┤ Rx(-3.6411) ├─┤ Ry(-3.588) ├──┤ Rz(3.0871) ├─■──┤ Rx(0.014925) ├─»
«      └┬────────────┤┌┴────────────┤ ┌┴────────────┤    └┬────────────┬┘ »
« q_6: ─┤ Rx(3.1055) ├┤ Ry(-3.2262) ├─┤ Rz(-4.9389) ├─■───┤ Rx(3.1132) ├──»
«      ┌┴────────────┤├─────────────┤ └┬────────────┤ │  ┌┴────────────┤  »
« q_7: ┤ Rx(-2.0423) ├┤ Ry(-3.1803) ├──┤ Rz(-1.925) ├─■──┤ Rx(0.88556) ├──»
«      ├─────────────┤├─────────────┤  ├────────────┤    └┬────────────┤  »
« q_8: ┤ Rx(-2.2109) ├┤ Ry(-1.4318) ├──┤ Rz(1.3438) ├─■───┤ Rx(3.1882) ├──»
«      └┬────────────┤├─────────────┴┐ ├────────────┤ │   ├────────────┤  »
« q_9: ─┤ Rx(2.9911) ├┤ Ry(-0.18306) ├─┤ Rz(4.3884) ├─■───┤ Rx(5.8256) ├──»
«       ├────────────┤├─────────────┬┘┌┴────────────┤    ┌┴────────────┴┐ »
«q_10: ─┤ Rx(-3.517) ├┤ Ry(-3.3247) ├─┤ Rz(-2.3367) ├─■──┤ Rx(-0.68689) ├─»
«       ├────────────┤├─────────────┤ └─────────────┘ │  └┬────────────┬┘ »
«q_11: ─┤ Ry(3.1258) ├┤ Rz(0.18182) ├─────────────────■───┤ Rx(2.1697) ├──»
«       └────────────┘└─────────────┘                     └────────────┘  »
«        ┌─────────────┐   ┌────────────┐ ┌──────────────┐┌─────────────┐ »
« q_0: ──┤ Ry(-3.0482) ├───┤ Rz(4.3551) ├─┤ Rx(-0.18402) ├┤ Ry(-5.4341) ├─»
«        └┬────────────┤   ├───────────┬┘ └──────────────┘├─────────────┤ »
« q_1: ───┤ Ry(-1.203) ├───┤ Rz(4.402) ├─────────■────────┤ Rx(-2.8799) ├─»
«         ├────────────┤  ┌┴───────────┴┐        │        ├─────────────┤ »
« q_2: ───┤ Ry(1.8042) ├──┤ Rz(-1.2444) ├────────■────────┤ Rx(0.30658) ├─»
«        ┌┴────────────┴┐ └┬────────────┤                 ├─────────────┤ »
« q_3: ──┤ Ry(-0.84006) ├──┤ Rz(5.4433) ├────────■────────┤ Rx(-2.9355) ├─»
«      ┌─┴──────────────┴┐┌┴────────────┴┐       │        └┬────────────┤ »
« q_4: ┤ Ry(-0.00028883) ├┤ Rz(-0.14542) ├───────■─────────┤ Rx(3.2292) ├─»
«      └─┬─────────────┬─┘└┬────────────┬┘                 ├────────────┤ »
« q_5: ──┤ Ry(-3.1694) ├───┤ Rz(1.8052) ├────────■─────────┤ Rx(3.1079) ├─»
«        ├─────────────┤   ├────────────┤        │        ┌┴────────────┤ »
« q_6: ──┤ Ry(-2.7661) ├───┤ Rz(2.0359) ├────────■────────┤ Rx(-1.8929) ├─»
«        ├─────────────┤  ┌┴────────────┤                 └┬────────────┤ »
« q_7: ──┤ Ry(-4.5371) ├──┤ Rz(-1.9426) ├────────■─────────┤ Rx(3.4186) ├─»
«        ├─────────────┤  ├─────────────┤        │        ┌┴────────────┤ »
« q_8: ──┤ Ry(-3.0675) ├──┤ Rz(0.10477) ├────────■────────┤ Rx(-3.1173) ├─»
«        ├─────────────┤  └┬────────────┤                 ├─────────────┴┐»
« q_9: ──┤ Ry(-4.5189) ├───┤ Rz(1.1692) ├────────■────────┤ Rx(-0.79689) ├»
«        ├─────────────┤  ┌┴────────────┤        │        ├─────────────┬┘»
«q_10: ──┤ Ry(-0.4043) ├──┤ Rz(-1.6442) ├────────■────────┤ Rx(-6.6286) ├─»
«        └─┬──────────┬┘  └┬────────────┤ ┌─────────────┐ └┬────────────┤ »
«q_11: ────┤ Ry(3.31) ├────┤ Rz(2.8501) ├─┤ Rx(0.98295) ├──┤ Ry(2.9877) ├─»
«          └──────────┘    └────────────┘ └─────────────┘  └────────────┘ »
«       ┌────────────┐                     ┌────────────┐ ┌─────────────┐»
« q_0: ─┤ Rz(-2.277) ├──────────────────■──┤ Rx(4.8468) ├─┤ Ry(-4.2166) ├»
«       ├────────────┤  ┌────────────┐  │ ┌┴────────────┤ └┬────────────┤»
« q_1: ─┤ Ry(3.4873) ├──┤ Rz(3.5372) ├──■─┤ Rx(-6.2861) ├──┤ Ry(3.0562) ├»
«      ┌┴────────────┴┐┌┴────────────┤    ├─────────────┤  ├────────────┤»
« q_2: ┤ Ry(-0.24756) ├┤ Rz(-1.2559) ├──■─┤ Rx(-0.1469) ├──┤ Ry(1.8721) ├»
«      ├─────────────┬┘└┬────────────┤  │ ├─────────────┤  ├────────────┤»
« q_3: ┤ Ry(0.45395) ├──┤ Rz(5.2339) ├──■─┤ Rx(-3.5828) ├──┤ Ry(3.6634) ├»
«      ├─────────────┤ ┌┴────────────┴┐   ├─────────────┴┐┌┴────────────┤»
« q_4: ┤ Ry(-3.1976) ├─┤ Rz(-0.95898) ├─■─┤ Rx(-0.71529) ├┤ Ry(-4.1886) ├»
«      ├─────────────┤ └┬────────────┬┘ │ └┬────────────┬┘├─────────────┤»
« q_5: ┤ Ry(-3.1957) ├──┤ Rz(1.8134) ├──■──┤ Rx(1.5096) ├─┤ Ry(-3.5114) ├»
«      ├─────────────┤ ┌┴────────────┤     ├────────────┤ ├─────────────┤»
« q_6: ┤ Ry(-1.9779) ├─┤ Rz(0.37254) ├──■──┤ Rx(1.3102) ├─┤ Ry(-4.4412) ├»
«      ├─────────────┤ └┬────────────┤  │ ┌┴────────────┤ └┬────────────┤»
« q_7: ┤ Ry(0.24378) ├──┤ Rz(2.7752) ├──■─┤ Rx(-1.7295) ├──┤ Ry(2.4082) ├»
«      ├─────────────┤ ┌┴────────────┤    ├─────────────┤ ┌┴────────────┤»
« q_8: ┤ Ry(-3.0658) ├─┤ Rz(-2.6581) ├──■─┤ Rx(-6.2553) ├─┤ Ry(-3.1154) ├»
«      ├─────────────┤ ├─────────────┴┐ │ └┬────────────┤ └┬────────────┤»
« q_9: ┤ Ry(-4.3811) ├─┤ Rz(-0.14585) ├─■──┤ Rx(4.0534) ├──┤ Ry(2.5395) ├»
«      └┬────────────┤ └┬────────────┬┘    ├────────────┤  ├───────────┬┘»
«q_10: ─┤ Ry(-3.256) ├──┤ Rz(1.2095) ├──■──┤ Rx(3.7823) ├──┤ Ry(0.249) ├─»
«       ├────────────┤  └────────────┘  │ ┌┴────────────┤  ├───────────┴┐»
«q_11: ─┤ Rz(2.7186) ├──────────────────■─┤ Rx(-3.9036) ├──┤ Ry(3.2672) ├»
«       └────────────┘                    └─────────────┘  └────────────┘»
«       ┌────────────┐  ┌────────────┐ ┌─────────────┐ ┌─────────────┐»
« q_0: ─┤ Rz(2.9356) ├──┤ Rx(0.2172) ├─┤ Ry(-2.2743) ├─┤ Rz(-1.2056) ├»
«       ├────────────┤  └────────────┘ ├─────────────┤ └┬────────────┤»
« q_1: ─┤ Rz(2.8676) ├────────■────────┤ Rx(-3.9358) ├──┤ Ry(2.2853) ├»
«       ├────────────┤        │        ├─────────────┤  ├───────────┬┘»
« q_2: ─┤ Rz(1.6613) ├────────■────────┤ Rx(-1.9354) ├──┤ Ry(4.469) ├─»
«       ├────────────┤                ┌┴─────────────┴┐ ├───────────┴┐»
« q_3: ─┤ Rz(2.6596) ├────────■───────┤ Rx(0.0079161) ├─┤ Ry(3.1025) ├»
«      ┌┴────────────┤        │       └─┬────────────┬┘┌┴────────────┤»
« q_4: ┤ Rz(-3.9475) ├────────■─────────┤ Rx(3.1522) ├─┤ Ry(-3.1487) ├»
«      ├─────────────┤                  ├────────────┤ ├─────────────┤»
« q_5: ┤ Rz(0.47677) ├────────■─────────┤ Rx(3.4533) ├─┤ Ry(-3.2904) ├»
«      ├─────────────┴┐       │        ┌┴────────────┤ ├─────────────┤»
« q_6: ┤ Rz(-0.86286) ├───────■────────┤ Rx(0.50136) ├─┤ Ry(-1.5579) ├»
«      ├─────────────┬┘                ├─────────────┤ ├─────────────┤»
« q_7: ┤ Rz(0.12141) ├────────■────────┤ Rx(0.46012) ├─┤ Ry(-1.6656) ├»
«      ├─────────────┤        │        ├─────────────┤ └┬────────────┤»
« q_8: ┤ Rz(-3.4134) ├────────■────────┤ Rx(-10.001) ├──┤ Ry(1.7709) ├»
«      ├─────────────┴┐                ├─────────────┴┐┌┴────────────┤»
« q_9: ┤ Rz(-0.17623) ├───────■────────┤ Rx(-0.76354) ├┤ Ry(-1.9154) ├»
«      ├─────────────┬┘       │       ┌┴──────────────┤└┬────────────┤»
«q_10: ┤ Rz(-3.3803) ├────────■───────┤ Rx(-0.034368) ├─┤ Ry(3.4222) ├»
«      ├─────────────┤ ┌─────────────┐└─┬────────────┬┘ ├────────────┤»
«q_11: ┤ Rz(-0.1501) ├─┤ Rx(-3.9522) ├──┤ Ry(3.1164) ├──┤ Rz(1.8662) ├»
«      └─────────────┘ └─────────────┘  └────────────┘  └────────────┘»
«                           ┌────────────┐  ┌─────────────┐  ┌───────────┐  »
« q_0: ─────────────────■───┤ Rx(5.8466) ├──┤ Ry(-5.0139) ├──┤ Rz(4.064) ├──»
«       ┌────────────┐  │  ┌┴────────────┤  └┬───────────┬┘ ┌┴───────────┴┐ »
« q_1: ─┤ Rz(3.7125) ├──■──┤ Rx(-3.4833) ├───┤ Ry(-2.48) ├──┤ Rz(-1.6024) ├─»
«      ┌┴────────────┤     └┬────────────┤ ┌─┴───────────┴─┐├─────────────┴┐»
« q_2: ┤ Rz(0.43852) ├──■───┤ Rx(3.1024) ├─┤ Ry(-0.054342) ├┤ Rz(-0.30274) ├»
«      ├─────────────┴┐ │  ┌┴────────────┤ ├───────────────┤└┬────────────┬┘»
« q_3: ┤ Rz(-0.86059) ├─■──┤ Rx(-3.1534) ├─┤ Ry(0.0066253) ├─┤ Rz(3.3986) ├─»
«      └┬────────────┬┘    └┬────────────┤ └┬─────────────┬┘┌┴────────────┤ »
« q_4: ─┤ Rz(-3.041) ├──■───┤ Rx(2.9993) ├──┤ Ry(-3.0377) ├─┤ Rz(-3.7787) ├─»
«       ├────────────┤  │   ├────────────┤  ├─────────────┤ └┬────────────┤ »
« q_5: ─┤ Rz(3.1372) ├──■───┤ Rx(3.3361) ├──┤ Ry(-3.5867) ├──┤ Rz(4.1795) ├─»
«      ┌┴────────────┤     ┌┴────────────┤  ├─────────────┤ ┌┴────────────┤ »
« q_6: ┤ Rz(-2.5598) ├──■──┤ Rx(-3.1375) ├──┤ Ry(-3.1447) ├─┤ Rz(-1.6813) ├─»
«      ├─────────────┤  │  ├─────────────┤  ├─────────────┤ ├─────────────┴┐»
« q_7: ┤ Rz(0.52651) ├──■──┤ Rx(-5.2392) ├──┤ Ry(-3.9868) ├─┤ Rz(-0.48221) ├»
«      ├─────────────┴┐    ├─────────────┴┐ └┬────────────┤ ├─────────────┬┘»
« q_8: ┤ Rz(-0.39746) ├─■──┤ Rx(-0.37665) ├──┤ Ry(4.0549) ├─┤ Rz(-3.3666) ├─»
«      ├─────────────┬┘ │ ┌┴──────────────┤  ├────────────┤ ├─────────────┤ »
« q_9: ┤ Rz(-2.3511) ├──■─┤ Rx(-0.048863) ├──┤ Ry(-3.141) ├─┤ Rz(-5.1279) ├─»
«      ├─────────────┤    └┬─────────────┬┘┌─┴────────────┴┐├─────────────┤ »
«q_10: ┤ Rz(-3.7674) ├──■──┤ Rx(0.05765) ├─┤ Ry(-0.023905) ├┤ Rz(-4.0904) ├─»
«      └─────────────┘  │  └┬────────────┤ └─┬────────────┬┘└┬────────────┤ »
«q_11: ─────────────────■───┤ Rx(-4.139) ├───┤ Ry(3.6691) ├──┤ Rz(1.6492) ├─»
«                           └────────────┘   └────────────┘  └────────────┘ »
«      ┌─────────────┐ ┌─────────────┐  ┌────────────┐                    »
« q_0: ┤ Rx(-1.2515) ├─┤ Ry(-3.2837) ├──┤ Rz(3.4314) ├──────────────────■─»
«      └─────────────┘ ├─────────────┤  ├────────────┤ ┌──────────────┐ │ »
« q_1: ───────■────────┤ Rx(-5.0558) ├──┤ Ry(5.4589) ├─┤ Rz(-0.97205) ├─■─»
«             │        ├─────────────┤ ┌┴────────────┴┐├─────────────┬┘   »
« q_2: ───────■────────┤ Rx(-3.6082) ├─┤ Ry(-0.36548) ├┤ Rz(-3.0052) ├──■─»
«                      ├─────────────┤ └┬────────────┬┘└┬────────────┤  │ »
« q_3: ───────■────────┤ Rx(-3.5874) ├──┤ Ry(4.0274) ├──┤ Rz(3.7093) ├──■─»
«             │        └┬────────────┤ ┌┴────────────┤  ├───────────┬┘    »
« q_4: ───────■─────────┤ Rx(3.2081) ├─┤ Ry(0.36438) ├──┤ Rz(6.043) ├───■─»
«                      ┌┴────────────┤ ├─────────────┤  ├───────────┴┐  │ »
« q_5: ───────■────────┤ Rx(-2.8578) ├─┤ Ry(-2.7423) ├──┤ Rz(1.3388) ├──■─»
«             │       ┌┴─────────────┴┐├─────────────┴┐ ├────────────┤    »
« q_6: ───────■───────┤ Rx(-0.013198) ├┤ Ry(0.072027) ├─┤ Rz(1.6396) ├──■─»
«                     └┬─────────────┬┘├─────────────┬┘┌┴────────────┤  │ »
« q_7: ───────■────────┤ Rx(-4.7139) ├─┤ Ry(-4.3254) ├─┤ Rz(0.59042) ├──■─»
«             │        ├─────────────┤ ├─────────────┴┐├─────────────┤    »
« q_8: ───────■────────┤ Rx(-1.5577) ├─┤ Ry(-0.86471) ├┤ Rz(-5.5912) ├──■─»
«                      ├─────────────┤ ├─────────────┬┘├─────────────┤  │ »
« q_9: ───────■────────┤ Rx(0.62125) ├─┤ Ry(-6.4683) ├─┤ Rz(0.66348) ├──■─»
«             │        ├─────────────┴┐├─────────────┤ └┬────────────┤    »
«q_10: ───────■────────┤ Rx(-0.57946) ├┤ Ry(0.53578) ├──┤ Rz(-3.708) ├──■─»
«      ┌─────────────┐ └┬────────────┬┘├─────────────┤  └────────────┘  │ »
«q_11: ┤ Rx(-2.5796) ├──┤ Ry(4.0921) ├─┤ Rz(-4.3358) ├──────────────────■─»
«      └─────────────┘  └────────────┘ └─────────────┘                    »
«       ┌────────────┐ ┌─────────────┐ ┌────────────┐  ┌────────────┐ »
« q_0: ─┤ Rx(1.1122) ├─┤ Ry(-6.0097) ├─┤ Rz(4.7972) ├──┤ Rx(5.0335) ├─»
«      ┌┴────────────┤ └┬────────────┤┌┴────────────┤ ┌┴────────────┤ »
« q_1: ┤ Rx(-3.0146) ├──┤ Ry(4.5006) ├┤ Rz(-3.3864) ├─┤ Rx(-2.5157) ├─»
«      ├─────────────┤  ├────────────┤└┬────────────┤ ├─────────────┴┐»
« q_2: ┤ Rx(-2.1722) ├──┤ Ry(-1.456) ├─┤ Rz(2.1308) ├─┤ Rx(-0.46713) ├»
«      ├─────────────┤  ├────────────┤┌┴────────────┤ ├─────────────┬┘»
« q_3: ┤ Rx(-1.5216) ├──┤ Ry(3.9382) ├┤ Rz(-1.2076) ├─┤ Rx(-5.1208) ├─»
«      ├─────────────┤  ├───────────┬┘└┬────────────┤ └┬────────────┤ »
« q_4: ┤ Rx(-6.6212) ├──┤ Ry(5.825) ├──┤ Rz(2.8647) ├──┤ Rx(2.7166) ├─»
«      ├─────────────┤  ├───────────┴┐┌┴────────────┴┐┌┴────────────┤ »
« q_5: ┤ Rx(-3.7077) ├──┤ Ry(-3.793) ├┤ Rz(-0.23748) ├┤ Rx(-3.6858) ├─»
«      └┬────────────┤  ├────────────┤├─────────────┬┘├─────────────┤ »
« q_6: ─┤ Rx(-1.598) ├──┤ Ry(1.9254) ├┤ Rz(-4.8908) ├─┤ Rx(-1.4325) ├─»
«      ┌┴────────────┤ ┌┴────────────┤├─────────────┤ ├─────────────┤ »
« q_7: ┤ Rx(-8.1563) ├─┤ Ry(-5.1987) ├┤ Rz(-7.1954) ├─┤ Rx(-4.9164) ├─»
«      ├─────────────┤ ├─────────────┤├─────────────┴┐├─────────────┤ »
« q_8: ┤ Rx(-2.0757) ├─┤ Ry(-5.7283) ├┤ Rz(0.049284) ├┤ Rx(-1.8947) ├─»
«      ├─────────────┴┐├─────────────┤├─────────────┬┘└┬────────────┤ »
« q_9: ┤ Rx(-0.39357) ├┤ Ry(-3.3623) ├┤ Rz(-6.9053) ├──┤ Rx(3.5652) ├─»
«      └┬────────────┬┘└┬────────────┤└┬───────────┬┘  ├────────────┤ »
«q_10: ─┤ Rx(3.2634) ├──┤ Ry(3.0646) ├─┤ Rz(-3.75) ├───┤ Rx(2.7165) ├─»
«       ├────────────┤  ├────────────┤┌┴───────────┴┐  ├────────────┤ »
«q_11: ─┤ Rx(-1.611) ├──┤ Ry(2.7252) ├┤ Rz(-1.1733) ├──┤ Rx(1.4235) ├─»
«       └────────────┘  └────────────┘└─────────────┘  └────────────┘ »
«      ┌─────────────┐  ┌────────────┐                                        »
« q_0: ┤ Ry(-2.9095) ├──┤ Rz(1.1423) ├──■────────────────────────────────■──■─»
«      ├─────────────┤ ┌┴────────────┤  │                                │  │ »
« q_1: ┤ Ry(-2.0678) ├─┤ Rz(-1.0612) ├──■──■────────■────────────────────┼──┼─»
«      └┬────────────┤ ├─────────────┤     │        │                    │  │ »
« q_2: ─┤ Ry(1.6661) ├─┤ Rz(0.95989) ├─────■──■─────┼────────────────────┼──■─»
«       ├────────────┤ └┬────────────┤        │     │                    │    »
« q_3: ─┤ Ry(1.2433) ├──┤ Rz(4.8994) ├────────■──■──■─────■──────────────┼────»
«       ├────────────┤ ┌┴────────────┤           │        │              │    »
« q_4: ─┤ Ry(1.2074) ├─┤ Rz(-2.7238) ├───────────■──■─────┼──────────────┼────»
«      ┌┴────────────┤ └┬────────────┤              │     │              │    »
« q_5: ┤ Ry(-3.8151) ├──┤ Rz(5.5058) ├──────────────■──■──■─────■────────┼────»
«      ├─────────────┤┌─┴────────────┴┐                │        │        │    »
« q_6: ┤ Ry(-4.6028) ├┤ Rz(-0.073569) ├────────────────■──■─────┼────────┼────»
«      ├─────────────┤└┬─────────────┬┘                   │     │        │    »
« q_7: ┤ Ry(-8.5219) ├─┤ Rz(-2.9948) ├────────────────────■──■──■─────■──┼────»
«      ├─────────────┤ └┬────────────┤                       │        │  │    »
« q_8: ┤ Ry(-4.1868) ├──┤ Rz(1.9123) ├───────────────────────■──■─────┼──┼────»
«      └┬────────────┤  ├────────────┤                          │     │  │    »
« q_9: ─┤ Ry(0.7911) ├──┤ Rz(5.1367) ├──────────────────────────■──■──■──┼──■─»
«       ├────────────┤ ┌┴────────────┴┐                            │     │  │ »
«q_10: ─┤ Ry(1.9749) ├─┤ Rz(-0.35523) ├────────────────────────────■──■──┼──┼─»
«       ├────────────┤ ├──────────────┤                               │  │  │ »
«q_11: ─┤ Ry(1.9468) ├─┤ Rz(-0.38098) ├───────────────────────────────■──■──■─»
«       └────────────┘ └──────────────┘                                       »
«                                                                           »
« q_0: ───────────────────■────────■────────────────────────────────────────»
«                         │        │                                        »
« q_1: ────■────────■─────┼────────┼──────────────────────────────────────■─»
«          │        │     │        │                                      │ »
« q_2: ─■──┼─────■──┼─────┼────────┼──────────────────────────────────────┼─»
«       │  │     │  │     │        │                                      │ »
« q_3: ─┼──┼─────┼──┼─────┼────────■─────────────────────────────■────────┼─»
«       │  │     │  │     │ ┌─────────────┐ ┌────────────┐       │        │ »
« q_4: ─■──┼──■──┼──■──■──┼─┤ Rx(-3.1424) ├─┤ Ry(3.1449) ├───────┼────────┼─»
«          │  │  │     │  │ └─────────────┘┌┴────────────┤       │        │ »
« q_5: ────┼──┼──■─────┼──┼────────■───────┤ Rx(-3.1416) ├───────┼────────┼─»
«          │  │        │  │        │       └─────────────┘       │        │ »
« q_6: ────┼──■──■─────┼──┼────────┼─────────────────────────────■────────┼─»
«          │     │     │  │        │                      ┌─────────────┐ │ »
« q_7: ────┼─────┼─────■──┼────────┼──────────────■───────┤ Rx(-3.1257) ├─┼─»
«          │     │        │        │              │       └─────────────┘ │ »
« q_8: ────┼─────■──■─────┼────────■──────────────┼──────────────■────────┼─»
«          │        │     │                       │              │        │ »
« q_9: ────┼────────┼─────┼───────────────────────┼──────────────┼────────┼─»
«          │        │     │                       │              │        │ »
«q_10: ────┼────────■─────■───────────────────────■──────────────┼────────■─»
«          │                                                     │          »
«q_11: ────■─────────────────────────────────────────────────────■──────────»
«                                                                           »
«                                                                             »
« q_0: ─────────────────────────────────────────────────────────────────────■─»
«      ┌─────────────┐  ┌─────────────┐    ┌────────────┐                   │ »
« q_1: ┤ Rx(-3.1444) ├──┤ Ry(-6.2834) ├────┤ Rz(6.8454) ├───────────────────┼─»
«      └─────────────┘  └┬───────────┬┘    ├────────────┤   ┌───────────┐   │ »
« q_2: ───────■──────────┤ Rx(3.199) ├─────┤ Ry(3.1678) ├───┤ Rz(6.674) ├───┼─»
«             │          ├───────────┴┐    ├────────────┤   ├───────────┴┐  │ »
« q_3: ───────┼──────────┤ Rx(3.2508) ├────┤ Ry(4.7246) ├───┤ Rz(1.0712) ├──┼─»
«             │         ┌┴────────────┤    └────────────┘   └────────────┘  │ »
« q_4: ───────┼─────────┤ Rz(-1.8199) ├─────────────────────────────────────┼─»
«             │       ┌─┴─────────────┴─┐ ┌──────────────┐                  │ »
« q_5: ───────┼───────┤ Ry(-7.8745e-06) ├─┤ Rz(-0.49597) ├──────────────────┼─»
«             │       └─────────────────┘ └──────────────┘  ┌────────────┐  │ »
« q_6: ───────┼──────────────────────────────────■──────────┤ Rx(3.1416) ├──┼─»
«             │          ┌────────────┐          │          ├────────────┤  │ »
« q_7: ───────┼──────────┤ Ry(3.1329) ├──────────┼──────────┤ Rz(3.6979) ├──┼─»
«             │         ┌┴────────────┤          │         ┌┴────────────┴┐ │ »
« q_8: ───────┼─────────┤ Rx(-7.2805) ├──────────┼─────────┤ Ry(-0.19892) ├─┼─»
«             │         └─────────────┘          │         └──────────────┘ │ »
« q_9: ───────┼──────────────────────────────────■──────────────────────────■─»
«             │         ┌─────────────┐    ┌────────────┐   ┌────────────┐    »
«q_10: ───────┼─────────┤ Rx(-3.1416) ├────┤ Ry(3.1416) ├───┤ Rz(2.0481) ├────»
«             │         └┬────────────┤  ┌─┴────────────┴─┐┌┴────────────┤    »
«q_11: ───────■──────────┤ Rx(3.1416) ├──┤ Ry(8.8466e-08) ├┤ Rz(-3.9125) ├────»
«                        └────────────┘  └────────────────┘└─────────────┘    »
«       ┌────────────┐┌────────────┐┌─────────────┐
« q_0: ─┤ Rx(4.7202) ├┤ Ry(2.9221) ├┤ Rz(-1.9588) ├
«       └────────────┘└────────────┘└─────────────┘
« q_1: ────────────────────────────────────────────
«                                                  
« q_2: ────────────────────────────────────────────
«                                                  
« q_3: ────────────────────────────────────────────
«                                                  
« q_4: ────────────────────────────────────────────
«                                                  
« q_5: ────────────────────────────────────────────
«       ┌────────────┐┌────────────┐               
« q_6: ─┤ Ry(3.1417) ├┤ Rz(2.0332) ├───────────────
«       └────────────┘└────────────┘               
« q_7: ────────────────────────────────────────────
«      ┌─────────────┐                             
« q_8: ┤ Rz(-0.4948) ├─────────────────────────────
«      ├─────────────┤┌────────────┐┌─────────────┐
« q_9: ┤ Rx(-3.1416) ├┤ Ry(3.1416) ├┤ Rz(-1.6568) ├
«      └─────────────┘└────────────┘└─────────────┘
«q_10: ────────────────────────────────────────────
«                                                  
«q_11: ────────────────────────────────────────────
«                                                  
