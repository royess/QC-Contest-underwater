Train hybrid.
----------epoch 0-----------
batched average loss:  -43.67207 minimum candidate loss:  -45.98958
probability converged
strcuture parameter: 
 [[0.4000106  1.5999894 ]
 [0.40006918 1.5999308 ]
 [0.4000092  1.5999908 ]
 [1.5999874  0.4000126 ]
 [1.599992   0.4000079 ]
 [0.4001549  1.5998452 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-51.06404, shape=(), dtype=float32)
----------epoch 50-----------
batched average loss:  -77.5774 minimum candidate loss:  -77.57741
probability converged
strcuture parameter: 
 [[-7.9860325  5.6548767]
 [-7.839538   5.0996523]
 [-8.057536   5.784244 ]
 [ 5.4909935 -7.914872 ]
 [ 5.883305  -8.083391 ]
 [-7.8299704  5.039535 ]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-77.95426, shape=(), dtype=float32)
----------epoch 100-----------
batched average loss:  -78.55353 minimum candidate loss:  -78.55351
probability converged
strcuture parameter: 
 [[-8.8953495  5.6824713]
 [-8.750829   5.1244187]
 [-8.965733   5.8125587]
 [ 5.5176167 -8.821388 ]
 [ 5.912098  -8.990245 ]
 [-8.738116   5.0638266]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.59556, shape=(), dtype=float32)
----------epoch 150-----------
batched average loss:  -78.71899 minimum candidate loss:  -78.71899
probability converged
strcuture parameter: 
 [[-8.998392   5.6826453]
 [-8.854185   5.1245756]
 [-9.068609   5.812737 ]
 [ 5.517784  -8.924078 ]
 [ 5.9122796 -9.092947 ]
 [-8.84103    5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.71927, shape=(), dtype=float32)
----------epoch 200-----------
batched average loss:  -78.72235 minimum candidate loss:  -78.72235
probability converged
strcuture parameter: 
 [[-9.001148   5.6826453]
 [-8.857266   5.1245756]
 [-9.071361   5.812737 ]
 [ 5.517784  -8.9268265]
 [ 5.9122796 -9.0956955]
 [-8.843781   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72247, shape=(), dtype=float32)
----------epoch 250-----------
batched average loss:  -78.72731 minimum candidate loss:  -78.72732
probability converged
strcuture parameter: 
 [[-9.002849   5.6826453]
 [-8.859      5.1245756]
 [-9.073058   5.812737 ]
 [ 5.517784  -8.928522 ]
 [ 5.9122796 -9.097391 ]
 [-8.845571   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72751, shape=(), dtype=float32)
----------epoch 300-----------
batched average loss:  -78.72931 minimum candidate loss:  -78.72931
probability converged
strcuture parameter: 
 [[-9.003885   5.6826453]
 [-8.86004    5.1245756]
 [-9.074095   5.812737 ]
 [ 5.517784  -8.929559 ]
 [ 5.9122796 -9.098428 ]
 [-8.846613   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.72956, shape=(), dtype=float32)
----------epoch 350-----------
batched average loss:  -78.73006 minimum candidate loss:  -78.730064
probability converged
strcuture parameter: 
 [[-9.004071   5.6826453]
 [-8.860227   5.1245756]
 [-9.074281   5.812737 ]
 [ 5.517784  -8.929745 ]
 [ 5.9122796 -9.098614 ]
 [-8.846799   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730064, shape=(), dtype=float32)
----------epoch 400-----------
batched average loss:  -78.730286 minimum candidate loss:  -78.730286
probability converged
strcuture parameter: 
 [[-9.0041     5.6826453]
 [-8.860254   5.1245756]
 [-9.074309   5.812737 ]
 [ 5.517784  -8.929773 ]
 [ 5.9122796 -9.098642 ]
 [-8.8468275  5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73021, shape=(), dtype=float32)
----------epoch 450-----------
batched average loss:  -78.7304 minimum candidate loss:  -78.7304
probability converged
strcuture parameter: 
 [[-9.004142   5.6826453]
 [-8.860297   5.1245756]
 [-9.074351   5.812737 ]
 [ 5.517784  -8.929815 ]
 [ 5.9122796 -9.098684 ]
 [-8.846869   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73047, shape=(), dtype=float32)
----------epoch 500-----------
batched average loss:  -78.73032 minimum candidate loss:  -78.730316
probability converged
strcuture parameter: 
 [[-9.004184   5.6826453]
 [-8.860339   5.1245756]
 [-9.074393   5.812737 ]
 [ 5.517784  -8.929857 ]
 [ 5.9122796 -9.098726 ]
 [-8.846911   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73045, shape=(), dtype=float32)
----------epoch 550-----------
batched average loss:  -78.730446 minimum candidate loss:  -78.73044
probability converged
strcuture parameter: 
 [[-9.004199   5.6826453]
 [-8.860354   5.1245756]
 [-9.074409   5.812737 ]
 [ 5.517784  -8.9298725]
 [ 5.9122796 -9.098742 ]
 [-8.846927   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730415, shape=(), dtype=float32)
----------epoch 600-----------
batched average loss:  -78.73048 minimum candidate loss:  -78.73048
probability converged
strcuture parameter: 
 [[-9.004196   5.6826453]
 [-8.860352   5.1245756]
 [-9.074405   5.812737 ]
 [ 5.517784  -8.929869 ]
 [ 5.9122796 -9.098738 ]
 [-8.846924   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73046, shape=(), dtype=float32)
----------epoch 650-----------
batched average loss:  -78.730354 minimum candidate loss:  -78.730354
probability converged
strcuture parameter: 
 [[-9.004194   5.6826453]
 [-8.86035    5.1245756]
 [-9.074403   5.812737 ]
 [ 5.517784  -8.929866 ]
 [ 5.9122796 -9.098735 ]
 [-8.846922   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730606, shape=(), dtype=float32)
----------epoch 700-----------
batched average loss:  -78.73041 minimum candidate loss:  -78.730415
probability converged
strcuture parameter: 
 [[-9.004231   5.6826453]
 [-8.860387   5.1245756]
 [-9.07444    5.812737 ]
 [ 5.517784  -8.929902 ]
 [ 5.9122796 -9.098771 ]
 [-8.846959   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730545, shape=(), dtype=float32)
----------epoch 750-----------
batched average loss:  -78.73047 minimum candidate loss:  -78.73047
probability converged
strcuture parameter: 
 [[-9.004208   5.6826453]
 [-8.860363   5.1245756]
 [-9.074417   5.812737 ]
 [ 5.517784  -8.929879 ]
 [ 5.9122796 -9.098748 ]
 [-8.846935   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73066, shape=(), dtype=float32)
----------epoch 800-----------
batched average loss:  -78.7306 minimum candidate loss:  -78.730606
probability converged
strcuture parameter: 
 [[-9.00426    5.6826453]
 [-8.860416   5.1245756]
 [-9.07447    5.812737 ]
 [ 5.517784  -8.929931 ]
 [ 5.9122796 -9.0988   ]
 [-8.846988   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73067, shape=(), dtype=float32)
----------epoch 850-----------
batched average loss:  -78.73069 minimum candidate loss:  -78.73068
probability converged
strcuture parameter: 
 [[-9.004297   5.6826453]
 [-8.860454   5.1245756]
 [-9.074507   5.812737 ]
 [ 5.517784  -8.929968 ]
 [ 5.9122796 -9.098837 ]
 [-8.847025   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730446, shape=(), dtype=float32)
----------epoch 900-----------
batched average loss:  -78.73071 minimum candidate loss:  -78.73071
probability converged
strcuture parameter: 
 [[-9.004321   5.6826453]
 [-8.860477   5.1245756]
 [-9.074531   5.812737 ]
 [ 5.517784  -8.929992 ]
 [ 5.9122796 -9.098861 ]
 [-8.847049   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73053, shape=(), dtype=float32)
----------epoch 950-----------
batched average loss:  -78.730576 minimum candidate loss:  -78.73057
probability converged
strcuture parameter: 
 [[-9.004522   5.6826453]
 [-8.860543   5.1245756]
 [-9.074475   5.812737 ]
 [ 5.517784  -8.929936 ]
 [ 5.9122796 -9.098805 ]
 [-8.846993   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7307, shape=(), dtype=float32)
----------epoch 1000-----------
batched average loss:  -78.730515 minimum candidate loss:  -78.73051
probability converged
strcuture parameter: 
 [[-9.004548   5.6826453]
 [-8.860881   5.1245756]
 [-9.07449    5.812737 ]
 [ 5.517784  -8.929951 ]
 [ 5.9122796 -9.09882  ]
 [-8.847008   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730675, shape=(), dtype=float32)
----------epoch 1050-----------
batched average loss:  -78.7306 minimum candidate loss:  -78.7306
probability converged
strcuture parameter: 
 [[-9.004557   5.6826453]
 [-8.86089    5.1245756]
 [-9.074498   5.812737 ]
 [ 5.517784  -8.929959 ]
 [ 5.9122796 -9.098828 ]
 [-8.847016   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73065, shape=(), dtype=float32)
----------epoch 1100-----------
batched average loss:  -78.73053 minimum candidate loss:  -78.73052
probability converged
strcuture parameter: 
 [[-9.004572   5.6826453]
 [-8.860906   5.1245756]
 [-9.074513   5.812737 ]
 [ 5.517784  -8.929975 ]
 [ 5.9122796 -9.098844 ]
 [-8.847032   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73074, shape=(), dtype=float32)
----------epoch 1150-----------
batched average loss:  -78.73065 minimum candidate loss:  -78.73066
probability converged
strcuture parameter: 
 [[-9.004585   5.6826453]
 [-8.860919   5.1245756]
 [-9.074527   5.812737 ]
 [ 5.517784  -8.929988 ]
 [ 5.9122796 -9.098857 ]
 [-8.847045   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7306, shape=(), dtype=float32)
----------epoch 1200-----------
batched average loss:  -78.73057 minimum candidate loss:  -78.73056
probability converged
strcuture parameter: 
 [[-9.00459    5.6826453]
 [-8.860924   5.1245756]
 [-9.0745325  5.812737 ]
 [ 5.517784  -8.929994 ]
 [ 5.9122796 -9.098863 ]
 [-8.847051   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73043, shape=(), dtype=float32)
----------epoch 1250-----------
batched average loss:  -78.73065 minimum candidate loss:  -78.73065
probability converged
strcuture parameter: 
 [[-9.004591   5.6826453]
 [-8.860925   5.1245756]
 [-9.074533   5.812737 ]
 [ 5.517784  -8.929995 ]
 [ 5.9122796 -9.098864 ]
 [-8.847052   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73058, shape=(), dtype=float32)
----------epoch 1300-----------
batched average loss:  -78.73072 minimum candidate loss:  -78.73072
probability converged
strcuture parameter: 
 [[-9.00465    5.6826453]
 [-8.860923   5.1245756]
 [-9.074532   5.812737 ]
 [ 5.517784  -8.929993 ]
 [ 5.9122796 -9.098862 ]
 [-8.84705    5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73072, shape=(), dtype=float32)
----------epoch 1350-----------
batched average loss:  -78.73046 minimum candidate loss:  -78.73046
probability converged
strcuture parameter: 
 [[-9.004738   5.6826453]
 [-8.860924   5.1245756]
 [-9.0745325  5.812737 ]
 [ 5.517784  -8.929994 ]
 [ 5.9122796 -9.098863 ]
 [-8.847051   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73061, shape=(), dtype=float32)
----------epoch 1400-----------
batched average loss:  -78.73065 minimum candidate loss:  -78.73065
probability converged
strcuture parameter: 
 [[-9.004742   5.6826453]
 [-8.860928   5.1245756]
 [-9.074536   5.812737 ]
 [ 5.517784  -8.929997 ]
 [ 5.9122796 -9.098866 ]
 [-8.8470545  5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730675, shape=(), dtype=float32)
----------epoch 1450-----------
batched average loss:  -78.73054 minimum candidate loss:  -78.730545
probability converged
strcuture parameter: 
 [[-9.004724   5.6826453]
 [-8.860909   5.1245756]
 [-9.074518   5.812737 ]
 [ 5.517784  -8.929979 ]
 [ 5.9122796 -9.098848 ]
 [-8.847036   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730606, shape=(), dtype=float32)
----------epoch 1500-----------
batched average loss:  -78.730644 minimum candidate loss:  -78.730644
probability converged
strcuture parameter: 
 [[-9.004714   5.6826453]
 [-8.8609     5.1245756]
 [-9.074509   5.812737 ]
 [ 5.517784  -8.92997  ]
 [ 5.9122796 -9.098839 ]
 [-8.847027   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73053, shape=(), dtype=float32)
----------epoch 1550-----------
batched average loss:  -78.73082 minimum candidate loss:  -78.73081
probability converged
strcuture parameter: 
 [[-9.004718   5.6826453]
 [-8.860904   5.1245756]
 [-9.0745125  5.812737 ]
 [ 5.517784  -8.929974 ]
 [ 5.9122796 -9.098843 ]
 [-8.847031   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73064, shape=(), dtype=float32)
----------epoch 1600-----------
batched average loss:  -78.73073 minimum candidate loss:  -78.730736
probability converged
strcuture parameter: 
 [[-9.004713   5.6826453]
 [-8.860899   5.1245756]
 [-9.074508   5.812737 ]
 [ 5.517784  -8.929969 ]
 [ 5.9122796 -9.098838 ]
 [-8.847026   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730774, shape=(), dtype=float32)
----------epoch 1650-----------
batched average loss:  -78.73065 minimum candidate loss:  -78.73065
probability converged
strcuture parameter: 
 [[-9.004717   5.6826453]
 [-8.861054   5.1245756]
 [-9.074512   5.812737 ]
 [ 5.517784  -8.929973 ]
 [ 5.9122796 -9.098894 ]
 [-8.84703    5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73074, shape=(), dtype=float32)
----------epoch 1700-----------
batched average loss:  -78.730736 minimum candidate loss:  -78.73074
probability converged
strcuture parameter: 
 [[-9.004728   5.6826453]
 [-8.86107    5.1245756]
 [-9.074523   5.812737 ]
 [ 5.517784  -8.929984 ]
 [ 5.9122796 -9.09892  ]
 [-8.847041   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73068, shape=(), dtype=float32)
----------epoch 1750-----------
batched average loss:  -78.73058 minimum candidate loss:  -78.73058
probability converged
strcuture parameter: 
 [[-9.004726   5.6826453]
 [-8.861069   5.1245756]
 [-9.074522   5.812737 ]
 [ 5.517784  -8.929983 ]
 [ 5.9122796 -9.09892  ]
 [-8.84704    5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73067, shape=(), dtype=float32)
----------epoch 1800-----------
batched average loss:  -78.73058 minimum candidate loss:  -78.73058
probability converged
strcuture parameter: 
 [[-9.004728   5.6826453]
 [-8.861071   5.1245756]
 [-9.074524   5.812737 ]
 [ 5.517784  -8.929985 ]
 [ 5.9122796 -9.098922 ]
 [-8.847042   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.7307, shape=(), dtype=float32)
----------epoch 1850-----------
batched average loss:  -78.73064 minimum candidate loss:  -78.73063
probability converged
strcuture parameter: 
 [[-9.004733   5.6826453]
 [-8.861075   5.1245756]
 [-9.074529   5.812737 ]
 [ 5.517784  -8.930054 ]
 [ 5.9122796 -9.098927 ]
 [-8.847047   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73075, shape=(), dtype=float32)
----------epoch 1900-----------
batched average loss:  -78.730446 minimum candidate loss:  -78.73044
probability converged
strcuture parameter: 
 [[-9.004782   5.6826453]
 [-8.861077   5.1245756]
 [-9.074531   5.812737 ]
 [ 5.517784  -8.930057 ]
 [ 5.9122796 -9.098928 ]
 [-8.847049   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73059, shape=(), dtype=float32)
----------epoch 1950-----------
batched average loss:  -78.73069 minimum candidate loss:  -78.73068
probability converged
strcuture parameter: 
 [[-9.004797   5.6826453]
 [-8.86108    5.1245756]
 [-9.074533   5.812737 ]
 [ 5.517784  -8.930059 ]
 [ 5.9122796 -9.098931 ]
 [-8.847058   5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.73076, shape=(), dtype=float32)
----------epoch 1999-----------
batched average loss:  -78.73072 minimum candidate loss:  -78.73073
probability converged
strcuture parameter: 
 [[-9.004797   5.6826453]
 [-8.86108    5.1245756]
 [-9.074533   5.812737 ]
 [ 5.517784  -8.930059 ]
 [ 5.9122796 -9.098931 ]
 [-8.84706    5.0639806]]
tf.Tensor([1 1 1 0 0 1], shape=(6,), dtype=int64)
current recommendation loss:  tf.Tensor(-78.730896, shape=(), dtype=float32)
Energy: tf.Tensor(-78.730896, shape=(), dtype=float32)
Ref energy: -74.38714627
Error rate: tf.Tensor(0.029066453, shape=(), dtype=float32)
       ┌─────────────┐   ┌────────────┐  ┌────────────┐┌─────────────┐»
 q_0: ─┤ Rx(0.68899) ├───┤ Ry(2.0105) ├──┤ Rz(2.2793) ├┤ Rx(-5.5892) ├»
       ├─────────────┤  ┌┴────────────┤ ┌┴────────────┤└─────────────┘»
 q_1: ─┤ Rx(-3.4824) ├──┤ Ry(-3.7134) ├─┤ Rz(-1.5464) ├───────■───────»
      ┌┴─────────────┴┐ ├─────────────┤ └┬────────────┤       │       »
 q_2: ┤ Rx(-0.021161) ├─┤ Ry(0.30432) ├──┤ Rz(-4.718) ├───────■───────»
      └┬─────────────┬┘ └┬────────────┤ ┌┴────────────┤               »
 q_3: ─┤ Rx(-1.7758) ├───┤ Ry(1.4098) ├─┤ Rz(-1.2287) ├───────■───────»
       ├─────────────┤  ┌┴────────────┤ ├─────────────┤       │       »
 q_4: ─┤ Rx(-1.0804) ├──┤ Ry(-6.7359) ├─┤ Rz(-4.4041) ├───────■───────»
       └┬────────────┤ ┌┴─────────────┴┐├─────────────┤               »
 q_5: ──┤ Rx(4.7511) ├─┤ Ry(-0.041426) ├┤ Rz(-1.4405) ├───────■───────»
       ┌┴────────────┤ └┬─────────────┬┘└┬────────────┤       │       »
 q_6: ─┤ Rx(-3.1416) ├──┤ Ry(-3.1417) ├──┤ Rz(3.3372) ├───────■───────»
       ├─────────────┤  ├─────────────┤  ├────────────┤               »
 q_7: ─┤ Rx(-4.6847) ├──┤ Ry(-2.0046) ├──┤ Rz(1.5394) ├───────■───────»
       ├─────────────┤  ├─────────────┴┐┌┴────────────┤       │       »
 q_8: ─┤ Rx(-3.3471) ├──┤ Ry(0.049824) ├┤ Rz(-2.5534) ├───────■───────»
       ├─────────────┴┐ ├─────────────┬┘├─────────────┤               »
 q_9: ─┤ Rx(0.022202) ├─┤ Ry(-3.1964) ├─┤ Rz(-2.8517) ├───────■───────»
       ├─────────────┬┘ └┬────────────┤ └┬────────────┤       │       »
q_10: ─┤ Rx(-1.2797) ├───┤ Ry(2.3799) ├──┤ Rz(1.3756) ├───────■───────»
       └┬────────────┤   ├────────────┤  ├────────────┤ ┌────────────┐»
q_11: ──┤ Rx(1.7112) ├───┤ Ry(1.8519) ├──┤ Rz(5.0178) ├─┤ Rx(4.9375) ├»
        └────────────┘   └────────────┘  └────────────┘ └────────────┘»
«       ┌─────────────┐   ┌─────────────┐                    ┌─────────────┐ »
« q_0: ─┤ Ry(-4.7095) ├───┤ Rz(-3.8147) ├─────────────────■──┤ Rx(-5.2534) ├─»
«       ├─────────────┤   ├─────────────┤  ┌────────────┐ │  ├─────────────┤ »
« q_1: ─┤ Rx(-5.6607) ├───┤ Ry(-3.0039) ├──┤ Rz(5.6039) ├─■──┤ Rx(-4.6648) ├─»
«       ├─────────────┤  ┌┴─────────────┴┐ ├────────────┤   ┌┴─────────────┴┐»
« q_2: ─┤ Rx(-2.8902) ├──┤ Ry(-0.032645) ├─┤ Rz(1.7949) ├─■─┤ Rx(-0.069645) ├»
«       ├─────────────┤  └─┬────────────┬┘┌┴────────────┤ │ └┬─────────────┬┘»
« q_3: ─┤ Rx(-2.0368) ├────┤ Ry(2.9395) ├─┤ Rz(-2.3363) ├─■──┤ Rx(-4.7865) ├─»
«       ├─────────────┤   ┌┴────────────┤ ├─────────────┤    ├─────────────┴┐»
« q_4: ─┤ Rx(0.44515) ├───┤ Ry(-5.7796) ├─┤ Rz(0.43342) ├─■──┤ Rx(-0.10192) ├»
«       ├─────────────┤   ├─────────────┤ ├─────────────┤ │  └┬────────────┬┘»
« q_5: ─┤ Rx(-1.8619) ├───┤ Ry(-1.7084) ├─┤ Rz(-1.2014) ├─■───┤ Rx(1.4575) ├─»
«      ┌┴─────────────┴─┐ ├─────────────┤ └┬────────────┤    ┌┴────────────┤ »
« q_6: ┤ Rx(0.00010695) ├─┤ Ry(-3.1415) ├──┤ Rz(3.7066) ├─■──┤ Rx(-1.6235) ├─»
«      └┬─────────────┬─┘ ├─────────────┤  ├────────────┤ │  └┬────────────┤ »
« q_7: ─┤ Rx(-3.6681) ├───┤ Ry(-1.6467) ├──┤ Rz(1.5044) ├─■───┤ Rx(3.4952) ├─»
«       ├─────────────┤   ├─────────────┤  ├───────────┬┘    ┌┴────────────┤ »
« q_8: ─┤ Rx(-2.9971) ├───┤ Ry(-7.1786) ├──┤ Rz(2.362) ├──■──┤ Rx(-3.7831) ├─»
«       └┬────────────┤   ├─────────────┤  ├───────────┴┐ │  ├─────────────┤ »
« q_9: ──┤ Rx(4.7791) ├───┤ Ry(-5.6744) ├──┤ Rz(5.3771) ├─■──┤ Rx(0.24575) ├─»
«        ├────────────┤   └┬────────────┤ ┌┴────────────┤    └┬────────────┤ »
«q_10: ──┤ Rx(3.4505) ├────┤ Ry(2.2699) ├─┤ Rz(-1.6224) ├─■───┤ Rx(2.3691) ├─»
«        ├────────────┤   ┌┴────────────┴┐└─────────────┘ │   ├────────────┤ »
«q_11: ──┤ Ry(1.3961) ├───┤ Rz(-0.22287) ├────────────────■───┤ Rx(5.4673) ├─»
«        └────────────┘   └──────────────┘                    └────────────┘ »
«      ┌─────────────┐ ┌─────────────┐ ┌────────────┐┌─────────────┐ »
« q_0: ┤ Ry(-4.4905) ├─┤ Rz(-1.7974) ├─┤ Rx(-3.975) ├┤ Ry(-5.1992) ├─»
«      ├─────────────┤ └┬────────────┤ └────────────┘├─────────────┤ »
« q_1: ┤ Ry(0.21649) ├──┤ Rz(2.5385) ├───────■───────┤ Rx(-2.8718) ├─»
«      └┬────────────┤ ┌┴────────────┤       │       └┬────────────┤ »
« q_2: ─┤ Ry(3.1917) ├─┤ Rz(-2.0272) ├───────■────────┤ Rx(3.1544) ├─»
«      ┌┴────────────┤ ├─────────────┤               ┌┴────────────┤ »
« q_3: ┤ Ry(-1.1652) ├─┤ Rz(-1.5465) ├───────■───────┤ Rx(-2.5817) ├─»
«      └┬───────────┬┘ ├─────────────┤       │       └┬────────────┤ »
« q_4: ─┤ Ry(1.827) ├──┤ Rz(-3.6933) ├───────■────────┤ Rx(1.2269) ├─»
«      ┌┴───────────┴┐ ├─────────────┴┐              ┌┴────────────┤ »
« q_5: ┤ Ry(-4.4016) ├─┤ Rz(-0.41063) ├──────■───────┤ Rx(-1.0174) ├─»
«      ├─────────────┤ ├─────────────┬┘      │       └┬────────────┤ »
« q_6: ┤ Ry(-5.3115) ├─┤ Rz(0.97448) ├───────■────────┤ Rx(-2.584) ├─»
«      └┬────────────┤ ├─────────────┴┐              ┌┴────────────┤ »
« q_7: ─┤ Ry(1.7265) ├─┤ Rz(-0.93274) ├──────■───────┤ Rx(-1.5123) ├─»
«      ┌┴────────────┤ ├─────────────┬┘      │       ├─────────────┤ »
« q_8: ┤ Ry(-5.7096) ├─┤ Rz(-1.7167) ├───────■───────┤ Rx(0.12068) ├─»
«      ├─────────────┴┐├─────────────┤               ├─────────────┴┐»
« q_9: ┤ Ry(-0.92585) ├┤ Rz(0.34875) ├───────■───────┤ Rx(-0.15479) ├»
«      ├──────────────┤└┬───────────┬┘       │       ├─────────────┬┘»
«q_10: ┤ Ry(-0.29931) ├─┤ Rz(3.135) ├────────■───────┤ Rx(0.87571) ├─»
«      └┬────────────┬┘┌┴───────────┴┐ ┌────────────┐└┬────────────┤ »
«q_11: ─┤ Ry(4.5212) ├─┤ Rz(-2.2739) ├─┤ Rx(2.8275) ├─┤ Ry(1.7081) ├─»
«       └────────────┘ └─────────────┘ └────────────┘ └────────────┘ »
«      ┌─────────────┐                     ┌─────────────┐   ┌─────────────┐  »
« q_0: ┤ Rz(-6.2019) ├──────────────────■──┤ Rx(-4.1038) ├───┤ Ry(-5.2486) ├──»
«      └┬────────────┤ ┌─────────────┐  │  ├─────────────┴┐  └┬────────────┤  »
« q_1: ─┤ Ry(2.8552) ├─┤ Rz(0.72626) ├──■──┤ Rx(-0.18326) ├───┤ Ry(3.6976) ├──»
«      ┌┴────────────┤ ├─────────────┤     ├─────────────┬┘  ┌┴────────────┤  »
« q_2: ┤ Ry(-3.1524) ├─┤ Rz(-3.0327) ├──■──┤ Rx(-5.1074) ├───┤ Ry(0.69423) ├──»
«      ├─────────────┤ └┬────────────┤  │  ├─────────────┤   ├─────────────┴┐ »
« q_3: ┤ Ry(-2.2754) ├──┤ Rz(2.6424) ├──■──┤ Rx(-4.7188) ├───┤ Ry(-0.61283) ├─»
«      ├─────────────┤ ┌┴────────────┤     └┬────────────┤   ├─────────────┬┘ »
« q_4: ┤ Ry(-2.0996) ├─┤ Rz(-5.7162) ├──■───┤ Rx(3.1415) ├───┤ Ry(-3.1416) ├──»
«      └┬────────────┤ ├─────────────┤  │   ├────────────┤   ├─────────────┤  »
« q_5: ─┤ Ry(-3.483) ├─┤ Rz(-3.1382) ├──■───┤ Rx(3.1599) ├───┤ Ry(-3.0655) ├──»
«      ┌┴────────────┤ └┬────────────┤     ┌┴────────────┤ ┌─┴─────────────┴─┐»
« q_6: ┤ Ry(-3.9005) ├──┤ Rz(2.3454) ├──■──┤ Rx(-3.1413) ├─┤ Ry(-0.00013508) ├»
«      └┬───────────┬┘ ┌┴────────────┤  │ ┌┴─────────────┴┐└──┬────────────┬─┘»
« q_7: ─┤ Ry(2.272) ├──┤ Rz(-4.1489) ├──■─┤ Rx(-0.065083) ├───┤ Ry(6.0223) ├──»
«      ┌┴───────────┴┐ ├─────────────┤    └┬─────────────┬┘  ┌┴────────────┤  »
« q_8: ┤ Ry(-3.1638) ├─┤ Rz(-2.9494) ├──■──┤ Rx(-5.7515) ├───┤ Ry(-10.262) ├──»
«      ├─────────────┤ ├─────────────┴┐ │  ├─────────────┤   ├─────────────┴┐ »
« q_9: ┤ Ry(-3.3535) ├─┤ Rz(-0.96084) ├─■──┤ Rx(-8.2528) ├───┤ Ry(-0.66947) ├─»
«      ├─────────────┤┌┴──────────────┤    ├─────────────┤   └┬────────────┬┘ »
«q_10: ┤ Ry(0.20782) ├┤ Rz(-0.090911) ├─■──┤ Rx(0.68073) ├────┤ Ry(3.3953) ├──»
«      ├─────────────┤└───────────────┘ │  └┬────────────┤    ├────────────┤  »
«q_11: ┤ Rz(-1.4888) ├──────────────────■───┤ Rx(-4.884) ├────┤ Ry(4.8293) ├──»
«      └─────────────┘                      └────────────┘    └────────────┘  »
«       ┌────────────┐ ┌────────────┐  ┌──────────────┐ ┌──────────────┐»
« q_0: ─┤ Rz(-1.228) ├─┤ Rx(5.4015) ├──┤ Ry(-0.05562) ├─┤ Rz(-0.27792) ├»
«       ├───────────┬┘ └────────────┘  ├─────────────┬┘ └┬────────────┬┘»
« q_1: ─┤ Rz(1.624) ├────────■─────────┤ Rx(-5.1689) ├───┤ Ry(1.5844) ├─»
«       ├───────────┴┐       │         ├─────────────┤   ├────────────┤ »
« q_2: ─┤ Rz(2.9154) ├───────■─────────┤ Rx(-2.8262) ├───┤ Ry(4.6411) ├─»
«       ├────────────┤                 ├─────────────┤   └┬──────────┬┘ »
« q_3: ─┤ Rz(1.4516) ├───────■─────────┤ Rx(-1.9751) ├────┤ Ry(1.84) ├──»
«      ┌┴────────────┤       │       ┌─┴─────────────┴─┐ ┌┴──────────┤  »
« q_4: ┤ Rz(-5.0186) ├───────■───────┤ Rx(-0.00020903) ├─┤ Ry(3.142) ├──»
«      └┬────────────┤               └──┬────────────┬─┘ ├───────────┴┐ »
« q_5: ─┤ Rz(-1.274) ├───────■──────────┤ Rx(2.5289) ├───┤ Ry(-2.815) ├─»
«       ├────────────┤       │         ┌┴────────────┤  ┌┴────────────┤ »
« q_6: ─┤ Rz(3.2189) ├───────■─────────┤ Rx(0.69229) ├──┤ Ry(0.78572) ├─»
«      ┌┴────────────┤                 └┬────────────┤  └┬────────────┤ »
« q_7: ┤ Rz(-1.8794) ├───────■──────────┤ Rx(1.9978) ├───┤ Ry(4.4727) ├─»
«      ├─────────────┤       │          ├────────────┤  ┌┴────────────┤ »
« q_8: ┤ Rz(-2.3897) ├───────■──────────┤ Rx(2.5887) ├──┤ Ry(0.24818) ├─»
«      └┬────────────┤                  ├───────────┬┘  ├─────────────┤ »
« q_9: ─┤ Rz(7.8497) ├───────■──────────┤ Rx(-1.88) ├───┤ Ry(-8.4524) ├─»
«      ┌┴────────────┤       │          └┬──────────┤   └┬────────────┤ »
«q_10: ┤ Rz(0.28502) ├───────■───────────┤ Rx(1.76) ├────┤ Ry(4.2056) ├─»
«      └┬────────────┤┌─────────────┐   ┌┴──────────┴┐  ┌┴────────────┴┐»
«q_11: ─┤ Rz(-1.531) ├┤ Rx(-1.7224) ├───┤ Ry(4.8445) ├──┤ Rz(-0.95185) ├»
«       └────────────┘└─────────────┘   └────────────┘  └──────────────┘»
«                         ┌─────────────┐ ┌────────────┐ ┌───────────┐ »
« q_0: ─────────────────■─┤ Rx(-2.6492) ├─┤ Ry(3.4331) ├─┤ Rz(1.098) ├─»
«      ┌─────────────┐  │ └┬────────────┤┌┴────────────┤ ├───────────┴┐»
« q_1: ┤ Rz(-1.9276) ├──■──┤ Rx(2.0118) ├┤ Ry(-7.7714) ├─┤ Rz(1.6514) ├»
«      ├─────────────┴┐   ┌┴────────────┤└┬───────────┬┘ ├────────────┤»
« q_2: ┤ Rz(-0.29472) ├─■─┤ Rx(-1.7877) ├─┤ Ry(4.435) ├──┤ Rz(1.6968) ├»
«      └┬────────────┬┘ │ ├─────────────┤ ├───────────┤  ├────────────┤»
« q_3: ─┤ Rz(2.9573) ├──■─┤ Rx(-4.1903) ├─┤ Ry(3.705) ├──┤ Rz(1.6463) ├»
«      ┌┴────────────┤    └┬────────────┤ ├───────────┴┐┌┴────────────┤»
« q_4: ┤ Rz(-3.5217) ├──■──┤ Rx(2.9411) ├─┤ Ry(3.0086) ├┤ Rz(-2.1318) ├»
«      └┬────────────┤  │  ├───────────┬┘┌┴────────────┤└┬────────────┤»
« q_5: ─┤ Rz(2.7095) ├──■──┤ Rx(1.939) ├─┤ Ry(-1.5764) ├─┤ Rz(4.7369) ├»
«      ┌┴────────────┤    ┌┴───────────┴┐└┬────────────┤ ├───────────┬┘»
« q_6: ┤ Rz(-2.4317) ├──■─┤ Rx(-4.8785) ├─┤ Ry(5.4785) ├─┤ Rz(5.148) ├─»
«      ├─────────────┴┐ │ ├─────────────┤┌┴────────────┤ ├───────────┴┐»
« q_7: ┤ Rz(-0.20994) ├─■─┤ Rx(0.89497) ├┤ Ry(-7.6171) ├─┤ Rz(-1.542) ├»
«      ├─────────────┬┘   └┬────────────┤└┬────────────┤┌┴────────────┤»
« q_8: ┤ Rz(-0.9242) ├──■──┤ Rx(-2.984) ├─┤ Ry(2.7646) ├┤ Rz(0.61905) ├»
«      └┬────────────┤  │ ┌┴────────────┤ ├────────────┤└┬────────────┤»
« q_9: ─┤ Rz(2.3102) ├──■─┤ Rx(-7.2644) ├─┤ Ry(2.1625) ├─┤ Rz(1.6731) ├»
«       ├────────────┤    ├─────────────┤┌┴────────────┤┌┴────────────┤»
«q_10: ─┤ Rz(1.2229) ├──■─┤ Rx(-3.8242) ├┤ Ry(0.79688) ├┤ Rz(-6.2908) ├»
«       └────────────┘  │ ├─────────────┤└┬────────────┤├─────────────┤»
«q_11: ─────────────────■─┤ Rx(-5.1191) ├─┤ Ry(2.1128) ├┤ Rz(-1.7925) ├»
«                         └─────────────┘ └────────────┘└─────────────┘»
«       ┌────────────┐  ┌────────────┐ ┌──────────────┐                    »
« q_0: ─┤ Rx(2.2935) ├──┤ Ry(5.6898) ├─┤ Rz(-0.58392) ├──────────────────■─»
«       └────────────┘ ┌┴────────────┤ └┬────────────┬┘┌───────────────┐ │ »
« q_1: ───────■────────┤ Rx(-4.7808) ├──┤ Ry(1.4079) ├─┤ Rz(-0.047684) ├─■─»
«             │        ├─────────────┤ ┌┴────────────┤ └┬─────────────┬┘   »
« q_2: ───────■────────┤ Rx(-2.0938) ├─┤ Ry(-1.4656) ├──┤ Rz(-3.1906) ├──■─»
«                      └┬────────────┤ └┬────────────┤  ├─────────────┤  │ »
« q_3: ───────■─────────┤ Rx(-2.226) ├──┤ Ry(1.8834) ├──┤ Rz(-2.1501) ├──■─»
«             │       ┌─┴────────────┴┐┌┴────────────┤  ├─────────────┤    »
« q_4: ───────■───────┤ Rx(-0.002504) ├┤ Ry(-3.1415) ├──┤ Rz(-4.2492) ├──■─»
«                     └─┬────────────┬┘├─────────────┤  └┬────────────┤  │ »
« q_5: ───────■─────────┤ Rx(3.1413) ├─┤ Ry(-3.1415) ├───┤ Rz(5.4462) ├──■─»
«             │        ┌┴────────────┤ ├─────────────┤   ├────────────┤    »
« q_6: ───────■────────┤ Rx(-3.5666) ├─┤ Ry(0.71822) ├───┤ Rz(2.2931) ├──■─»
«                      └┬────────────┤ └┬────────────┤  ┌┴────────────┤  │ »
« q_7: ───────■─────────┤ Rx(3.2648) ├──┤ Ry(1.8336) ├──┤ Rz(-3.0781) ├──■─»
«             │         ├────────────┤  ├────────────┤  ├─────────────┤    »
« q_8: ───────■─────────┤ Rx(-2.698) ├──┤ Ry(2.7451) ├──┤ Rz(-3.2769) ├──■─»
«                      ┌┴────────────┤ ┌┴────────────┤  └┬────────────┤  │ »
« q_9: ───────■────────┤ Rx(-3.2727) ├─┤ Ry(0.64214) ├───┤ Rz(2.9436) ├──■─»
«             │        ├─────────────┤ ├─────────────┴┐  ├────────────┤    »
«q_10: ───────■────────┤ Rx(-8.6828) ├─┤ Ry(-0.51812) ├──┤ Rz(4.8822) ├──■─»
«      ┌─────────────┐ └┬────────────┤ ├─────────────┬┘  └────────────┘  │ »
«q_11: ┤ Rx(-2.5793) ├──┤ Ry(4.4688) ├─┤ Rz(-4.8298) ├───────────────────■─»
«      └─────────────┘  └────────────┘ └─────────────┘                     »
«       ┌─────────────┐ ┌─────────────┐ ┌─────────────┐┌─────────────┐»
« q_0: ─┤ Rx(-6.6509) ├─┤ Ry(-3.7308) ├─┤ Rz(-4.2203) ├┤ Rx(-4.8868) ├»
«       ├─────────────┤ └┬────────────┤ ├─────────────┤└─────────────┘»
« q_1: ─┤ Rx(-4.6883) ├──┤ Ry(6.2989) ├─┤ Rz(-5.6184) ├───────■───────»
«       ├─────────────┤  ├────────────┤ ├─────────────┤       │       »
« q_2: ─┤ Rx(-3.1636) ├──┤ Ry(3.1455) ├─┤ Rz(-4.0916) ├───────■───────»
«       ├─────────────┤ ┌┴────────────┤ └┬────────────┤               »
« q_3: ─┤ Rx(-2.6836) ├─┤ Ry(-3.1391) ├──┤ Rz(7.5339) ├───────■───────»
«      ┌┴─────────────┴┐├─────────────┴┐┌┴────────────┤       │       »
« q_4: ┤ Rx(0.0052328) ├┤ Ry(0.013086) ├┤ Rz(-5.2501) ├───────■───────»
«      └┬─────────────┬┘└┬────────────┬┘└┬───────────┬┘               »
« q_5: ─┤ Rx(-3.1419) ├──┤ Ry(3.1413) ├──┤ Rz(5.383) ├────────■───────»
«       ├─────────────┴┐┌┴────────────┤  ├───────────┴┐       │       »
« q_6: ─┤ Rx(-0.59447) ├┤ Ry(0.88533) ├──┤ Rz(1.3551) ├───────■───────»
«       ├─────────────┬┘├─────────────┤ ┌┴────────────┤               »
« q_7: ─┤ Rx(0.47452) ├─┤ Ry(-1.0185) ├─┤ Rz(-4.0288) ├───────■───────»
«       ├─────────────┤ ├─────────────┤ └┬────────────┤       │       »
« q_8: ─┤ Rx(-2.9541) ├─┤ Ry(-6.7512) ├──┤ Rz(2.5198) ├───────■───────»
«       ├─────────────┴┐├─────────────┤  ├────────────┤               »
« q_9: ─┤ Rx(0.076001) ├┤ Ry(-6.3454) ├──┤ Rz(6.8117) ├───────■───────»
«       └┬────────────┬┘└┬────────────┤  ├────────────┤       │       »
«q_10: ──┤ Rx(2.9628) ├──┤ Ry(3.8232) ├──┤ Rz(8.0761) ├───────■───────»
«        ├───────────┬┘  ├────────────┤  ├────────────┤ ┌────────────┐»
«q_11: ──┤ Rx(-1.48) ├───┤ Ry(1.3142) ├──┤ Rz(1.9724) ├─┤ Rx(4.7868) ├»
«        └───────────┘   └────────────┘  └────────────┘ └────────────┘»
«      ┌──────────────┐┌─────────────┐                    ┌────────────┐»
« q_0: ┤ Ry(-0.33584) ├┤ Rz(-3.7648) ├─────────────────■──┤ Rx(3.0839) ├»
«      ├─────────────┬┘├─────────────┤┌─────────────┐  │ ┌┴────────────┤»
« q_1: ┤ Rx(-6.2783) ├─┤ Ry(-3.1402) ├┤ Rz(-1.9641) ├──■─┤ Rx(-4.0143) ├»
«      └┬────────────┤ └┬────────────┤├─────────────┤    └┬────────────┤»
« q_2: ─┤ Rx(4.5607) ├──┤ Ry(4.5159) ├┤ Rz(-1.8475) ├──■──┤ Rx(5.0712) ├»
«      ┌┴────────────┤ ┌┴────────────┤└┬────────────┤  │  ├───────────┬┘»
« q_3: ┤ Rx(-3.6874) ├─┤ Ry(-2.2578) ├─┤ Rz(6.1807) ├──■──┤ Rx(7.294) ├─»
«      └┬────────────┤ ├─────────────┤ ├────────────┤     ├───────────┴┐»
« q_4: ─┤ Rx(3.2694) ├─┤ Ry(0.13111) ├─┤ Rz(-5.035) ├──■──┤ Rx(3.8385) ├»
«      ┌┴────────────┤ ├─────────────┤ ├────────────┤  │ ┌┴────────────┤»
« q_5: ┤ Rx(-3.1426) ├─┤ Ry(-3.1412) ├─┤ Rz(3.5708) ├──■─┤ Rx(-3.1399) ├»
«      └┬───────────┬┘ └┬────────────┤┌┴────────────┴┐   └┬────────────┤»
« q_6: ─┤ Rx(1.686) ├───┤ Ry(1.9121) ├┤ Rz(-0.05046) ├─■──┤ Rx(5.2672) ├»
«      ┌┴───────────┴┐  ├────────────┤├──────────────┤ │ ┌┴────────────┤»
« q_7: ┤ Rx(-5.8026) ├──┤ Ry(7.0838) ├┤ Rz(-0.52768) ├─■─┤ Rx(-6.1849) ├»
«      ├─────────────┤  ├────────────┤├─────────────┬┘   ├─────────────┤»
« q_8: ┤ Rx(-3.1366) ├──┤ Ry(3.4306) ├┤ Rz(-5.8268) ├──■─┤ Rx(-7.1051) ├»
«      ├─────────────┴┐┌┴────────────┤├─────────────┤  │ └┬────────────┤»
« q_9: ┤ Rx(-0.28806) ├┤ Ry(-6.0041) ├┤ Rz(-3.0115) ├──■──┤ Rx(0.5638) ├»
«      ├─────────────┬┘├─────────────┤└┬────────────┤    ┌┴────────────┤»
«q_10: ┤ Rx(0.85783) ├─┤ Ry(0.36287) ├─┤ Rz(4.1391) ├──■─┤ Rx(-1.8285) ├»
«      └┬────────────┤ ├─────────────┤ └────────────┘  │ └┬────────────┤»
«q_11: ─┤ Ry(1.2562) ├─┤ Rz(-2.6598) ├─────────────────■──┤ Rx(3.1707) ├»
«       └────────────┘ └─────────────┘                    └────────────┘»
«       ┌────────────┐┌─────────────┐  ┌────────────┐  ┌────────────┐ »
« q_0: ─┤ Ry(4.6925) ├┤ Rz(-1.5576) ├──┤ Rx(2.8446) ├──┤ Ry(4.6471) ├─»
«      ┌┴────────────┤├─────────────┤ ┌┴────────────┤ ┌┴────────────┴┐»
« q_1: ┤ Ry(-1.5127) ├┤ Rz(-3.0361) ├─┤ Rx(0.13526) ├─┤ Ry(-0.53204) ├»
«      └┬────────────┤├─────────────┴┐└┬────────────┤ ├─────────────┬┘»
« q_2: ─┤ Ry(2.9559) ├┤ Rz(-0.63757) ├─┤ Rx(4.2289) ├─┤ Ry(-3.6017) ├─»
«      ┌┴────────────┤└┬────────────┬┘ ├────────────┤ ├─────────────┤ »
« q_3: ┤ Ry(0.78696) ├─┤ Rz(4.9902) ├──┤ Rx(1.2666) ├─┤ Ry(0.50418) ├─»
«      └┬────────────┤┌┴────────────┤  ├────────────┤ └┬────────────┤ »
« q_4: ─┤ Ry(4.2423) ├┤ Rz(-6.8471) ├──┤ Rx(3.9843) ├──┤ Ry(4.4369) ├─»
«      ┌┴────────────┤├─────────────┤ ┌┴────────────┤ ┌┴────────────┤ »
« q_5: ┤ Ry(-4.4338) ├┤ Rz(0.05972) ├─┤ Rx(-3.3413) ├─┤ Ry(-4.4286) ├─»
«      └┬────────────┤└┬────────────┤ └┬────────────┤ ├─────────────┤ »
« q_6: ─┤ Ry(1.6508) ├─┤ Rz(2.7353) ├──┤ Rx(6.3596) ├─┤ Ry(-2.6947) ├─»
«       ├────────────┤ ├────────────┤ ┌┴────────────┤ └┬────────────┤ »
« q_7: ─┤ Ry(4.3506) ├─┤ Rz(3.4043) ├─┤ Rx(-3.2887) ├──┤ Ry(3.4885) ├─»
«      ┌┴────────────┤ ├────────────┤ ├─────────────┴┐┌┴────────────┤ »
« q_8: ┤ Ry(-8.6684) ├─┤ Rz(4.1946) ├─┤ Rx(-0.19924) ├┤ Ry(-11.193) ├─»
«      ├─────────────┤┌┴────────────┤ └┬────────────┬┘├─────────────┤ »
« q_9: ┤ Ry(-1.8325) ├┤ Rz(-3.3701) ├──┤ Rx(2.0021) ├─┤ Ry(-1.2014) ├─»
«      └┬────────────┤└┬────────────┤  ├────────────┤ └┬────────────┤ »
«q_10: ─┤ Ry(3.6179) ├─┤ Rz(-2.652) ├──┤ Rx(4.3751) ├──┤ Ry(4.9255) ├─»
«      ┌┴────────────┤┌┴────────────┤ ┌┴────────────┤ ┌┴────────────┤ »
«q_11: ┤ Ry(0.78791) ├┤ Rz(-2.7444) ├─┤ Rx(-6.6205) ├─┤ Ry(-2.4145) ├─»
«      └─────────────┘└─────────────┘ └─────────────┘ └─────────────┘ »
«      ┌─────────────┐                                                         »
« q_0: ┤ Rz(-2.0951) ├─■────────────────────────────────■──■───────────────────»
«      ├─────────────┤ │                                │  │                   »
« q_1: ┤ Rz(-0.2866) ├─■──■────────■────────────────────┼──┼─────■────────■────»
«      └┬────────────┤    │        │                    │  │     │        │    »
« q_2: ─┤ Rz(2.1623) ├────■──■─────┼────────────────────┼──■──■──┼─────■──┼────»
«       ├────────────┤       │     │                    │     │  │     │  │    »
« q_3: ─┤ Rz(3.3752) ├───────■──■──■─────■──────────────┼─────┼──┼─────┼──┼────»
«      ┌┴────────────┤          │        │              │     │  │     │  │    »
« q_4: ┤ Rz(0.58774) ├──────────■──■─────┼──────────────┼─────■──┼──■──┼──■──■─»
«      └┬────────────┤             │     │              │        │  │  │     │ »
« q_5: ─┤ Rz(1.8202) ├─────────────■──■──■─────■────────┼────────┼──┼──■─────┼─»
«      ┌┴────────────┤                │        │        │        │  │        │ »
« q_6: ┤ Rz(-6.8399) ├────────────────■──■─────┼────────┼────────┼──■──■─────┼─»
«      └┬───────────┬┘                   │     │        │        │     │     │ »
« q_7: ─┤ Rz(2.787) ├────────────────────■──■──■─────■──┼────────┼─────┼─────■─»
«       ├───────────┴┐                      │        │  │        │     │       »
« q_8: ─┤ Rz(3.5256) ├──────────────────────■──■─────┼──┼────────┼─────■──■────»
«      ┌┴────────────┤                         │     │  │        │        │    »
« q_9: ┤ Rz(-0.1889) ├─────────────────────────■──■──■──┼──■─────┼────────┼────»
«      ├─────────────┤                            │     │  │     │        │    »
«q_10: ┤ Rz(-0.2185) ├────────────────────────────■──■──┼──┼─────┼────────■────»
«      └┬────────────┤                               │  │  │     │             »
«q_11: ─┤ Rz(6.3365) ├───────────────────────────────■──■──■─────■─────────────»
«       └────────────┘                                                         »
«                                                                     »
« q_0: ─■───────■─────────────────────────────────────────────────────»
«       │       │                                       ┌────────────┐»
« q_1: ─┼───────┼─────────────────────────────────────■─┤ Rx(3.1486) ├»
«       │       │                                     │ └────────────┘»
« q_2: ─┼───────┼─────────────────────────────────────┼───────■───────»
«       │       │                                     │       │       »
« q_3: ─┼───────■────────────────────────────■────────┼───────┼───────»
«       │ ┌────────────┐┌─────────────┐      │        │       │       »
« q_4: ─┼─┤ Rx(3.1407) ├┤ Ry(-3.1399) ├──────┼────────┼───────┼───────»
«       │ └────────────┘├─────────────┤      │        │       │       »
« q_5: ─┼───────■───────┤ Rx(-3.1416) ├──────┼────────┼───────┼───────»
«       │       │       └─────────────┘      │        │       │       »
« q_6: ─┼───────┼────────────────────────────■────────┼───────┼───────»
«       │       │                      ┌────────────┐ │       │       »
« q_7: ─┼───────┼──────────────■───────┤ Rx(3.1056) ├─┼───────┼───────»
«       │       │              │       └────────────┘ │       │       »
« q_8: ─┼───────■──────────────┼─────────────■────────┼───────┼───────»
«       │                      │             │        │       │       »
« q_9: ─┼──────────────────────┼─────────────┼────────┼───────┼───────»
«       │                      │             │        │       │       »
«q_10: ─■──────────────────────■─────────────┼────────■───────┼───────»
«                                            │                │       »
«q_11: ──────────────────────────────────────■────────────────■───────»
«                                                                     »
«                                                           ┌────────────┐  »
« q_0: ─────────────────────────────────────────────────■───┤ Rx(-3.142) ├──»
«      ┌─────────────┐ ┌────────────┐                   │   └────────────┘  »
« q_1: ┤ Ry(-3.1378) ├─┤ Rz(8.6855) ├───────────────────┼───────────────────»
«      ├─────────────┤ ├────────────┤ ┌─────────────┐   │                   »
« q_2: ┤ Rx(-1.1279) ├─┤ Ry(4.6421) ├─┤ Rz(-5.4888) ├───┼───────────────────»
«      └┬────────────┤ ├────────────┤ └┬───────────┬┘   │                   »
« q_3: ─┤ Rx(3.1403) ├─┤ Ry(6.2859) ├──┤ Rz(-7.05) ├────┼───────────────────»
«       ├────────────┤ └────────────┘  └───────────┘    │                   »
« q_4: ─┤ Rz(3.1727) ├──────────────────────────────────┼───────────────────»
«       ├────────────┤ ┌────────────┐                   │                   »
« q_5: ─┤ Ry(3.1417) ├─┤ Rz(6.1111) ├───────────────────┼───────────────────»
«       └────────────┘ └────────────┘  ┌────────────┐   │   ┌────────────┐  »
« q_6: ──────────────────────■─────────┤ Rx(2.4976) ├───┼───┤ Ry(3.3261) ├──»
«       ┌────────────┐       │         ├───────────┬┘   │   └────────────┘  »
« q_7: ─┤ Ry(3.1151) ├───────┼─────────┤ Rz(4.839) ├────┼───────────────────»
«      ┌┴────────────┤       │       ┌─┴───────────┴──┐ │   ┌────────────┐  »
« q_8: ┤ Rx(-3.1413) ├───────┼───────┤ Ry(0.00010255) ├─┼───┤ Rz(-3.051) ├──»
«      └─────────────┘       │       └────────────────┘ │ ┌─┴────────────┴─┐»
« q_9: ──────────────────────■──────────────────────────■─┤ Rx(-0.0014024) ├»
«      ┌─────────────┐┌─────────────┐ ┌─────────────┐     └────────────────┘»
«q_10: ┤ Rx(-3.1425) ├┤ Ry(-3.1418) ├─┤ Rz(-5.8579) ├───────────────────────»
«      ├─────────────┤└┬────────────┤ └┬────────────┤                       »
«q_11: ┤ Rx(-6.2832) ├─┤ Ry(6.2832) ├──┤ Rz(2.4483) ├───────────────────────»
«      └─────────────┘ └────────────┘  └────────────┘                       »
«      ┌─────────────┐┌──────────────┐
« q_0: ┤ Ry(-3.1419) ├┤ Rz(-0.58686) ├
«      └─────────────┘└──────────────┘
« q_1: ───────────────────────────────
«                                     
« q_2: ───────────────────────────────
«                                     
« q_3: ───────────────────────────────
«                                     
« q_4: ───────────────────────────────
«                                     
« q_5: ───────────────────────────────
«       ┌───────────┐                 
« q_6: ─┤ Rz(3.745) ├─────────────────
«       └───────────┘                 
« q_7: ───────────────────────────────
«                                     
« q_8: ───────────────────────────────
«       ┌────────────┐ ┌────────────┐ 
« q_9: ─┤ Ry(3.1428) ├─┤ Rz(1.4864) ├─
«       └────────────┘ └────────────┘ 
«q_10: ───────────────────────────────
«                                     
«q_11: ───────────────────────────────
«                                     
